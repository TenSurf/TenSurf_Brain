{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-4fw_YqzlXh"
      },
      "source": [
        "#Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDTDcE5hzixq",
        "outputId": "aff3238a-1eb3-4700-b14a-102ef6a58f69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -upy-cuda12x (c:\\users\\tensu\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -upy-cuda12x (c:\\users\\tensu\\anaconda3\\lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataprep 0.4.5 requires pandas<2.0,>=1.1, but you have pandas 2.2.1 which is incompatible.\n",
            "dataprep 0.4.5 requires pydantic<2.0,>=1.6, but you have pydantic 2.6.4 which is incompatible.\n",
            "dataprep 0.4.5 requires regex<2022.0.0,>=2021.8.3, but you have regex 2023.12.25 which is incompatible.\n",
            "dataprep 0.4.5 requires sqlalchemy==1.3.24, but you have sqlalchemy 2.0.27 which is incompatible.\n",
            "modin 0.20.1 requires pandas==1.5.3, but you have pandas 2.2.1 which is incompatible.\n",
            "streamlit 1.20.0 requires pandas<2,>=0.25, but you have pandas 2.2.1 which is incompatible.\n",
            "streamlit 1.20.0 requires protobuf<4,>=3.12, but you have protobuf 4.25.3 which is incompatible.\n",
            "tensorflow-intel 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
            "transformers 4.24.0 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.15.2 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langgraph langchain langchain_openai langchainhub langchain-core langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXgPXexOzu1Y"
      },
      "source": [
        "#Load key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iZja0GkezuOB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pPviSQU_z-Ml"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S34eFEoL0DNw"
      },
      "source": [
        "#Define the Tools\n",
        "### tools = function call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QJ3Ptj0C0C04"
      },
      "outputs": [],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import StructuredTool\n",
        "from langgraph.prebuilt import ToolExecutor\n",
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L_Zlfuo14_zy"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def multiply(first_number: int, second_number: int) -> int:\n",
        "    \"\"\"Multiplies two numbers together.\"\"\"\n",
        "    return first_number * second_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D6QuQd-e8udB"
      },
      "outputs": [],
      "source": [
        "tools = [multiply]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV7YbzMn7-zV"
      },
      "source": [
        "# Set up the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j-xVNSru7-cW"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_openai_tools_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate, SystemMessagePromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DUJrXG9e8VMi"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\",\n",
        "                   temperature=0,\n",
        "                   streaming=True)\n",
        "system_template = \"\"\"\n",
        "You are a assistant.\n",
        "\"\"\"\n",
        "human_template = \"{input}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1PxrzZhX8XcD"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessagePromptTemplate.from_template(system_template),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
        "        HumanMessagePromptTemplate.from_template(\n",
        "            input_variables=[\"input\"], template=human_template\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PILRKjCL8qe2"
      },
      "outputs": [],
      "source": [
        "agent = create_openai_tools_agent(model, tools, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB79W0VZ80bZ"
      },
      "source": [
        "#Run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NLn-LvyV82GT"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "W17YNcpD83zV"
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True).with_config({\"run_name\": \"Agent with Tools\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpNpJ8Bk85TN",
        "outputId": "287d148a-b853-4c0e-ba59-a7a4aafc7de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `multiply` with `{'first_number': 2, 'second_number': 8}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m16\u001b[0m\u001b[32;1m\u001b[1;3mThe result of multiplying 2 by 8 is 16.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'what is 2 mul 8?',\n",
              " 'output': 'The result of multiplying 2 by 8 is 16.'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"what is 2 mul 8?\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nB1ZZfm9Ovp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
