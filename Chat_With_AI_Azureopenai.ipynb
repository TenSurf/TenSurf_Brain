{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAhjshLYldSq"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import PyPDF2\n",
        "import os\n",
        "from typing import Optional\n",
        "import requests\n",
        "from typing import Optional\n",
        "import base64\n",
        "from openpyxl import load_workbook\n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "from pptx import Presentation\n",
        "import docx\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "from functions_json import functions\n",
        "from functions_python import *\n",
        "from utils import date_validation, monthdelta\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "class FileProcessor:\n",
        "    def __init__(self, api_name='azureopenai'):\n",
        "        self.api_name = api_name\n",
        "        self.default_prompt = \"What is the main idea of this file?\"\n",
        "        if self.api_name == 'openai':\n",
        "            self.api_key = \"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\"\n",
        "            self.client = OpenAI(api_key=self.api_key)\n",
        "            self.GPT_MODEL = \"gpt-3.5-turbo-1106\"\n",
        "            self.whisper_model = \"whisper-1\"\n",
        "        else:  # Default to 'azureopenai'\n",
        "            self.api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "            self.api_version = '2023-10-01-preview'\n",
        "            self.api_key = '80ddd1ad72504f2fa226755d49491a61'\n",
        "            self.client = AzureOpenAI(\n",
        "                api_key=self.api_key,\n",
        "                api_version=self.api_version,\n",
        "                azure_endpoint=self.api_endpoint\n",
        "            )\n",
        "            self.tts_api_version = '2024-02-15-preview'\n",
        "            self.tts_model = 'TTS_1'\n",
        "            self.GPT_MODEL = \"gpt_35_16k\"\n",
        "            self.whisper_model = \"whisper_001\"\n",
        "            self.voice_name = 'alloy'\n",
        "            self.tts_model = 'tts_1'\n",
        "\n",
        "    def is_TunSurf_related (self, prompt):\n",
        "\n",
        "                messages = [\n",
        "                {\"role\": \"system\", \"content\": \"Classify if the following prompt is relevant or irrelevant. Guidelines for you as a Trading Assistant:Relevance: Focus exclusively on queries related to trading and financial markets(including stock tickers). If a question falls outside this scope, politely inform the user that the question is beyond the service's focus.Accuracy: Ensure that the information provided is accurate and up-to-date. Use reliable financial data and current market analysis to inform your responses.Clarity: Deliver answers in a clear, concise, and understandable manner. Avoid jargon unless the user demonstrates familiarity with financial terms.Promptness: Aim to provide responses quickly to facilitate timely decision-making for users.Confidentiality: Do not ask for or handle personal investment details or sensitive financial information.Compliance: Adhere to legal and ethical standards applicable to financial advice and information dissemination.Again, focus solely on topics related to trading and financial markets. Politely notify the user if a question is outside this specific area of expertise.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "                ]\n",
        "                '''\n",
        "                messages = [\n",
        "                {\"role\": \"system\", \"content\": \"Classify if the following prompt is irrelevant to trading or financial markets. note: just say irrelevant or relevant\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "                {\"role\": \"system\", \"content\": \"Guidelines for you as a Trading Assistant:Relevance: Focus exclusively on queries related to trading and financial markets. If a question falls outside this scope, politely inform the user that the question is beyond the service's focus.Accuracy: Ensure that the information provided is accurate and up-to-date. Use reliable financial data and current market analysis to inform your responses.Clarity: Deliver answers in a clear, concise, and understandable manner. Avoid jargon unless the user demonstrates familiarity with financial terms.Promptness: Aim to provide responses quickly to facilitate timely decision-making for users.Confidentiality: Do not ask for or handle personal investment details or sensitive financial information.Compliance: Adhere to legal and ethical standards applicable to financial advice and information dissemination.Again, focus solely on topics related to trading and financial markets. Politely notify the user if a question is outside this specific area of expertise.\"}\n",
        "                ]\n",
        "                '''\n",
        "                response = self.client.chat.completions.create(model= self.GPT_MODEL, temperature=0.2, messages=messages)\n",
        "                #print(response)\n",
        "                return response.choices[0].message.content\n",
        "\n",
        "    def text_to_speech(self, text, output_file='output.mp3'):\n",
        "      if self.api_name == 'azureopenai':\n",
        "        url = f\"{self.api_endpoint}/openai/deployments/{self.tts_model}/audio/speech?api-version={self.tts_api_version}\"\n",
        "        headers = {\n",
        "            \"api-key\": self.api_key,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model\": self.tts_model,\n",
        "            \"input\": text,\n",
        "            \"voice\": self.voice_name\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "        if response.status_code == 200:\n",
        "            with open(output_file, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            return output_file\n",
        "        else:\n",
        "            print(f\"Failed to generate speech: {response.status_code} - {response.text}\")\n",
        "            return None\n",
        "      else:\n",
        "        response1 = self.client.audio.speech.create(\n",
        "            model= self.tts_model,\n",
        "            voice= self.voice_name,\n",
        "            input= text\n",
        "            )\n",
        "        response = response1.stream_to_file(\"output_file.mp3\")\n",
        "        if response.status_code == 200:\n",
        "            with open(output_file, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            return output_file\n",
        "        else:\n",
        "            print(f\"Failed to generate speech: {response.status_code} - {response.text}\")\n",
        "            return None\n",
        "\n",
        "    def chat_with_ai(self, messages: list, content: str, file_exist):\n",
        "\n",
        "        # try:\n",
        "            if not content:\n",
        "              return \"\"\n",
        "\n",
        "            relevance_check = self.is_TunSurf_related(content)\n",
        "            if \"irrelevant\" in relevance_check.lower():\n",
        "              return \"I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\"\n",
        "\n",
        "\n",
        "\n",
        "            def get_response(messages, functions, model, function_call):\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=model, temperature=0.2, messages=messages, functions=functions, function_call=function_call)\n",
        "                return response\n",
        "\n",
        "            def get_result(messages, chat_response):\n",
        "                assistant_message = chat_response.choices[0].message\n",
        "                messages.append(assistant_message)\n",
        "\n",
        "                if chat_response.choices[0].message.function_call == None:\n",
        "                    results = f\"{chat_response.choices[0].message.content}\"\n",
        "\n",
        "                else:\n",
        "                    function_name = chat_response.choices[0].message.function_call.name\n",
        "                    function_arguments = json.loads(chat_response.choices[0].message.function_call.arguments)\n",
        "                    FC = FunctionCalls()\n",
        "                    print(f\"\\n{chat_response.choices[0].message}\\n\")\n",
        "                    from datetime import datetime\n",
        "                    now = datetime.now()\n",
        "\n",
        "                    if function_name == \"detect_trend\":\n",
        "                        # correcting function_arguments\n",
        "                        if \"lookback\" not in function_arguments:\n",
        "                            if \"symbol\" not in function_arguments:\n",
        "                                function_arguments[\"symbol\"] = \"NQ\"\n",
        "                            if \"start_datetime\" not in function_arguments:\n",
        "                                function_arguments[\"start_datetime\"] = f\"{now - timedelta(days=10)}\"\n",
        "                            if \"end_datetime\" not in function_arguments:\n",
        "                                function_arguments[\"end_datetime\"] = f\"{now}\"\n",
        "                        else:\n",
        "                            if ((\"lookback\" in function_arguments) and (\"start_datetime\" in function_arguments)) or \\\n",
        "                                ((\"lookback\" in function_arguments) and (\"end_datetime\" in function_arguments)):\n",
        "                                raise ValueError(\"Both lookback and datetimes could not be valued\")\n",
        "                            else:\n",
        "                                function_arguments[\"end_datetime\"] = f\"{now}\"\n",
        "                                k = int(function_arguments[\"lookback\"].split(\" \")[0])\n",
        "                                if function_arguments[\"lookback\"].split(\" \")[-1] == \"seconds\" or function_arguments[\"lookback\"].split(\" \")[-1] == \"second\":\n",
        "                                    function_arguments[\"start_datetime\"] = f\"{now - timedelta(seconds=k)}\"\n",
        "                                elif function_arguments[\"lookback\"].split(\" \")[-1] == \"minutes\" or function_arguments[\"lookback\"].split(\" \")[-1] == \"minute\":\n",
        "                                    function_arguments[\"start_datetime\"] = f\"{now - timedelta(minutes=k)}\"\n",
        "                                elif function_arguments[\"lookback\"].split(\" \")[-1] == \"hours\" or function_arguments[\"lookback\"].split(\" \")[-1] == \"hour\":\n",
        "                                    function_arguments[\"start_datetime\"] = f\"{now - timedelta(hours=k)}\"\n",
        "                                elif function_arguments[\"lookback\"].split(\" \")[-1] == \"days\" or function_arguments[\"lookback\"].split(\" \")[-1] == \"day\":\n",
        "                                    function_arguments[\"start_datetime\"] = f\"{now - timedelta(days=k)}\"\n",
        "                                elif function_arguments[\"lookback\"].split(\" \")[-1] == \"weeks\" or function_arguments[\"lookback\"].split(\" \")[-1] == \"week\":\n",
        "                                    function_arguments[\"start_datetime\"] = f\"{now - timedelta(weeks=k)}\"\n",
        "                                elif function_arguments[\"lookback\"].split(\" \")[-1] == \"months\" or function_arguments[\"lookback\"].split(\" \")[-1] == \"month\":\n",
        "                                    function_arguments[\"start_datetime\"] = f\"{monthdelta(now, -k)}\"\n",
        "                                elif function_arguments[\"lookback\"].split(\" \")[-1] == \"years\" or function_arguments[\"lookback\"].split(\" \")[-1] == \"year\":\n",
        "                                    function_arguments[\"start_datetime\"] = f\"{now - relativedelta(years=k)}\"\n",
        "                                else:\n",
        "                                    raise ValueError(\"???\")\n",
        "\n",
        "                        # if the date formats were not valid\n",
        "                        if not (date_validation(function_arguments[\"start_datetime\"]) and date_validation(function_arguments[\"end_datetime\"])):\n",
        "                            results = \"Please enter dates in the following foramat: YYYY-MM-DD or specify a period of time whether for the past seconds or minutes or hours or days or weeks or years.\"\n",
        "\n",
        "                        trend = FC.detect_trend(parameters=function_arguments)\n",
        "                        messages.append({\"role\": \"system\", \"content\": f\"The result of the function calling with function {function_name} has become {trend}. At any situations, never return the number which is the output of the detect_trend function. Instead, use its correcsponding explanation which is in the detect_trend function's description. Make sure to mention the start_datetime and end_datetime. If the user provide neither specified both start_datetime and end_datetime nor lookback parameters, politely tell them that they should. Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Now generate a proper response.\"})\n",
        "                        chat_response = get_response(\n",
        "                            messages, functions, self.GPT_MODEL, \"auto\"\n",
        "                        )\n",
        "                        assistant_message = chat_response.choices[0].message\n",
        "                        messages.append(assistant_message)\n",
        "                        results = chat_response.choices[0].message.content\n",
        "\n",
        "                    elif function_name == \"calculate_sr\":\n",
        "                        # correcting function_arguments\n",
        "                        if \"symbol\" not in function_arguments:\n",
        "                            function_arguments[\"symbol\"] = \"ES\"\n",
        "                        if \"timeframe\" not in function_arguments:\n",
        "                            function_arguments[\"timeframe\"] = \"1h\"\n",
        "                        if \"lookback_days\" not in function_arguments:\n",
        "                            function_arguments[\"lookback_days\"] = \"10 days\"\n",
        "\n",
        "                        sr_value, sr_start_date, sr_end_date, sr_importance = FC.calculate_sr(parameters=function_arguments)\n",
        "                        messages.append({\"role\": \"system\", \"content\": f\"The result of the function calling with function {function_name} has become {sr_value} for levels_prices, {sr_start_date} for levels_start_timestamps, {sr_end_date} for levels_end_timestamps and {sr_importance} for levels_scores. Now generate a proper response\"})\n",
        "                        chat_response = get_response(\n",
        "                            messages, functions, self.GPT_MODEL, \"auto\"\n",
        "                        )\n",
        "                        results = chat_response.choices[0].message.content\n",
        "\n",
        "                    elif function_name == \"visualize_data\":\n",
        "                      def get_and_visualize_polygon_data(ticker: str, start_datetime_str: str = None, end_datetime_str: str = None, timeframe: str = 'day', api_key: str = None, data_type: str = \"realtime\") -> dict:\n",
        "                        if data_type == \"realtime\":\n",
        "                            current_time = datetime.now()\n",
        "                            end_datetime =  current_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        "                            three_days_ago = current_time - timedelta(days=3)\n",
        "                            start_datetime = three_days_ago.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        "                            start_datetime_str = start_datetime\n",
        "                            end_datetime_str = end_datetime\n",
        "                            start_datetime = datetime.strptime(start_datetime_str, \"%Y-%m-%dT%H:%M:%S\")\n",
        "                            end_datetime = datetime.strptime(end_datetime_str, \"%Y-%m-%dT%H:%M:%S\")\n",
        "                            start_timestamp_ms = int(start_datetime.timestamp()) * 1000\n",
        "                            end_timestamp_ms = int(end_datetime.timestamp()) * 1000\n",
        "                            url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/{timeframe}/{start_timestamp_ms}/{end_timestamp_ms}?apiKey={api_key}\"\n",
        "                        elif data_type == \"historical\":\n",
        "                            start_datetime = datetime.strptime(start_datetime_str, \"%Y-%m-%dT%H:%M:%S\")\n",
        "                            end_datetime = datetime.strptime(end_datetime_str, \"%Y-%m-%dT%H:%M:%S\")\n",
        "                            start_timestamp_ms = int(start_datetime.timestamp()) * 1000\n",
        "                            end_timestamp_ms = int(end_datetime.timestamp()) * 1000\n",
        "                            url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/{timeframe}/{start_timestamp_ms}/{end_timestamp_ms}?apiKey={api_key}\"\n",
        "                        else:\n",
        "                            return {\"error\": \"Invalid data type. Please specify either 'realtime' or 'historical'.\"}\n",
        "                        response = requests.get(url)\n",
        "                        function_response = response.json()\n",
        "                        prices = [{'time': datetime.fromtimestamp(result['t'] / 1000), 'open': result['o'], 'close': result['c'], 'high': result['h'], 'low': result['l'], 'volume': result['v']} for result in function_response['results']]\n",
        "                        data = pd.DataFrame(prices)\n",
        "                        #print(data)\n",
        "                        data.to_csv(\"data.csv\")\n",
        "\n",
        "                        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
        "\n",
        "                        fig.add_trace(go.Candlestick(x=data['time'],\n",
        "                                          open=data['open'],\n",
        "                                          high=data['high'],\n",
        "                                          low=data['low'],\n",
        "                                          close=data['close'],\n",
        "                                          name='Candlestick Chart'), row=1, col=1)\n",
        "\n",
        "                        # Volume plot\n",
        "                        fig.add_trace(go.Bar(x=data['time'],\n",
        "                                y=data['volume'],\n",
        "                                name='Volume',\n",
        "                                marker_color='blue'), row=2, col=1)\n",
        "\n",
        "                        fig.update_layout(title='Candlestick Chart with Volume for ' + ticker,\n",
        "                              yaxis_title='Price',\n",
        "                              xaxis_rangeslider_visible=False,\n",
        "                              xaxis=dict(type='category'))\n",
        "                        # save figure as an html file\n",
        "                        fig.write_html(\"candlestick_chart.html\")\n",
        "\n",
        "                        #fig.show()\n",
        "                        return  data\n",
        "                      polygon_api_key = \"6lpCMsrDOzmm6PPpSkci73RfUvEeU9y_\"\n",
        "                      ######\n",
        "                      results = get_and_visualize_polygon_data(**function_arguments, api_key=polygon_api_key)\n",
        "                return results\n",
        "\n",
        "            messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "            messages.append({\"role\": \"user\", \"content\": content})\n",
        "            response = get_response(messages, functions, self.GPT_MODEL, \"auto\")\n",
        "            res = get_result(messages, response)\n",
        "            if file_exist ==1:\n",
        "              if self.last_file_type == '.mp3':  # Check if the last file processed was MP3\n",
        "                self.text_to_speech(res, 'response.mp3')\n",
        "                return res, 'response.mp3'\n",
        "            return res\n",
        "\n",
        "        # except Exception as e:\n",
        "        #     print(f\"An error occurred while chatting with AI, please try again with: {e}\")\n",
        "\n",
        "    def image_process(self, file_path: str) -> str:\n",
        "        try:\n",
        "            print(\"Image file detected. VisionGPT processing...\")\n",
        "            # OpenAI API Key\n",
        "            api_key = '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'\n",
        "            # Perform VisionGPT processing here\n",
        "            def encode_image(file_path):\n",
        "                with open(file_path, \"rb\") as image_file:\n",
        "                    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "            image_path = file_path\n",
        "            base64_image = encode_image(image_path)\n",
        "\n",
        "            headers = {\n",
        "                \"Content-Type\": \"application/json\",\n",
        "                \"Authorization\": f\"Bearer {api_key}\"\n",
        "            }\n",
        "\n",
        "            payload = {\n",
        "                \"model\": \"gpt-4-vision-preview\",\n",
        "                \"messages\": [\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\n",
        "                                \"type\": \"text\",\n",
        "                                \"text\": \"What’s in this image?\"\n",
        "                            },\n",
        "                            {\n",
        "                                \"type\": \"image_url\",\n",
        "                                \"image_url\": {\n",
        "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                                }\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                ],\n",
        "                \"max_tokens\": 300\n",
        "            }\n",
        "\n",
        "            response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "            response.raise_for_status()  # Raise an exception for any HTTP error status\n",
        "            data_image = response.json()\n",
        "            file_contents = data_image['choices'][0]['message']['content']\n",
        "            print(\"Image processing complete.\")\n",
        "            return file_contents\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing the image: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def pdf_process(self, file_path: str) -> str:\n",
        "        try:\n",
        "            print(\"PDF file detected. Extracting text...\")\n",
        "            with open(file_path, 'rb') as file:\n",
        "                pdf = PyPDF2.PdfReader(file)\n",
        "                file_contents = ''\n",
        "                for page in range(len(pdf.pages)):\n",
        "                    file_contents += pdf.pages[page].extract_text()\n",
        "            print(\"Extraction complete.\")\n",
        "            return file_contents\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing the PDF: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def text_process(self, file_path: str) -> str:\n",
        "        try:\n",
        "            print(\"Text file detected. Extracting text...\")\n",
        "            with open(file_path, 'r') as file:\n",
        "                file_contents = file.read()\n",
        "            print(\"Extraction complete.\")\n",
        "            return file_contents\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing the text file: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def word_process(self, file_path: str) -> str:\n",
        "        try:\n",
        "            print(\"Word document detected. Extracting text...\")\n",
        "            doc = docx.Document(file_path)\n",
        "            file_contents = '\\n'.join([para.text for para in doc.paragraphs])\n",
        "            print(\"Extraction complete.\")\n",
        "            return file_contents\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing the Word document: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def powerpoint_process(self, file_path: str) -> str:\n",
        "        try:\n",
        "            print(\"Powerpoint document detected. Extracting text...\")\n",
        "            # Load the PowerPoint presentation\n",
        "            prs = Presentation(file_path)\n",
        "            # Initialize an empty list to store the extracted lines of text\n",
        "            extracted_lines = []\n",
        "            # Iterate through each slide in the presentation\n",
        "            for slide in prs.slides:\n",
        "                # Iterate through each shape in the slide\n",
        "                for shape in slide.shapes:\n",
        "                    # Check if the shape has text\n",
        "                    if hasattr(shape, \"text\"):\n",
        "                        # Strip leading and trailing spaces from the text\n",
        "                        text = shape.text.strip()\n",
        "                        # Append non-empty lines to the list\n",
        "                        if text:\n",
        "                            extracted_lines.append(text)\n",
        "\n",
        "            # Join the extracted lines into a single string with newlines\n",
        "            file_contents = '\\n'.join(extracted_lines)\n",
        "            print(\"Extraction complete.\")\n",
        "            # Return the extracted text\n",
        "            return file_contents\n",
        "\n",
        "        except Exception as e:\n",
        "            # Print an error message if an exception occurs\n",
        "            print(f\"An error occurred while processing the PowerPoint file: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def speech_process(self, file_path: str) -> str:\n",
        "        try:\n",
        "            print(\"Speech file detected. Processing speech...\")\n",
        "            '''\n",
        "            client = AzureOpenAI(\n",
        "            api_key=\"80ddd1ad72504f2fa226755d49491a61\",\n",
        "            api_version=\"2023-10-01-preview\",\n",
        "            azure_endpoint = \"https://tensurfbrain1.openai.azure.com/\"\n",
        "            )\n",
        "            '''\n",
        "            #deployment_id = \"whisper_001\"\n",
        "            speech= open(file_path, \"rb\")\n",
        "            transcription = self.client.audio.transcriptions.create(\n",
        "            file=speech,\n",
        "            model=self.whisper_model\n",
        "            )\n",
        "            speech_contents = transcription.text\n",
        "            print(\"Speech processing complete.\")\n",
        "            return speech_contents\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing the speech file: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def excel_process(self, file_path: str) -> str:\n",
        "        try:\n",
        "            print(\"Excel file detected. Extracting text...\")\n",
        "            wb = load_workbook(file_path)\n",
        "            file_contents = '\\n'.join([str(cell.value) for sheet in wb.sheetnames for row in wb[sheet].iter_rows() for cell in row if cell.value is not None])\n",
        "            print(\"Extraction complete.\")\n",
        "            return file_contents\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing the Excel file: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def csv_process(self, file_path: str) -> str:\n",
        "        try:\n",
        "            print(\"CSV file detected. Extracting text...\")\n",
        "            with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
        "                csv_reader = csv.reader(file)\n",
        "                file_contents = '\\n'.join(','.join(row) for row in csv_reader)\n",
        "            print(\"Extraction complete.\")\n",
        "            return file_contents\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing the CSV file: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def process_file(self, file_path: str) -> str:\n",
        "        try:\n",
        "            _, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "            self.last_file_type = file_extension.lower()  # Track the type of the last processed file\n",
        "\n",
        "            if file_extension.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']:\n",
        "                return self.image_process(file_path)\n",
        "\n",
        "            elif file_extension.lower() == '.pdf':\n",
        "                return self.pdf_process(file_path)\n",
        "\n",
        "            elif file_extension.lower() == '.txt':\n",
        "                return self.text_process(file_path)\n",
        "\n",
        "            elif file_extension.lower() == '.docx':\n",
        "                return self.word_process(file_path)\n",
        "\n",
        "            elif file_extension.lower() in ['.pptx', '.ppt']:\n",
        "                return self.powerpoint_process(file_path)\n",
        "\n",
        "            elif file_extension.lower() == '.mp3':\n",
        "                return self.speech_process(file_path)\n",
        "\n",
        "            elif file_extension.lower() == '.csv':\n",
        "                return self.csv_process(file_path)\n",
        "\n",
        "            elif file_extension.lower() == '.xlsx':\n",
        "                return self.excel_process(file_path)\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported file format. Please provide an image, PDF, PPT, TXT, DOCX, MP3, XLSX, or other supported file format.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing the file: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def get_content(self, file_path: Optional[str]) -> str:\n",
        "        content = \"\"\n",
        "        try:\n",
        "            if file_path:\n",
        "                file_content = self.process_file(file_path)\n",
        "                content += file_content + \"\\n\"\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while getting content: {e}\")\n",
        "        return content.strip()\n",
        "\n",
        "    def get_user_input(self, file_path: Optional[str], prompt: Optional[str], messages: Optional[list]) -> str:\n",
        "        content = \"\"\n",
        "        file_exist = 0\n",
        "        if file_path:\n",
        "            file_exist = 1\n",
        "            file_content = self.get_content(file_path)\n",
        "            if file_content:\n",
        "                content += file_content + \"\\n\"\n",
        "        if prompt:\n",
        "            content += prompt + \"\\n\"\n",
        "        else:\n",
        "            content += 'what is the main idea?' + '\\n'\n",
        "        return self.chat_with_ai(messages=messages,content=content.strip(), file_exist=file_exist)"
      ],
      "metadata": {
        "id": "EYkryb6kIBNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tZ-NSVoo142H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}