{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkDMcuAkyfpD"
      },
      "outputs": [],
      "source": [
        "# from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "# class CustomCallbackHandler(BaseCallbackHandler):\n",
        "#     def on_tool_start(self, tool_name: str, **kwargs):\n",
        "#         print(f\"Tool {tool_name} started with arguments: {kwargs}\")\n",
        "\n",
        "#     def on_tool_end(self, tool_name: str, output: str, **kwargs):\n",
        "#         print(f\"Tool {tool_name} finished with output: {output}\")\n",
        "\n",
        "#     def on_llm_start(self, **kwargs):\n",
        "#         print(\"LLM started\")\n",
        "\n",
        "#     def on_llm_end(self, output: str, **kwargs):\n",
        "#         print(f\"LLM finished with output: {output}\")\n",
        "\n",
        "# # Example usage\n",
        "# handler = CustomCallbackHandler()\n",
        "\n",
        "# # Simulating some events\n",
        "# handler.on_tool_start(\"example_tool\", arg1=\"value1\", arg2=\"value2\")\n",
        "# handler.on_tool_end(\"example_tool\", output=\"tool output\")\n",
        "# handler.on_llm_start()\n",
        "# handler.on_llm_end(output=\"LLM output\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfknVBncqyyR"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvP4kQpiU3bz",
        "outputId": "d26dee24-dd3e-4160-a891-11fbce810d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Openai in /usr/local/lib/python3.10/dist-packages (1.30.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from Openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from Openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from Openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from Openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from Openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from Openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->Openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->Openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->Openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->Openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->Openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->Openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->Openai) (2.18.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install Openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcrPkYWKEnFJ",
        "outputId": "72269dab-7253-4285-841e-46154c86c9f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libgraphviz-dev is already the newest version (2.42.2-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: pygraphviz in /usr/local/lib/python3.10/dist-packages (1.13)\n"
          ]
        }
      ],
      "source": [
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V8z7XbSFNAh",
        "outputId": "f7f2811e-2d5c-4416-8245-d557639d60f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: zigzag in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: Cython<0.30,>=0.29 in /usr/local/lib/python3.10/dist-packages (from zigzag) (0.29.37)\n",
            "Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from zigzag) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install zigzag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnLtdz5cFwdn",
        "outputId": "702855ca-108f-421a-e1a2-a5aeeba55e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: influxdb_client in /usr/local/lib/python3.10/dist-packages (1.43.0)\n",
            "Requirement already satisfied: reactivex>=4.0.4 in /usr/local/lib/python3.10/dist-packages (from influxdb_client) (4.0.4)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from influxdb_client) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from influxdb_client) (2.8.2)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from influxdb_client) (67.7.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from influxdb_client) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->influxdb_client) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from reactivex>=4.0.4->influxdb_client) (4.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install influxdb_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiiOvTlEm1vz",
        "outputId": "a1cbae7b-05cf-4b99-821d-a3bea4b5765d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (7.34.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (5.10.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (4.9.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (5.7.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import_ipynb) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.18.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import_ipynb) (4.2.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import_ipynb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import_ipynb) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install import_ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZo2S6-jmtdz",
        "outputId": "f5b2508d-ca1e-4f2a-d022-a03753094bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: crewai in /usr/local/lib/python3.10/dist-packages (0.30.11)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.4.4)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai) (8.1.7)\n",
            "Requirement already satisfied: embedchain<0.2.0,>=0.1.98 in /usr/local/lib/python3.10/dist-packages (from crewai) (0.1.104)\n",
            "Requirement already satisfied: instructor<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (0.5.2)\n",
            "Requirement already satisfied: langchain<0.2.0,>=0.1.10 in /usr/local/lib/python3.10/dist-packages (from crewai) (0.1.20)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.30.5)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.7.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.0.1)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /usr/local/lib/python3.10/dist-packages (from crewai) (2023.12.25)\n",
            "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (1.13.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (4.12.3)\n",
            "Requirement already satisfied: chromadb<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (0.5.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (1.52.0)\n",
            "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (0.1.43)\n",
            "Requirement already satisfied: langchain-cohere<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (0.1.5)\n",
            "Requirement already satisfied: langchain-openai<0.2.0,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (0.1.7)\n",
            "Requirement already satisfied: posthog<4.0.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (3.5.0)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (4.2.0)\n",
            "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (0.3.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (13.7.1)\n",
            "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (0.7.7)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (2.0.30)\n",
            "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai) (0.7.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (3.9.5)\n",
            "Requirement already satisfied: docstring-parser<0.16,>=0.15 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (0.15)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (8.3.0)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (0.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (6.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (0.1.67)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (2.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (4.11.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai) (7.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (1.25.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.25.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (3.20.3)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai) (0.46b0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (2.18.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (1.9.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai) (1.3.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai) (1.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain<0.2.0,>=0.1.98->crewai) (2.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.2.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.110.3)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.30.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.18.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.46b0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.64.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (4.1.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (29.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (3.10.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai) (0.9.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai) (1.14.1)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (1.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (23.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (2.0.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain<0.2.0,>=0.1.98->crewai) (5.3.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai) (3.18.2)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai) (5.5.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai) (1.33)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain<0.2.0,>=0.1.98->crewai) (3.0.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (2.0.1)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai) (1.34.117)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai) (1.9.4)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai) (0.4.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai) (2.32.0.20240602)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.37.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (2.7.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (0.13.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai) (2.4)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (3.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai) (0.1.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.12)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.46b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (67.7.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (3.8.1)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.6.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai) (2.1.5)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.117 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai) (1.34.117)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai) (0.10.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (1.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (2023.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (0.6.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install crewai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m7_gzAqnAk7",
        "outputId": "873fb6df-d73b-41a1-e076-2ccc5de3858d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.14.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.12.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.6)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.25.2)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.9.3)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.11.0)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.22.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2024.2.2)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (7.0.1)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (23.2)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (4.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured) (4.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_bBjlk-nErZ",
        "outputId": "26acf72d-db98-4399-8129-80bb61bc1413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.0.51)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.17)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.1.52)\n",
            "Requirement already satisfied: langchain_experimental in /usr/local/lib/python3.10/dist-packages (0.0.58)\n",
            "Requirement already satisfied: uuid6<2025.0.0,>=2024.1.12 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2024.1.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.38)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.67)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.30.5)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.32.0.20240602)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (23.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langchain langchain_openai langchainhub langchain-core langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et1N1I-snLxA",
        "outputId": "9a59a99b-1484-4b4f-cdec-59047d6e6933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sec_api in /usr/local/lib/python3.10/dist-packages (1.0.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from sec_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->sec_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->sec_api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->sec_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->sec_api) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install sec_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1zEYTDlG2iP",
        "outputId": "58576b66-5692-4f41-c332-32f869a99c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.8.0)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.45 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.1.52)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.45->langchain_groq) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.45->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.45->langchain_groq) (0.1.67)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.45->langchain_groq) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.45->langchain_groq) (8.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.45->langchain_groq) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain_groq) (3.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain_groq) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain_groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.45->langchain_groq) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBv2qwKEGp18",
        "outputId": "20ccb73c-c684-4a53-c1cf-d42315033943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.18.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp-I-elhFmoz",
        "outputId": "86b19ed3-93f4-4030-af05-31052d2a1d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/saeid976/researcher\n",
            "  Cloning https://github.com/saeid976/researcher to /tmp/pip-req-build-xbt1qjbq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/saeid976/researcher /tmp/pip-req-build-xbt1qjbq\n",
            "  Resolved https://github.com/saeid976/researcher to commit 5757d943a71a6bfef9371fc0fddf7c3e712c3062\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyMuPDF>=1.23.6 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (1.24.5)\n",
            "Requirement already satisfied: SQLAlchemy>=2.0.28 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (2.0.30)\n",
            "Requirement already satisfied: aiofiles>=23.2.1 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (23.2.1)\n",
            "Requirement already satisfied: arxiv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (2.1.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (4.12.3)\n",
            "Requirement already satisfied: colorama>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.4.6)\n",
            "Requirement already satisfied: duckduckgo_search>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (6.1.4)\n",
            "Requirement already satisfied: fastapi>=0.104.1 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.110.3)\n",
            "Requirement already satisfied: htmldocx<0.0.7,>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.0.6)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (3.1.4)\n",
            "Requirement already satisfied: langchain>=0.0.350 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.1.20)\n",
            "Requirement already satisfied: langchain-google-genai<0.0.12,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.0.11)\n",
            "Requirement already satisfied: langchain-openai<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.1.7)\n",
            "Requirement already satisfied: langchain_community>=0.0.28 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.0.38)\n",
            "Requirement already satisfied: langgraph>=0.0.29 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.0.51)\n",
            "Requirement already satisfied: lxml[html-clean]>=4.9.2 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (4.9.4)\n",
            "Requirement already satisfied: markdown>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (3.6)\n",
            "Requirement already satisfied: md2pdf>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (1.0.1)\n",
            "Requirement already satisfied: mistune<4.0.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (3.0.2)\n",
            "Requirement already satisfied: newspaper3k>=0.2.8 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.2.8)\n",
            "Requirement already satisfied: openai>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (1.30.5)\n",
            "Requirement already satisfied: permchain>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.0.8)\n",
            "Requirement already satisfied: playwright>=1.39.0 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (1.44.0)\n",
            "Requirement already satisfied: pydantic>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (2.7.1)\n",
            "Requirement already satisfied: python-docx<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (1.1.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (1.0.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.0.9)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (2.31.0)\n",
            "Requirement already satisfied: tavily-python>=0.2.8 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.3.3)\n",
            "Requirement already satisfied: uvicorn>=0.24.0.post1 in /usr/local/lib/python3.10/dist-packages (from gpt-researcher==0.0.5) (0.30.1)\n",
            "Requirement already satisfied: feedparser==6.0.10 in /usr/local/lib/python3.10/dist-packages (from arxiv>=2.0.0->gpt-researcher==0.0.5) (6.0.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->gpt-researcher==0.0.5) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->gpt-researcher==0.0.5) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->gpt-researcher==0.0.5) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->gpt-researcher==0.0.5) (2024.2.2)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser==6.0.10->arxiv>=2.0.0->gpt-researcher==0.0.5) (1.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.12.2->gpt-researcher==0.0.5) (2.5)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search>=4.1.1->gpt-researcher==0.0.5) (8.1.7)\n",
            "Requirement already satisfied: pyreqwest-impersonate>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search>=4.1.1->gpt-researcher==0.0.5) (0.4.7)\n",
            "Requirement already satisfied: orjson>=3.10.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search>=4.1.1->gpt-researcher==0.0.5) (3.10.3)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.104.1->gpt-researcher==0.0.5) (0.37.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.104.1->gpt-researcher==0.0.5) (4.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.1.2->gpt-researcher==0.0.5) (2.1.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.350->gpt-researcher==0.0.5) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.350->gpt-researcher==0.0.5) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.350->gpt-researcher==0.0.5) (0.6.6)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.350->gpt-researcher==0.0.5) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.350->gpt-researcher==0.0.5) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.350->gpt-researcher==0.0.5) (0.1.67)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.350->gpt-researcher==0.0.5) (1.25.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.350->gpt-researcher==0.0.5) (8.3.0)\n",
            "Requirement already satisfied: google-generativeai<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (0.4.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai<0.2.0,>=0.1.0->gpt-researcher==0.0.5) (0.7.0)\n",
            "Requirement already satisfied: uuid6<2025.0.0,>=2024.1.12 in /usr/local/lib/python3.10/dist-packages (from langgraph>=0.0.29->gpt-researcher==0.0.5) (2024.1.12)\n",
            "\u001b[33mWARNING: lxml 4.9.4 does not provide the extra 'html-clean'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: WeasyPrint in /usr/local/lib/python3.10/dist-packages (from md2pdf>=1.0.1->gpt-researcher==0.0.5) (62.1)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from md2pdf>=1.0.1->gpt-researcher==0.0.5) (0.6.2)\n",
            "Requirement already satisfied: markdown2 in /usr/local/lib/python3.10/dist-packages (from md2pdf>=1.0.1->gpt-researcher==0.0.5) (2.4.13)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k>=0.2.8->gpt-researcher==0.0.5) (9.4.0)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from newspaper3k>=0.2.8->gpt-researcher==0.0.5) (1.2.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k>=0.2.8->gpt-researcher==0.0.5) (3.8.1)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k>=0.2.8->gpt-researcher==0.0.5) (5.1.2)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from newspaper3k>=0.2.8->gpt-researcher==0.0.5) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k>=0.2.8->gpt-researcher==0.0.5) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k>=0.2.8->gpt-researcher==0.0.5) (2.8.2)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k>=0.2.8->gpt-researcher==0.0.5) (0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3.3->gpt-researcher==0.0.5) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3.3->gpt-researcher==0.0.5) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3.3->gpt-researcher==0.0.5) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3.3->gpt-researcher==0.0.5) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3.3->gpt-researcher==0.0.5) (4.66.4)\n",
            "Requirement already satisfied: greenlet==3.0.3 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.39.0->gpt-researcher==0.0.5) (3.0.3)\n",
            "Requirement already satisfied: pyee==11.1.0 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.39.0->gpt-researcher==0.0.5) (11.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.1->gpt-researcher==0.0.5) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.1->gpt-researcher==0.0.5) (2.18.2)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.3 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF>=1.23.6->gpt-researcher==0.0.5) (1.24.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.24.0.post1->gpt-researcher==0.0.5) (0.14.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.350->gpt-researcher==0.0.5) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.350->gpt-researcher==0.0.5) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.350->gpt-researcher==0.0.5) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.350->gpt-researcher==0.0.5) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.350->gpt-researcher==0.0.5) (1.9.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3.3->gpt-researcher==0.0.5) (1.2.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.350->gpt-researcher==0.0.5) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.350->gpt-researcher==0.0.5) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k>=0.2.8->gpt-researcher==0.0.5) (1.16.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (0.4.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (2.27.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (1.23.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3.3->gpt-researcher==0.0.5) (1.0.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain>=0.0.350->gpt-researcher==0.0.5) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain>=0.0.350->gpt-researcher==0.0.5) (23.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->gpt-researcher==0.0.5) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->gpt-researcher==0.0.5) (2023.12.25)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k>=0.2.8->gpt-researcher==0.0.5) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k>=0.2.8->gpt-researcher==0.0.5) (3.14.0)\n",
            "Requirement already satisfied: pydyf>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (0.10.0)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (1.16.0)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (1.1)\n",
            "Requirement already satisfied: tinycss2>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (1.3.0)\n",
            "Requirement already satisfied: cssselect2>=0.1 in /usr/local/lib/python3.10/dist-packages (from WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (0.7.0)\n",
            "Requirement already satisfied: Pyphen>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (0.15.0)\n",
            "Requirement already satisfied: fonttools[woff]>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (4.51.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2>=0.1->WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (0.5.1)\n",
            "Requirement already satisfied: zopfli>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from fonttools[woff]>=4.0.0->WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (0.2.3)\n",
            "Requirement already satisfied: brotli>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from fonttools[woff]>=4.0.0->WeasyPrint->md2pdf>=1.0.1->gpt-researcher==0.0.5) (1.1.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain>=0.0.350->gpt-researcher==0.0.5) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.350->gpt-researcher==0.0.5) (1.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (1.64.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai<0.0.12,>=0.0.11->gpt-researcher==0.0.5) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/saeid976/researcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVaURl9SEzMm"
      },
      "source": [
        "# Function_call notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q40lkyLGnjWy"
      },
      "outputs": [],
      "source": [
        "# %run functions_python.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QVnAbvAnZIi-"
      },
      "outputs": [],
      "source": [
        "# fc = FunctionCalls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "chkHPIgMZATp"
      },
      "outputs": [],
      "source": [
        "import functions_python\n",
        "import input_filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sqCrGtqPn8zd"
      },
      "outputs": [],
      "source": [
        "# fc = functions_python.FunctionCalls()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScRdMcIrHYZX"
      },
      "source": [
        "# Langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3e30lMEBHFcy"
      },
      "outputs": [],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool\n",
        "from langgraph.prebuilt import ToolExecutor\n",
        "from typing import Optional, Type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlPLaNe4GjgH"
      },
      "source": [
        "## On boarding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "446r9He4Go5K"
      },
      "outputs": [],
      "source": [
        "# !pip install psycopg2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gCKEDbC-ogr2"
      },
      "outputs": [],
      "source": [
        "# import psycopg2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gPAJPkmMGsbX"
      },
      "outputs": [],
      "source": [
        "# class SaveTradingStyle(BaseModel):\n",
        "#     \"\"\"save the style of trading.\"\"\"\n",
        "\n",
        "#     userId: float = Field(..., description=\"user id\")\n",
        "\n",
        "\n",
        "# def trading_style_saver(userId: float) -> str:\n",
        "#     try:\n",
        "#         # Connect to the PostgreSQL server\n",
        "#         conn = psycopg2.connect(\n",
        "#             dbname=\"tensurf\",\n",
        "#             user=\"tensurf\",\n",
        "#             password=\"tensurf\",\n",
        "#             host=\"135.181.158.245\",\n",
        "#             port=\"5432\"\n",
        "#         )\n",
        "\n",
        "#         # Create a cursor object\n",
        "#         cur = conn.cursor()\n",
        "\n",
        "#         trading_style = input(\"What is your trading style (day trader, swing trader, or both)? \")\n",
        "#         cur.execute(\"SELECT COUNT(*) FROM onboarding_user WHERE id = %s\",(userId,))\n",
        "#         count = cur.fetchone()[0]\n",
        "#         if count > 0:\n",
        "#             cur.execute(\"UPDATE onboarding_user SET trading_style=%s WHERE id=%s\",(trading_style, userId))\n",
        "#         else:\n",
        "#             cur.execute(\"INSERT INTO onboarding_user (id,trading_style) values (%s,%s)\", (userId, trading_style))\n",
        "\n",
        "#         conn.commit()\n",
        "#         cur.close()\n",
        "#         conn.close()\n",
        "\n",
        "#         return \"Trading style is saved successfully.\"\n",
        "\n",
        "#     except psycopg2.Error as e:\n",
        "#         return f\"Error in trading_style_saver: {e}\"\n",
        "\n",
        "\n",
        "# databaseStyle = StructuredTool.from_function(\n",
        "#     func=trading_style_saver,\n",
        "#     name=\"SaveTradingStyle\",\n",
        "#     description=\"save the style of trading\",\n",
        "#     args_schema=SaveTradingStyle,\n",
        "#     return_direct=False,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pMvPszfGG0VH"
      },
      "outputs": [],
      "source": [
        "# class SaveRiskPercentage(BaseModel):\n",
        "#     \"\"\"Get the info of the trader about how much risk they take for trading.\"\"\"\n",
        "\n",
        "#     userId: float = Field(..., description=\"user id\")\n",
        "\n",
        "# def risk_percentage_saver(userId) -> str:\n",
        "#     # Save risk percentage to the database\n",
        "#     try:\n",
        "#         # Connect to the PostgreSQL server\n",
        "#         conn = psycopg2.connect(\n",
        "#             dbname=\"tensurf\",\n",
        "#             user=\"tensurf\",\n",
        "#             password=\"tensurf\",\n",
        "#             host=\"135.181.158.245\",\n",
        "#             port=\"5432\"\n",
        "#         )\n",
        "\n",
        "#         # Create a cursor object\n",
        "#         cur = conn.cursor()\n",
        "\n",
        "#         cur.execute(\"SELECT COUNT(*) FROM onboarding_user WHERE id = %s\",(userId,))\n",
        "#         while True:\n",
        "#             percentage = float(input(\"What is the maximum percentage of your capital that you want to risk in trade (0-100)? \"))\n",
        "#             if 0 <= percentage <= 100:\n",
        "#                 break\n",
        "#             else:\n",
        "#                 print(\"Please enter a positive float number between 0 and 100.\")\n",
        "#         count = cur.fetchone()[0]\n",
        "#         if count > 0:\n",
        "#             cur.execute(\"UPDATE onboarding_user SET risk_parameter=%s WHERE id=%s\",(percentage, userId))\n",
        "#         else:\n",
        "#             cur.execute(\"INSERT INTO onboarding_user (id,risk_parameter) values (%s,%s)\", (userId, percentage))\n",
        "\n",
        "#         # Commit the transaction\n",
        "#         conn.commit()\n",
        "#         cur.close()\n",
        "#         conn.close()\n",
        "\n",
        "#         return \"percentage of risk is saved successfully.\"\n",
        "\n",
        "#     except psycopg2.Error as e:\n",
        "#         return f\"Error in risk_percentage_saver: {e}\"\n",
        "\n",
        "\n",
        "# databaseRisk = StructuredTool.from_function(\n",
        "#     func=risk_percentage_saver,\n",
        "#     name=\"SaveRiskPercentage\",\n",
        "#     description=\"Get the info of the trader about how much risk they take for trading.\",\n",
        "#     args_schema=SaveRiskPercentage,\n",
        "#     return_direct=False,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5mB3KvXDG06h"
      },
      "outputs": [],
      "source": [
        "# def check_user_id():\n",
        "#     try:\n",
        "#         # Connect to the PostgreSQL server\n",
        "#         conn = psycopg2.connect(\n",
        "#             dbname=\"tensurf\",\n",
        "#             user=\"tensurf\",\n",
        "#             password=\"tensurf\",\n",
        "#             host=\"135.181.158.245\",\n",
        "#             port=\"5432\"\n",
        "#         )\n",
        "\n",
        "#         # Create a cursor object\n",
        "#         cur = conn.cursor()\n",
        "#         user_id = input(\"What is your id?\")\n",
        "#         # Query to check if the user_id exists in the table\n",
        "#         cur.execute(\"SELECT COUNT(*) FROM onboarding_user WHERE id = %s\",(user_id,))\n",
        "#         count = cur.fetchone()[0]\n",
        "\n",
        "#         if count > 0:\n",
        "#           return user_id\n",
        "\n",
        "#         else:\n",
        "#           return f\"User with user_id= {user_id} does not exist in the table.\"\n",
        "\n",
        "#     except psycopg2.Error as e:\n",
        "#       return f\"Error in check_user_id: {e}\"\n",
        "\n",
        "# databaseId = StructuredTool.from_function(\n",
        "#     func=check_user_id,\n",
        "#     name=\"CheckUserId\",\n",
        "#     description=\"Checking the id of the user\",\n",
        "#     return_direct=False,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "behgQf7V1wNk"
      },
      "source": [
        "## Calculate Stop Loss:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "enrMEMS7HaTe"
      },
      "outputs": [],
      "source": [
        "class PropertiesCalculateSl(BaseModel):\n",
        "\tsymbol: Optional[list] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\n",
        "\tmethod: Optional[str] = Field(None, description=\"shows the method of SL calculation.\")\n",
        "\n",
        "\tdirection: Optional[int] = Field(None, description=\"-1: means the user want to calculate stoploss for a short position. 1: means the user want to calculate stoploss for a long position\")\n",
        "\n",
        "\tlookback: Optional[int] = Field(None, description=\"it is used when the method is set to 'minmax' and shows the number of candles that the SL is calculated based on them.\")\n",
        "\n",
        "\tneighborhood: Optional[int] = Field(None, description=\"A parameter that is used in the swing method to define the range or window within which swings are detected. example: \\\n",
        "If the 'neighborhood' parameter is set to 3, it means that the swing detection is based on considering 3 candles to the \\\n",
        "left and 3 candles to the right of the swing point.\")\n",
        "\n",
        "\tatr_coef: Optional[int] = Field(None, description=\"it is used if the method is 'atr' and shows the coefficient of atr\")\n",
        "\n",
        "\n",
        "class CalculateSL(BaseTool):\n",
        "\tname = \"calculate_sl\"\n",
        "\tdescription = \"\"\"Stoploss (SL) is a limitation for potential losses in a position. It's below the current price for long position and above it for short position. \\\n",
        "Distance between the SL and current price is named risk value. This function calculates the SL based o some different methods. \\\n",
        "Returns A dictionary same as this: \\\n",
        "{'sl': [17542.5], 'risk': [268.5], 'info': ['calculated based on maximum high price of previous 100 candles']} \\\n",
        "which includes sl value, risk on the trade and an information. \\\n",
        "If user don't select any method for sl calculation or select \"level\" method, or zigzag method the otput can include \\\n",
        "more than one stoploss and the values type in the output can be a list such as this \\\n",
        "{'sl': [17542.5, 17818.25, 17858.5, 17882.5, 18518.75], 'risk': [268.5, 7.25, 47.5, 71.5, 707.75], 'info': ['minmax', 'swing', 'atr', '5min_SR', 'daily_SR']} \\\n",
        "It includes a list of stoplosses and the risk on them and finally the level or method name of stoploss.\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesCalculateSl\n",
        "\n",
        "\tdef _run(\n",
        "        self, symbol: str = None, method: str = None, direction: int = None,\n",
        "\t\tlookback: int = None, neighborhood: int = None, atr_coef: int = None\n",
        "    ) -> int:\n",
        "\n",
        "\t\tparameters = {\n",
        "                      \"symbol\": symbol,\n",
        "                      \"method\": method,\n",
        "                      \"direction\": direction,\n",
        "                      \"lookback\": lookback,\n",
        "                      \"neighborhood\": neighborhood,\n",
        "                      \"atr_coef\": atr_coef\n",
        "\t\t\t\t\t\t\t\t\t\t\t}\n",
        "\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\n",
        "\t\treturn fc.calculate_sl(parameters)\n",
        "\n",
        "SL = CalculateSL()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EciRRD4YELCo"
      },
      "source": [
        "## Calculate Take-Profit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JianU1wXGZL3"
      },
      "outputs": [],
      "source": [
        "class PropertiesCalculateTp(BaseModel):\n",
        "\tsymbol: Optional[list] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\n",
        "\tdirection: Optional[int] = Field(None, description=\"-1: means the user want to calculate stoploss for a short position. 1: means the user want to calculate stoploss for a long position\")\n",
        "\n",
        "\tstoploss: Optional[int] = Field(None, description=\"the value for stoploss\")\n",
        "\n",
        "\n",
        "class CalculateTp(BaseTool):\n",
        "\tname = \"calculate_tp\"\n",
        "\tdescription = \"\"\"Take profit (TP) is opposite of the stop-loss (SL) and is based on maximum reward that we intend to achieve from a trade. \\\n",
        "It represents the price level at which a trader aims to close a position to secure profits before the market reverses. \\\n",
        "Returns list of price for take-profit and information for each price For exampe: \\\n",
        "{'tp': [5139.25, 5140.25, 5144.0], 'info': ['calculated based on the level VWAP_Top_Band_2', 'calculated based on the level Overnight_high', 'calculated based on the level VWAP_Top_Band_3']}\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesCalculateTp\n",
        "\n",
        "\tdef _run(\n",
        "        self, symbol: str = None, direction: int = None, stoploss: int = None\n",
        "    ) -> int:\n",
        "\t\tparameters = {\n",
        "\t\t\t\t\t\t\"symbol\": symbol,\n",
        "\t\t\t\t\t\t\"direction\": direction,\n",
        "\t\t\t\t\t\t\"stoploss\": stoploss\n",
        "\t\t\t\t\t\t}\n",
        "\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\n",
        "\t\treturn fc.calculate_tp(parameters)\n",
        "\n",
        "TP = CalculateTp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt4sSmAQH1Ph"
      },
      "source": [
        "## Trend Detection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZM38gBSZEjBk"
      },
      "outputs": [],
      "source": [
        "class PropertiesCalculateTrend(BaseModel):\n",
        "\tsymbol: Optional[list] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\n",
        "\tstart_datetime: Optional[str] = Field(None, description=\"The start timestamp of period over which the analysis is done. \\\n",
        "\tThe format of the date should be in the following format %b-%d-%y %H:%M:%S like this example: May-1-2024 13:27:49\")\n",
        "\tend_datetime: Optional[str] = Field(None, description=\"The end timestamp of period over which the analysis is done. \\\n",
        "\tThe format of the date should be in the following format %b-%d-%y %H:%M:%S like this example: May-1-2024 13:27:49. \\\n",
        "\tThe user can set this parameter to now. In this situation this parameter's value is the current date time.\")\n",
        "\n",
        "\tlookback: Optional[str] = Field(None, description=\"The number of seconds, minutes, hours, days, weeks, months or years to look back for calculating the trend of the given symbol. \\\n",
        "This parameter determines the depth of historical data to be considered in the analysis. The format of this value must obey one of the following examples: 30 seconds, 10 minutes, 2 hours, 5 days, 3 weeks, 2 months and 3 years. \\\n",
        "Either start_datetime along with end_datetime should be specified or lookback should be specified but both cases should not happen simultaneously.\")\n",
        "\n",
        "class CalculateTrend(BaseTool):\n",
        "\tname = \"detect_trend\"\n",
        "\tdescription = \"\"\"Analyzes the trend of a specified financial instrument over a given time range. \\\n",
        "It is designed primarily for financial data analysis, enabling users to gauge the general direction of a security or market index. \\\n",
        "Whether start_datetime with end_datetime, end_datetime with lookback or lookback parameters could be valued for determining the period over which's trend wants to be detected. \\\n",
        "The function returns a numerical value that indicates the trend intensity and direction within the specified parameters. \\\n",
        "Returns a number between -3 and 3 that represents the trends intensity and direction. The value is interpreted as follows: \\\n",
        "\\n -3: strong bearish (downward) trend \\\n",
        "\\n -2: moderate bearish (downward) trend \\\n",
        "\\n -1: mild bearish (downward) trend \\\n",
        "\\n 0: without significant trend \\\n",
        "\\n 3: strong bullish (upward) trend \\\n",
        "\\n 2: moderate bullish (upward) trend \\\n",
        "\\n 1: mild bullish (upward) trend\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesCalculateTrend\n",
        "\n",
        "\tdef _run(\n",
        "\t\t\tself, symbol: str = None, start_datetime: str = None, end_datetime: str = None, lookback: str = None\n",
        "    ) -> dict:\n",
        "\n",
        "\t\tfunction_arguments = {\n",
        "\t\t\t\t\t\t\"symbol\": symbol,\n",
        "\t\t\t\t\t\t\"start_datetime\": start_datetime,\n",
        "\t\t\t\t\t\t\"end_datetime\": end_datetime,\n",
        "\t\t\t\t\t\t\"lookback\": lookback\n",
        "\t\t\t\t\t\t}\n",
        "\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\n",
        "\t\treturn fc.detect_trend(function_arguments)\n",
        "\n",
        "\n",
        "Trend = CalculateTrend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AahZLwrkH-G-"
      },
      "source": [
        "## Calculate Support and Resistance Levels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gv2RBUw3H6s_"
      },
      "outputs": [],
      "source": [
        "class PropertiesCalculateSR(BaseModel):\n",
        "\tsymbol: Optional[list] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\ttimeframe: Optional[str] = Field(None, description=\"Specifies the timeframe of the candlestick chart to be analyzed. \\\n",
        "\tThis parameter defines the granularity of the data used for calculating the levels. The only allowed formats would like 3h, 20min, 1d.\")\n",
        "\tlookback_days: Optional[str] = Field(None, description=\"The number of days to look back for calculating the support and resistance levels. \\\n",
        "This parameter determines the depth of historical data to be considered in the analysis. (e.g. 10 days)\")\n",
        "\n",
        "class CalculateSR(BaseTool):\n",
        "\tname = \"calculate_sr\"\n",
        "\tdescription = \"\"\"Support and resistance levels represent price points on a chart where the odds favor a pause or reversal of a prevailing trend. \\\n",
        "This function analyzes candlestick charts over a specified timeframe and lookback period to calculate these levels and their respective strengths. \\\n",
        "Returns a dictionary containing five lists, each corresponding to a specific aspect of the calculated support and resistance levels: \\\n",
        "1. levels_prices (list of floats): The prices at which support and resistance levels have been identified. \\\n",
        "2. levels_start_timestamps (list of timestamps) \\\n",
        "3. levels_detect_timestamps (list of timestamps) \\\n",
        "4. levels_end_timestamps (list of timestamps) \\\n",
        "5. levels_scores (list of floats): Scores associated with each level, indicating the strength or significance of the level. Higher scores typically imply stronger levels.\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesCalculateSR\n",
        "\n",
        "\tdef _run(\n",
        "\t\t\tself, symbol: str = None, timeframe: str = None, lookback_days: str = None\n",
        "    ) -> dict:\n",
        "\t\tparameters = {\n",
        "\t\t\t\t\t\t\"symbol\": symbol,\n",
        "\t\t\t\t\t\t\"timeframe\": timeframe,\n",
        "\t\t\t\t\t\t\"lookback_days\": lookback_days\n",
        "\t\t\t\t\t\t}\n",
        "\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\n",
        "\t\treturn fc.calculate_sr(parameters)\n",
        "\n",
        "SR = CalculateSR()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALEtGCoWoI_2"
      },
      "source": [
        "## Bias detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xj0NnY7OoRtF"
      },
      "outputs": [],
      "source": [
        "class PropertiesBiasDetection(BaseModel):\n",
        "\tsymbol: Optional[list] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\n",
        "\tmethod: Optional[str] = Field(None, description=\"The user can choose from different methods including MC, Zigzag trend, \\\n",
        "Trend detection, weekly wvap, candle stick pattern, cross ma, vp detection ,power & counter ratio.\")\n",
        "\n",
        "class BiasDetection(BaseTool):\n",
        "\tname = \"bias_detection\"\n",
        "\tdescription = \"\"\"Detecting trading bias through different methods or Detecting the appropriate entry point for a long or short trade.\n",
        "Returns a number between -3 and 3 that represents the trends intensity and direction. The value is interpreted as follows:\n",
        "-3: Strong downward , -2: downward -1: Weak downward, 0: No significant trend / Neutral, 1: Weak upward, 2.upward, 3: Strong upward\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesBiasDetection\n",
        "\n",
        "\tdef _run(\n",
        "        self, symbol: str = None, method: str = None\n",
        "    ) -> dict:\n",
        "\n",
        "\t\tparameters = {\n",
        "\t\t\t\t\t\t\"symbol\": symbol,\n",
        "\t\t\t\t\t\t\"method\": method\n",
        "\t\t\t\t\t\t}\n",
        "\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\n",
        "\t\treturn fc.get_bias(parameters)\n",
        "\n",
        "Bias = BiasDetection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwjkTlbXlsgC"
      },
      "source": [
        "## Financial tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tPZezZDc4HaZ"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['AZURE_EMBEDDING_MODEL'] ='embedding-ada-002'\n",
        "# os.environ['LLM_PROVIDER'] = 'groq'\n",
        "# os.environ[\"AZURE_OPENAI_API_KEY\"] =  \"80ddd1ad72504f2fa226755d49491a61\"\n",
        "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://tensurfbrain1.openai.azure.com/\"\n",
        "# os.environ[\"OPENAI_API_VERSION\"] = \"2023-10-01-preview\"\n",
        "# os.environ['EMBEDDING_PROVIDER']='azureopenai'\n",
        "# os.environ['SMART_LLM_MODEL']='llama3-70b-8192'\n",
        "# os.environ['TAVILY_API_KEY']='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'\n",
        "# os.environ['GROQ_API_KEY'] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6BLvYUSu9cJs"
      },
      "outputs": [],
      "source": [
        "# from gpt_researcher import GPTResearcher\n",
        "# import asyncio\n",
        "# from dotenv import load_dotenv\n",
        "# import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2pgbq2vu9c2W"
      },
      "outputs": [],
      "source": [
        "# query = \"what day is today?\"\n",
        "# report_type = \"research_report\"\n",
        "\n",
        "# researcher = GPTResearcher(query, report_type)\n",
        "# report = await researcher.conduct_research()\n",
        "# report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7_Y5zF-Ol0oi"
      },
      "outputs": [],
      "source": [
        "# from langchain.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
        "# from langchain.text_splitter            import CharacterTextSplitter\n",
        "# from langchain.embeddings               import AzureOpenAIEmbeddings\n",
        "# from langchain_community.vectorstores   import FAISS\n",
        "# from unstructured.partition.html        import partition_html\n",
        "# from sec_api                            import QueryApi\n",
        "# import requests\n",
        "# import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "k1sZSRy4cGWU"
      },
      "outputs": [],
      "source": [
        "# api_type = \"azure\"\n",
        "# api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "# api_version = '2023-10-01-preview'\n",
        "# api_key = '80ddd1ad72504f2fa226755d49491a61'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Uj86R_SODN7t"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IojgHYsIDP7j"
      },
      "outputs": [],
      "source": [
        "# api_type = \"azure\"\n",
        "# api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "# api_version = '2023-10-01-preview'\n",
        "# api_key = '80ddd1ad72504f2fa226755d49491a61'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Z4wONgm_DpdO"
      },
      "outputs": [],
      "source": [
        "# client = AzureOpenAI(\n",
        "#     api_key=api_key,\n",
        "#     api_version=api_version,\n",
        "#     azure_endpoint=api_endpoint\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qNPoFrgXDVvZ"
      },
      "outputs": [],
      "source": [
        "# def generate_embeddings(text, model='embedding-ada-002'):\n",
        "#   return client.embeddings.create(input = [text], model=model).data[0].embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXLc0iHYZ48v"
      },
      "source": [
        "### Search tools:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "280xJBiDmFrH"
      },
      "outputs": [],
      "source": [
        "# class PropertiesSearchTheInternet(BaseModel):\n",
        "#     query: str = Field(..., description=\"A random topic that will be searched on the internet\")\n",
        "\n",
        "\n",
        "# class SearchTheInternet(BaseTool):\n",
        "#     name = \"SearchTheInternet\"\n",
        "#     description = \"\"\"Useful to search the internet about a a given topic and return relevant results\"\"\"\n",
        "\n",
        "#     args_schema: Type[BaseModel] = PropertiesSearchTheInternet\n",
        "\n",
        "#     def _run(\n",
        "#         self, query: str\n",
        "#     ) -> dict:\n",
        "#             top_result_to_return = 4\n",
        "#             url = \"https://google.serper.dev/search\"\n",
        "#             payload = json.dumps({\"q\": query})\n",
        "#             headers = {\n",
        "#                 'X-API-KEY': '77976766163a61a4bae1ed8672ae79e916955783',\n",
        "#                 'content-type': 'application/json'\n",
        "#             }\n",
        "#             response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "#             results = response.json()['organic']\n",
        "#             string = []\n",
        "#             for result in results[:top_result_to_return]:\n",
        "#               try:\n",
        "#                 string.append('\\n'.join([\n",
        "#                     f\"Title: {result['title']}\", f\"Link: {result['link']}\",\n",
        "#                     f\"Snippet: {result['snippet']}\", \"\\n-----------------\"\n",
        "#                 ]))\n",
        "#               except KeyError:\n",
        "#                 next\n",
        "\n",
        "#             return '\\n'.join(string)\n",
        "\n",
        "# SearchInternet = SearchTheInternet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "J6Ou8CTPZIp9"
      },
      "outputs": [],
      "source": [
        "# SearchInternet.run(\"Apple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EawXSHEOXRFq"
      },
      "outputs": [],
      "source": [
        "# class PropertiesSearchNews(BaseModel):\n",
        "#     query: str = Field(..., description=\"A random topic that will be searched on the internet\")\n",
        "\n",
        "\n",
        "# class SearchNews(BaseTool):\n",
        "#     name = \"SearchNews\"\n",
        "#     description = \"\"\"Useful to search news about a company, stock or any other topic and return relevant results\"\"\"\n",
        "\n",
        "#     args_schema: Type[BaseModel] = PropertiesSearchNews\n",
        "\n",
        "#     def _run(\n",
        "#         self, query: str\n",
        "#     ) -> dict:\n",
        "#             top_result_to_return = 4\n",
        "#             url = \"https://google.serper.dev/news\"\n",
        "#             payload = json.dumps({\"q\": query})\n",
        "#             headers = {\n",
        "#                 'X-API-KEY': '77976766163a61a4bae1ed8672ae79e916955783',\n",
        "#                 'content-type': 'application/json'\n",
        "#             }\n",
        "#             response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "#             results = response.json()['news']\n",
        "#             string = []\n",
        "#             for result in results[:top_result_to_return]:\n",
        "#               try:\n",
        "#                 string.append('\\n'.join([\n",
        "#                     f\"Title: {result['title']}\", f\"Link: {result['link']}\",\n",
        "#                     f\"Snippet: {result['snippet']}\", \"\\n-----------------\"\n",
        "#                 ]))\n",
        "#               except KeyError:\n",
        "#                 next\n",
        "\n",
        "#             return '\\n'.join(string)\n",
        "\n",
        "# NewsSearch = SearchNews()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nNVEG3bmZzf0"
      },
      "outputs": [],
      "source": [
        "# NewsSearch.run(\"NQ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etCFxbh3Z8iv"
      },
      "source": [
        "### SECTools:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TvUHS5EHbzb2"
      },
      "outputs": [],
      "source": [
        "# def download_form_html(url):\n",
        "#   headers = {\n",
        "#     'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
        "#     'Accept-Encoding': 'gzip, deflate, br',\n",
        "#     'Accept-Language': 'en-US,en;q=0.9,pt-BR;q=0.8,pt;q=0.7',\n",
        "#     'Cache-Control': 'max-age=0',\n",
        "#     'Dnt': '1',\n",
        "#     'Sec-Ch-Ua': '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\"',\n",
        "#     'Sec-Ch-Ua-Mobile': '?0',\n",
        "#     'Sec-Ch-Ua-Platform': '\"macOS\"',\n",
        "#     'Sec-Fetch-Dest': 'document',\n",
        "#     'Sec-Fetch-Mode': 'navigate',\n",
        "#     'Sec-Fetch-Site': 'none',\n",
        "#     'Sec-Fetch-User': '?1',\n",
        "#     'Upgrade-Insecure-Requests': '1',\n",
        "#     'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
        "#   }\n",
        "\n",
        "#   response = requests.get(url, headers=headers)\n",
        "\n",
        "#   return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Pl1QuMSZb2sL"
      },
      "outputs": [],
      "source": [
        "# def embedding_search(url, ask):\n",
        "#   text = download_form_html(url)\n",
        "#   elements = partition_html(text=text)\n",
        "#   content = \"\\n\".join([str(el) for el in elements])\n",
        "#   text_splitter = CharacterTextSplitter(\n",
        "#       separator = \"\\n\",\n",
        "#       chunk_size = 1000,\n",
        "#       chunk_overlap  = 150,\n",
        "#       length_function = len,\n",
        "#       is_separator_regex = False,\n",
        "#   )\n",
        "#   docs = text_splitter.create_documents([content])\n",
        "#   retriever = FAISS.from_documents(\n",
        "#       docs, AzureOpenAIEmbeddings()\n",
        "#     ).as_retriever()\n",
        "#   retriever = FAISS.from_documents(\n",
        "#     docs, client.embeddings\n",
        "#   ).as_retriever()\n",
        "#   answers = retriever.get_relevant_documents(ask, top_k=4)\n",
        "#   answers = \"\\n\\n\".join([a.page_content for a in answers])\n",
        "\n",
        "#   return answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CbRpT87iaNZy"
      },
      "outputs": [],
      "source": [
        "# class PropertiesSearch10q(BaseModel):\n",
        "#     stock: str = Field(..., description=\"A random stock.\")\n",
        "#     ask: str = Field(..., description=\"Question from the 10-Q of the stock\")\n",
        "\n",
        "\n",
        "# class Search10q(BaseTool):\n",
        "#     name = \"Search10q\"\n",
        "#     description = \"\"\"Useful to search information from the latest 10-Q form for a given stock.\n",
        "#                      The input to this tool should be a pipe (|) separated text of\n",
        "#                      length two, representing the stock ticker you are interested and what\n",
        "#                      question you have from it.\n",
        "#                      For example, `AAPL|what was last quarter's revenue`.\"\"\"\n",
        "\n",
        "#     args_schema: Type[BaseModel] = PropertiesSearch10q\n",
        "\n",
        "#     def _run(\n",
        "#         self, stock: str, ask: str\n",
        "#     ) -> dict:\n",
        "#             queryApi = QueryApi(api_key=\"befd094ddadf6a9e080bf194b6d9197e753ec1d4226fc8e595ed717b2f1bc3a5\")\n",
        "#             query = {\n",
        "#               \"query\": {\n",
        "#                 \"query_string\": {\n",
        "#                   \"query\": f\"ticker:{stock} AND formType:\\\"10-Q\\\"\"\n",
        "#                 }\n",
        "#               },\n",
        "#               \"from\": \"0\",\n",
        "#               \"size\": \"1\",\n",
        "#               \"sort\": [{ \"filedAt\": { \"order\": \"desc\" }}]\n",
        "#             }\n",
        "\n",
        "#             fillings = queryApi.get_filings(query)['filings']\n",
        "#             if len(fillings) == 0:\n",
        "#               return \"Sorry, I couldn't find any filling for this stock, check if the ticker is correct.\"\n",
        "#             link = fillings[0]['linkToFilingDetails']\n",
        "#             answer = embedding_search(link, ask)\n",
        "#             return answer\n",
        "\n",
        "# TenQ = Search10q()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zpdtHTRAcJ72"
      },
      "outputs": [],
      "source": [
        "# TenQ.run({\"stock\":\"AAPL\", \"ask\":\"what was last quarter's revenue.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "g4Qb73vldAkP"
      },
      "outputs": [],
      "source": [
        "# class PropertiesSearch10k(BaseModel):\n",
        "#     stock: str = Field(..., description=\"A random stock.\")\n",
        "#     ask: str = Field(..., description=\"Question from the 10-k of the stock\")\n",
        "\n",
        "\n",
        "# class Search10k(BaseTool):\n",
        "#     name = \"Search10k\"\n",
        "#     description = \"\"\"Useful to search information from the latest 10-K form for a given stock.\n",
        "#                      The input to this tool should be a pipe (|) separated text of\n",
        "#                      length two, representing the stock ticker you are interested, what\n",
        "#                      question you have from it.\n",
        "#                      For example, `AAPL|what was last year's revenue`.\"\"\"\n",
        "\n",
        "#     args_schema: Type[BaseModel] = PropertiesSearch10k\n",
        "\n",
        "#     def _run(\n",
        "#         self, stock: str, ask: str\n",
        "#     ) -> dict:\n",
        "#             queryApi = QueryApi(api_key=\"befd094ddadf6a9e080bf194b6d9197e753ec1d4226fc8e595ed717b2f1bc3a5\")\n",
        "#             query = {\n",
        "#               \"query\": {\n",
        "#                 \"query_string\": {\n",
        "#                   \"query\": f\"ticker:{stock} AND formType:\\\"10-K\\\"\"\n",
        "#                 }\n",
        "#               },\n",
        "#               \"from\": \"0\",\n",
        "#               \"size\": \"1\",\n",
        "#               \"sort\": [{ \"filedAt\": { \"order\": \"desc\" }}]\n",
        "#             }\n",
        "\n",
        "#             fillings = queryApi.get_filings(query)['filings']\n",
        "#             if len(fillings) == 0:\n",
        "#               return \"Sorry, I couldn't find any filling for this stock, check if the ticker is correct.\"\n",
        "#             link = fillings[0]['linkToFilingDetails']\n",
        "#             answer = embedding_search(link, ask)\n",
        "#             return answer\n",
        "\n",
        "# Tenk = Search10k()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhFk82hXFm2b"
      },
      "source": [
        "## Openai utilites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rivfZPicJUKb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "W16S_ST_JQA0"
      },
      "outputs": [],
      "source": [
        "# api_type = \"azure\"\n",
        "# api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "# api_version = '2023-10-01-preview'\n",
        "# api_key = '80ddd1ad72504f2fa226755d49491a61'\n",
        "# client = AzureOpenAI(\n",
        "#     api_key= api_key,\n",
        "#     api_version= api_version,\n",
        "#     azure_endpoint= api_endpoint\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JHliSi6UsYzU"
      },
      "outputs": [],
      "source": [
        "# class ChatWithOpenai:\n",
        "# \tdef __init__(self, system_message, model, temperature, max_tokens, client, default_user_messages=None):\n",
        "# \t\tself.system_message = system_message\n",
        "# \t\tself.model = model\n",
        "# \t\tself.temperature = temperature\n",
        "# \t\tself.max_tokens = max_tokens\n",
        "# \t\tself.client = client\n",
        "# \t\tself.messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "# \t\tif default_user_messages:\n",
        "# \t\t\tfor user_message in default_user_messages:\n",
        "# \t\t\t\tself.messages += [{\"role\": \"user\", \"content\": user_message}]\n",
        "\n",
        "# \tdef chat(self, user_input):\n",
        "# \t\tresponse = self.client.chat.completions.create(\n",
        "# \t\t\tmodel=self.model,\n",
        "# \t\t\tmessages=self.messages + user_input,\n",
        "# \t\t\ttemperature=self.temperature,\n",
        "# \t\t\tmax_tokens=self.max_tokens\n",
        "# \t\t)\n",
        "# \t\treturn response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EviWbdxLbylh"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "\n",
        "groq_api1 = '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'\n",
        "client1 = Groq(api_key = groq_api1)\n",
        "\n",
        "groq_api2 = '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'\n",
        "client2 = Groq(api_key = groq_api2)\n",
        "\n",
        "groq_api3 = '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'\n",
        "client3 = Groq(api_key = groq_api3)\n",
        "\n",
        "MODEL1 = 'llama3-70b-8192'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PFlhfvJ9b0Kt"
      },
      "outputs": [],
      "source": [
        "from openai import AzureOpenAI\n",
        "\n",
        "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "api_version = '2023-10-01-preview'\n",
        "api_key1 = '80ddd1ad72504f2fa226755d49491a61'\n",
        "api_key2 = '4a342430ad17498da149a9b77bf4c51f'\n",
        "\n",
        "client4 = AzureOpenAI(\n",
        "    api_key= api_key1,\n",
        "    api_version= api_version,\n",
        "    azure_endpoint= api_endpoint\n",
        ")\n",
        "\n",
        "client5 = AzureOpenAI(\n",
        "    api_key= api_key2,\n",
        "    api_version= api_version,\n",
        "    azure_endpoint= api_endpoint\n",
        ")\n",
        "\n",
        "MODEL2 = 'gpt_35_16k'\n",
        "MODEL3 = 'gpt_4_32k'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UDiNTy9MbZOg"
      },
      "outputs": [],
      "source": [
        "clients = [client1, client2, client3, client4, client5]\n",
        "models = [MODEL1, MODEL1, MODEL1, MODEL2, MODEL3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9TQMmI0LaVa5"
      },
      "outputs": [],
      "source": [
        "class ChatWithOpenai:\n",
        "    def __init__(self, system_message, temperature, models, clients, max_tokens, default_user_messages=None):\n",
        "        self.system_message = system_message\n",
        "        self.models = models\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "        self.clients = clients\n",
        "        self.messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "        if default_user_messages:\n",
        "            for user_message in default_user_messages:\n",
        "                self.messages += [{\"role\": \"user\", \"content\": user_message}]\n",
        "\n",
        "    def chat(self, user_input):\n",
        "        for client, model in zip(self.clients, self.models):\n",
        "            try:\n",
        "                response = client.chat.completions.create(\n",
        "                  model=model,\n",
        "                  messages=self.messages + user_input,\n",
        "                  temperature=self.temperature,\n",
        "                  max_tokens=self.max_tokens,\n",
        "                  stream=True\n",
        "                )\n",
        "                print(f\"client{self.clients.index(client)+1} has worked\")\n",
        "                return response.choices[0].message.content\n",
        "            except Exception as e:\n",
        "              print(f\"Error with client: client {self.clients.index(client)+1}. Exception: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr_s_UHkFGCT"
      },
      "source": [
        "## Irrelevant handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "v5b3pyZJNYl3"
      },
      "outputs": [],
      "source": [
        "# message = \"'check the grammer for me?'\"\n",
        "# user_input = [{\"role\": \"user\", \"content\": message}]\n",
        "# handler_zero_openai.chat(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "T6nK6QWyOlx-"
      },
      "outputs": [],
      "source": [
        "# Handler.run(\"check the grammer for me?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GvR7waNZrJSZ"
      },
      "outputs": [],
      "source": [
        "default_message = [\"Check the following text for greeting words and do as the system message said.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ry7DgJSZQT0g"
      },
      "outputs": [],
      "source": [
        "handler_zero_openai = ChatWithOpenai(system_message=\"You are an assistant. Your job is to check the user input Not answer it.\\\n",
        "If the user input contains greeting words like hello, hi, and so on, \\\n",
        "then you should remove these words. \\\n",
        "Note that the final response is either the input with the greeting word removed, \\\n",
        "or None if the input consists only of a greeting word. \\\n",
        "if there is no greeting word in the input, the response is the last user input itself \\\n",
        "without any changes. \\\n",
        "No other responses are possible. \\\n",
        "Here are some examples and the valid responses: \\\n",
        "Example 1 (when there is no greeting word): \\\n",
        "{ input: What is the weather? response: What is the weather? } \\\n",
        "Example 2 (when there is a greeting word): \\\n",
        "{ input: Hi can you speak French? response: Can you speak French? } \\\n",
        "Example 3 (when there is just one or more greeting words): \\\n",
        "{ input: Hello. response: None } \\\n",
        "Note that you are not permitted to answer user requests directly. \\\n",
        "Only perform the tasks instructed by system messages.\",\n",
        "\n",
        "                                      default_user_messages=default_message,\n",
        "                                      models=models,\n",
        "                                      temperature=0.2,\n",
        "                                      max_tokens=100,\n",
        "                                      clients=clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dx8bLNJsCY0U"
      },
      "outputs": [],
      "source": [
        "handler_one_openai = ChatWithOpenai(system_message=\"You are an assistant. Your job is to check the user input, not answer it. \\\n",
        "We are a system with the name 'Tensurf Brain' or 'Tensurf'. \\\n",
        "If the user needs any information about us or needs a tutorial for \\\n",
        "how our system is working, your job is to detect these scenarios and respond with 'True'. \\\n",
        "If the user asks about you, the answer is also 'True'. \\\n",
        "Also, when the user is confused and doesn't know how to start or what to do, \\\n",
        "the answer is also 'True'. \\\n",
        "For any other input that doesn't classify in the tutorial or information \\\n",
        "about 'Tensurf Brain' or 'Tensurf' you should return false. \\\n",
        "Note that you are not permitted to answer user requests directly. \\\n",
        "Only perform the tasks instructed by system messages.\",\n",
        "                                    models=models,\n",
        "                                    temperature=0.2,\n",
        "                                    max_tokens=100,\n",
        "                                    clients=clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Deg_ndB8NhcO"
      },
      "outputs": [],
      "source": [
        "handler_two_openai = ChatWithOpenai(system_message=\"You are an assistant. Your job is to check the user input. \\\n",
        "If the user input does not contain any financial and \\\n",
        "trading topics or requests, then you should answer only\\\n",
        "with True. Otherwise, return False. \\\n",
        "Possible responses for you are 'True' or 'False'. \\\n",
        "For example, the correct response to the question \\\n",
        "'What is the trend?' is 'False'.\",\n",
        "                              models=models,\n",
        "                              temperature=0,\n",
        "                              max_tokens=100,\n",
        "                              clients=clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "J8UHKYBEEfH5"
      },
      "outputs": [],
      "source": [
        "class HandleIrrelevantSchema(BaseModel):\n",
        "    massage: str = Field(..., description=\"The humanmassage\")\n",
        "\n",
        "\n",
        "class HandleIrrelevant(BaseTool):\n",
        "    name = \"HandleIrrelevant\"\n",
        "    description = \"\"\"This function checks if the message contains financial or trading subjects or not. \\\n",
        "The output of this function is either True or False and the possible output of this function are 'True' or 'False'.: \\\n",
        "True: when the message contains financial or trading subjects. \\\n",
        "False: when the message request is not in these fields.\"\"\"\n",
        "\n",
        "    args_schema: Type[BaseModel] = HandleIrrelevantSchema\n",
        "\n",
        "    def _run(\n",
        "        self, massage: str\n",
        "    ) -> dict:\n",
        "\n",
        "        user_input = [{\"role\": \"user\", \"content\": \"'\" + massage + \"'\"}]\n",
        "\n",
        "        modified_input = handler_zero_openai.chat(user_input)\n",
        "        # print(f\"inside handler func: {modified_input}\")\n",
        "        if modified_input == 'None':\n",
        "          return 'Greeting'\n",
        "\n",
        "        modified_user_input = [{\"role\": \"user\", \"content\": modified_input}]\n",
        "\n",
        "        if handler_one_openai.chat(modified_user_input) == 'True':\n",
        "          return \"Tutorial\"\n",
        "        # print(f\"in the handler: {modified_user_input}\")\n",
        "        else:\n",
        "          return handler_two_openai.chat(modified_user_input)\n",
        "\n",
        "        # chat_with_openai(user_input)\n",
        "        # return chat_with_openai(user_input)\n",
        "\n",
        "Handler = HandleIrrelevant()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ZzsXJuayUsk2"
      },
      "outputs": [],
      "source": [
        "# Handler.run(\"What is the trend?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5NqR7iXE65aV"
      },
      "outputs": [],
      "source": [
        "# tools = [trend, SR, TP, Sl, Bias, databaseId, databaseRisk, databaseStyle, Handler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AmVaq852XjDt"
      },
      "outputs": [],
      "source": [
        "tools = [Trend, SR, TP, SL, Bias, Handler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "mmuJdTx-LkO3"
      },
      "outputs": [],
      "source": [
        "tool_executor = ToolExecutor(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nDgbgr9HdZl"
      },
      "source": [
        "## Helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "j1mr9W5nxLW6"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, BaseMessage, ChatMessage, FunctionMessage, HumanMessage\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
        "from langchain_core.tools import tool\n",
        "from typing import Annotated, List, Sequence, Tuple, TypedDict, Union\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, BasePromptTemplate, MessagesPlaceholder\n",
        "import operator\n",
        "import functools\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "QDz0tK9PxPDJ"
      },
      "outputs": [],
      "source": [
        "def create_agent(llm, tools, system_message: str):\n",
        "  \"\"\"Create an agent.\"\"\"\n",
        "  functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "      [\n",
        "          (\n",
        "              \"system\",\n",
        "              \" You are a helpful AI assistant, collaborating with other assistants.\"\n",
        "              \" Use the provided tools to progress towards answering the question.\"\n",
        "              \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
        "              \" will help where you left off. Execute what you can to make progress.\"\n",
        "              \" If you or any of the other assistants have the final answer or deliverable,\"\n",
        "              \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
        "              f\" You have access to the following tools: {tool}.\\n{system_message}\",\n",
        "          ),\n",
        "          MessagesPlaceholder(variable_name=\"messages\"),\n",
        "      ]\n",
        "  )\n",
        "  prompt = prompt.partial(system_message=system_message)\n",
        "  prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
        "  return prompt | llm.bind_functions(functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qmFMyzFvxkVl"
      },
      "outputs": [],
      "source": [
        "def agent_node(state, agent, name):\n",
        "  result = agent.invoke(state)\n",
        "\n",
        "  if isinstance(result, FunctionMessage):\n",
        "      pass\n",
        "\n",
        "  else:\n",
        "      result = HumanMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
        "\n",
        "  return {\n",
        "      \"messages\": [result],\n",
        "      \"sender\": name,\n",
        "      \"output_json\": state[\"output_json\"]\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG5-7xPrWAEO"
      },
      "source": [
        "## Agents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "I3GZHhQgWrtm"
      },
      "outputs": [],
      "source": [
        "from langchain_core.agents import AgentActionMessageLog\n",
        "from langchain_openai import AzureChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "LW8US-J3xzUH"
      },
      "outputs": [],
      "source": [
        "api_type = \"azure\"\n",
        "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "api_version = '2023-10-01-preview'\n",
        "api_key = '80ddd1ad72504f2fa226755d49491a61'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "P7L2tpF8xzUH"
      },
      "outputs": [],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "                  api_key=api_key,\n",
        "                  api_version=api_version,\n",
        "                  azure_endpoint=api_endpoint,\n",
        "                  deployment_name=\"gpt_35_16k\",\n",
        "                  temperature=0,\n",
        "                  streaming=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "k9XEZ_r8xscp"
      },
      "outputs": [],
      "source": [
        "# Trend:At any situations, never return the number which is the output of the Trend function. Instead, use its correcsponding explanation which is in the Trend tool's description. Make sure to mention the start_datetime and end_datetime or the lookback parameter if the user have mentioned in their last message. If the user provide neither specified both start_datetime and end_datetime nor lookback parameters, politely tell them that they should and introduce these parameters to them so that they can use them. Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Now generate a proper response. \\\n",
        "trading_agent = create_agent(\n",
        "    llm,\n",
        "    [Trend, SR, TP, SL, Bias],\n",
        "    system_message=\"\"\"You are an assistant with the following capabilities given to you by your tools:\n",
        "SR: Calculate support and resistance levels. \\\n",
        "Trend: Calculate the trend of a specified financial instrument over a given time range and timeframe. \\\n",
        "TP: Calculate Take profit (TP), \\\n",
        "SL: Calculate Stoploss (SL), \\\n",
        "Bias: Detecting trading bias. \\\n",
        "Note the following rules for result of each tool: \\\n",
        "SR:Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Do not mention the name of the levels either they are support or resistance. Just put all the levels together in a list and show them. The final answer should also contain the following texts: These levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels. \\\n",
        "Trend:At any situations, never return the number which is the output of the Trend function. Instead, use its correcsponding explanation which is in the Trend tool's description. Make sure to mention the start_datetime and end_datetime or the lookback parameter. Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Now generate a proper response. \\\n",
        "TP: Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Now generate a proper response. \\\n",
        "SL: Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. The unit of every number in the answer should be mentioned. Now generate a proper response. \\\n",
        "Bias: Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Now generate a proper response.\"\"\"\n",
        ")\n",
        "trading_node = functools.partial(agent_node, agent=trading_agent, name=\"Trading\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "DlECe-H-yZaV"
      },
      "outputs": [],
      "source": [
        "# onboarding_agent = create_agent(\n",
        "#     llm,\n",
        "#     [databaseId, databaseRisk, databaseStyle],\n",
        "#     \"\"\"You are an onboarding assistant who helps new users set and change some of the user fields in the database.\n",
        "#        Note that user requests in our systems must only pertain to financial and trading topics.\n",
        "#        If the users request is not related to these topics, this tool will handle it.\"\"\",\n",
        "# )\n",
        "# onboarding_node = functools.partial(agent_node, agent=onboarding_agent, name=\"Onboarding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjyNdJzWW4-C"
      },
      "source": [
        "## Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elx78emqXsiT"
      },
      "source": [
        "### adding sub graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thp0qoYhCrDj"
      },
      "outputs": [],
      "source": [
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KxGO5t6CobZ"
      },
      "outputs": [],
      "source": [
        "def reduce_list(left: list | None, right: list | None) -> list:\n",
        "  \"\"\"Append the right-hand list, replacing any elements with the same id in the left-hand list.\"\"\"\n",
        "  if not left:\n",
        "      left = []\n",
        "  if not right:\n",
        "      right = []\n",
        "  left_, right_ = [], []\n",
        "  for orig, new in [(left, left_), (right, right_)]:\n",
        "      for val in orig:\n",
        "          if not isinstance(val, dict):\n",
        "              val = {\"val\": val}\n",
        "          if \"id\" not in val:\n",
        "              val[\"id\"] = str(uuid.uuid4())\n",
        "          new.append(val)\n",
        "  # Merge the two lists\n",
        "  left_idx_by_id = {val[\"id\"]: i for i, val in enumerate(left_)}\n",
        "  merged = left_.copy()\n",
        "  for val in right_:\n",
        "      if (existing_idx := left_idx_by_id.get(val[\"id\"])) is not None:\n",
        "          merged[existing_idx] = val\n",
        "      else:\n",
        "          merged.append(val)\n",
        "  return merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB1Z12UJxPLB"
      },
      "outputs": [],
      "source": [
        "# class AgentState(TypedDict):\n",
        "#   messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "#   path: Annotated[list[str], reduce_list]\n",
        "#   # sender: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9bdSVwA4iPg"
      },
      "outputs": [],
      "source": [
        "# subGraphOne = StateGraph(AgentState)\n",
        "# mainGraph = StateGraph(AgentState)\n",
        "\n",
        "# mainGraph.add_node(\"Handler\", run_Handler)\n",
        "\n",
        "# subGraphOne.add_node(\"Greeting\", run_greeting)\n",
        "# subGraphOne.add_node(\"Tutorial\", run_tutorial)\n",
        "\n",
        "# subGraphOne.add_edge(\"Greeting\", END)\n",
        "# subGraphOne.add_edge(\"Tutorial\", END)\n",
        "# subGraphOne.add_conditional_edges(\n",
        "#     \"Handler\",\n",
        "#     router,\n",
        "#     {\"Greeting\": \"Greeting\", \"Tutorial\": \"Tutorial\", \"end\": END},\n",
        "# )\n",
        "\n",
        "# subGraphOne.set_entry_point(\"Handler\")\n",
        "# # subGraphOne.set_finish_point(\"Trading\")\n",
        "\n",
        "# mainGraph.add_node(\"Trading\", trading_node)\n",
        "# mainGraph.add_node(\"Onboarding\", onboarding_node)\n",
        "# mainGraph.add_node(\"call_tool\", tool_node)\n",
        "# mainGraph.add_node(\"child\", subGraphOne.compile())\n",
        "\n",
        "# mainGraph.add_conditional_edges(\n",
        "#     \"Trading\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        "# )\n",
        "# mainGraph.add_conditional_edges(\n",
        "#     \"Onboarding\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        "# )\n",
        "\n",
        "\n",
        "# mainGraph.add_conditional_edges(\n",
        "#     \"call_tool\",\n",
        "#     lambda x: x[\"sender\"],\n",
        "#     {\n",
        "#         \"Trading\": \"Trading\",\n",
        "#         \"Onboarding\": \"Onboarding\",\n",
        "#     },\n",
        "# )\n",
        "# mainGraph.set_entry_point(\"Handler\")\n",
        "\n",
        "# graph = mainGraph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pXiBnGkX13I"
      },
      "source": [
        "### normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "tVkwTo3E48dI"
      },
      "outputs": [],
      "source": [
        "def run_Handler(state):\n",
        "  tool_name = \"HandleIrrelevant\"\n",
        "\n",
        "  messages = state[\"messages\"]\n",
        "  last_message = messages[-1]\n",
        "\n",
        "  # print(\"&\"*50)\n",
        "  # print(last_message.content)\n",
        "  # print(\"&\"*50)\n",
        "\n",
        "  action = ToolInvocation(\n",
        "      tool=tool_name,\n",
        "      tool_input=last_message.content,\n",
        "  )\n",
        "\n",
        "  response = tool_executor.invoke(action)\n",
        "  # print(response)\n",
        "  standard_response = \"\"\n",
        "  if response == 'True':\n",
        "    standard_response = \"I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\"\n",
        "\n",
        "  function_message = FunctionMessage(\n",
        "       content=standard_response, HandleIrrelevant_response=f\"{str(response)}\", name=action.tool\n",
        "  )\n",
        "\n",
        "  return {\"messages\": [function_message]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "JkjI0fgMbhT2"
      },
      "outputs": [],
      "source": [
        "def run_greeting(state):\n",
        "  # tool_name = \"HandleIrrelevant\"\n",
        "\n",
        "  # action = ToolInvocation(\n",
        "  #     tool=tool_name,\n",
        "  #     tool_input=\"Hi\",\n",
        "  # )\n",
        "\n",
        "  # response = tool_executor.invoke(action)\n",
        "\n",
        "  greeting = ChatWithOpenai(system_message=\"You are an financial and trading assistant.\",\n",
        "                            models=models,\n",
        "                            temperature=0.2,\n",
        "                            max_tokens=100,\n",
        "                            clients=clients)\n",
        "  input = [{\"role\": \"user\", \"content\": \"Hi\"}]\n",
        "  response = greeting.chat(input)\n",
        "\n",
        "  function_message = FunctionMessage(\n",
        "       content=response ,name='openai chat'\n",
        "  )\n",
        "\n",
        "  return {\"messages\": [function_message]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "wxNA-zRPTE42"
      },
      "outputs": [],
      "source": [
        "def run_tutorial(state):\n",
        "  response = \"\"\"I'm TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools:\n",
        "1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\"\n",
        "2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\"\n",
        "3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\"\n",
        "4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\"\n",
        "5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\"\n",
        "Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!\"\"\"\n",
        "\n",
        "  function_message = FunctionMessage(\n",
        "       content=response ,name='hardcoded string'\n",
        "  )\n",
        "\n",
        "  return {\"messages\": [function_message]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "BfUv6qxqbDDg"
      },
      "outputs": [],
      "source": [
        "def output_json_assigner(tool_name, response):\n",
        "  output_json = {}\n",
        "  if tool_name == \"calculate_sr\":\n",
        "    sr_value, sr_start_date, sr_detect_date, sr_end_date, sr_importance = response\n",
        "    output_json[\"levels_prices\"] = sr_value\n",
        "    output_json[\"levels_start_timestamps\"] = sr_start_date\n",
        "    output_json[\"levels_detect_timestamps\"] = sr_detect_date\n",
        "    output_json[\"levels_end_timestamps\"] = sr_end_date\n",
        "    output_json[\"levels_scores\"] = sr_importance\n",
        "  return output_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "nS7yahoQzOaI"
      },
      "outputs": [],
      "source": [
        "def tool_node(state):\n",
        "  \"\"\"This runs tools in the graph\n",
        "      It takes in an agent action\n",
        "      and calls that tool and\n",
        "      returns the result.\"\"\"\n",
        "  messages = state[\"messages\"]\n",
        "  last_message = messages[-1]\n",
        "  tool_input = json.loads(\n",
        "      last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
        "  )\n",
        "\n",
        "  if len(tool_input) == 1 and \"__arg1\" in tool_input:\n",
        "      tool_input = next(iter(tool_input.values()))\n",
        "  # tool_name = last_message.additional_kwargs[\"function_call\"][\"name\"]\n",
        "\n",
        "  tool_name = last_message.additional_kwargs[\"function_call\"][\"name\"].split(\".\")[-1]\n",
        "\n",
        "  action = ToolInvocation(\n",
        "      tool=tool_name,\n",
        "      tool_input=tool_input,\n",
        "  )\n",
        "\n",
        "  response = tool_executor.invoke(action)\n",
        "\n",
        "  out_json = output_json_assigner(tool_name, response)\n",
        "\n",
        "\n",
        "  function_message = FunctionMessage(\n",
        "      content=f\"{tool_name} response: {str(response)}\", name=action.tool\n",
        "  )\n",
        "\n",
        "  return {\"messages\": [function_message], \"output_json\":out_json}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ZqafxFRLzXlm"
      },
      "outputs": [],
      "source": [
        "def router(state):\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    if last_message.name != 'HandleIrrelevant':\n",
        "      last_message = messages[-2]\n",
        "\n",
        "      if \"function_call\" in last_message.additional_kwargs:\n",
        "        return \"call_tool\"\n",
        "\n",
        "      if not \"function_call\" in last_message.additional_kwargs and last_message.type == \"function\":\n",
        "        return \"continue\"\n",
        "\n",
        "      if not last_message.additional_kwargs and last_message.type == \"human\":\n",
        "        return \"end\"\n",
        "\n",
        "    else:\n",
        "      if \"Greeting\" in last_message.HandleIrrelevant_response and last_message.name == 'HandleIrrelevant':\n",
        "        return \"Greeting\"\n",
        "\n",
        "      if \"Tutorial\" in last_message.HandleIrrelevant_response and last_message.name == 'HandleIrrelevant':\n",
        "        return \"Tutorial\"\n",
        "\n",
        "      if \"True\" in last_message.HandleIrrelevant_response and last_message.name == 'HandleIrrelevant':\n",
        "        return \"end\"\n",
        "\n",
        "      if \"False\" in last_message.HandleIrrelevant_response and last_message.name == 'HandleIrrelevant':\n",
        "        return \"continue\"\n",
        "\n",
        "      if \"False\" in last_message.content and last_message.name == \"HandleGreeting\":\n",
        "        return \"continue\"\n",
        "\n",
        "      if \"False\" not in last_message.content and last_message.name == \"HandleGreeting\":\n",
        "        return \"end\"\n",
        "\n",
        "\n",
        "    return \"continue\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "rQJEV9IJYO0r"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "  output_json: dict\n",
        "  input_json: dict\n",
        "  sender: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "HWKy0Tnuzr7P"
      },
      "outputs": [],
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"Trading\", trading_node)\n",
        "# workflow.add_node(\"Onboarding\", onboarding_node)\n",
        "workflow.add_node(\"call_tool\", tool_node)\n",
        "workflow.add_node(\"Handler\", run_Handler)\n",
        "workflow.add_node(\"Greeting\", run_greeting)\n",
        "workflow.add_node(\"Tutorial\", run_tutorial)\n",
        "\n",
        "# workflow.add_node(\"Inquiry\", inquiry_node)\n",
        "# workflow.add_node(\"Support\", support_node)\n",
        "# workflow.add_node(\"Inquiry\", inquiry_node)\n",
        "\n",
        "# workflow.add_edge(\"Inquiry\", \"call_tool\")\n",
        "\n",
        "# workflow.add_edge(\"Handler\", \"Trading\")\n",
        "\n",
        "workflow.add_edge(\"Greeting\", END)\n",
        "workflow.add_edge(\"Tutorial\", END)\n",
        "\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"Inquiry\",\n",
        "#     router,\n",
        "#     {\"call_tool\": \"call_tool\", \"continue\": \"Inquiry\"},\n",
        "# )\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"Support\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        "# )\n",
        "workflow.add_conditional_edges(\n",
        "    \"Handler\",\n",
        "    router,\n",
        "    {\"continue\": \"Trading\", \"Greeting\": \"Greeting\", \"Tutorial\": \"Tutorial\", \"end\": END},\n",
        ")\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"Greeting\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"end\": END},\n",
        "# )\n",
        "workflow.add_conditional_edges(\n",
        "    \"Trading\",\n",
        "    router,\n",
        "    {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        ")\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"Onboarding\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        "# )\n",
        "\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"call_tool\",\n",
        "    lambda x: x[\"sender\"],\n",
        "    {\n",
        "        \"Trading\": \"Trading\",\n",
        "        # \"Onboarding\": \"Onboarding\",\n",
        "        # \"Inquiry\": \"Inquiry\",\n",
        "        # \"Support\": END\n",
        "    },\n",
        ")\n",
        "workflow.set_entry_point(\"Handler\")\n",
        "\n",
        "graph = workflow.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8B2R2gjXU6A"
      },
      "source": [
        "## Graph visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "MogS2xefyYIf"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "import base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "-3izld86Xfj9"
      },
      "outputs": [],
      "source": [
        "def display_image(image_bytes: bytes, width=300):\n",
        "    decoded_img_bytes = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "    html = f'<img src=\"data:image/png;base64,{decoded_img_bytes}\" style=\"width: {width}px;\" />'\n",
        "    display(HTML(html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "OlsVc0H1xviv"
      },
      "outputs": [],
      "source": [
        "# display_image(graph.get_graph().draw_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FWNCO4ZXlMp"
      },
      "source": [
        "## Test prompts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "Cps0Oo1fS3lR",
        "outputId": "c254cfdb-bdfa-4d93-b2b9-9a6eb9d6f01a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt:  \tCalculate Support and Resistance Levels of YM and NQ by looking back up to past 5 days and timeframe of 10 minutes.\n",
            "Error with client: client 1. Exception: Request timed out.\n",
            "Error with client: client 2. Exception: Request timed out.\n",
            "Error with client: client 3. Exception: Request timed out.\n",
            "Error with client: client 4. Exception: Request timed out.\n",
            "Error with client: client 5. Exception: Request timed out.\n",
            "Error with client: client 1. Exception: Request timed out.\n",
            "Error with client: client 2. Exception: Request timed out.\n",
            "Error with client: client 3. Exception: Request timed out.\n",
            "Error with client: client 4. Exception: Request timed out.\n",
            "Error with client: client 5. Exception: Request timed out.\n",
            "Error with client: client 1. Exception: Request timed out.\n",
            "Error with client: client 2. Exception: Request timed out.\n",
            "Error with client: client 3. Exception: Request timed out.\n",
            "Error with client: client 4. Exception: Request timed out.\n",
            "Error with client: client 5. Exception: Request timed out.\n",
            "{'Handler': {'messages': [FunctionMessage(content='', name='HandleIrrelevant', HandleIrrelevant_response='None')]}}\n"
          ]
        }
      ],
      "source": [
        "# sample prompt for each function\n",
        "prompts = [\n",
        "    # # detect_trend\n",
        "    # \"What is the trend of NQ and ES stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\",\n",
        "    # calculate_sr\n",
        "    \"Calculate Support and Resistance Levels of YM and NQ by looking back up to past 5 days and timeframe of 10 minutes.\",\n",
        "    # # calculate_sl\n",
        "    # \"What would be the stop loss of trading short positinos based on NQ and ES and minmax method by looking back up to 30 candles?\",\n",
        "    # # calculate_tp\n",
        "    # \"How much would be the take-profit of the NQ with the stop loss of 10 and direction of 1?\",\n",
        "    # # bias_detection\n",
        "    # \"Tell me about the bias of ES on the market.\",\n",
        "\t# # irrelevant\n",
        "\t# \"What are the rules of basketball?\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "\tprint(f\"Prompt:  \t{prompt}\")\n",
        "\tfor s in graph.stream(\n",
        "\t\t\t{\n",
        "\t\t\t\t\"messages\": [\n",
        "\t\t\t\t\tHumanMessage(\n",
        "\t\t\t\t\tcontent=prompt\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\t],\n",
        "\t\t\t\t\"input_json\": input_filter.front_end_json_sample\n",
        "\t\t\t},\n",
        "\t\t\t# Maximum number of steps to take in the graph\n",
        "\t\t\t{\"recursion_limit\": 150},\n",
        "\t\t):\n",
        "\t\tprint(s)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GfknVBncqyyR",
        "bVaURl9SEzMm",
        "nlPLaNe4GjgH",
        "EciRRD4YELCo",
        "lt4sSmAQH1Ph",
        "AahZLwrkH-G-",
        "ALEtGCoWoI_2",
        "LwjkTlbXlsgC",
        "nhFk82hXFm2b",
        "Xr_s_UHkFGCT",
        "2nDgbgr9HdZl",
        "uG5-7xPrWAEO",
        "elx78emqXsiT",
        "_pXiBnGkX13I",
        "W8B2R2gjXU6A"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
