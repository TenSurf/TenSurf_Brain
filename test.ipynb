{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import merged\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing each function individualy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "detect_trend_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the trend of NQ stock from 3/4/2024 15:45:30 until 13/4/2024 15:45:30?\",\n",
    "    \"What is the trend of NQ stock for the past week?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"What is the trend?\",\n",
    "    \"Show me the trend of ES from 2024-03-25 11:12:17 to 2024-04-01 9:31:23.\",\n",
    "    \"Trend of GC, 2024-03-25 11:12:17 to 2024-04-01 9:31:23\",\n",
    "    \"Trend of GC, past 2 hours\",\n",
    "    # Challenging Prompts\n",
    "    \"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\",\n",
    "    \"What is the trend of NQ stock from 2024/4/3 15:45:30 until 2024/4/13 15:45:30?\",\n",
    "    \"What is the trend of NQ stock from 2024/4/13 15:45:30 until 2024/4/3 15:45:30?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"3/4/2024 15:45:30\",\\n  \"end_datetime\": \"13/4/2024 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\GradioFunctionCallingApp\\functions_python.py:653: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  end_datetime = pd.to_datetime(end_datetime)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D77042DA0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-03-04T23:45:30Z), stop: time(v: 2024-04-13T22:45:30Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ stock from 3/4/2024 15:45:30 until 13/4/2024 15:45:30?    =>    The trend of the NQ stock from 3/4/2024 15:45:30 until 13/4/2024 15:45:30 is not significant.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"lookback\": \"1 week\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D770BD000>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-21T17:46:18Z), stop: time(v: 2024-04-28T17:46:18Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ stock for the past week?    =>    The trend of the NQ stock for the past week is not significant.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D770D7220>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-18T17:46:24Z), stop: time(v: 2024-04-28T17:46:24Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ?    =>    The trend of the NQ stock is not significant. Please provide a specific time range or lookback period for a more accurate analysis.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D770E41F0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-18T17:46:29Z), stop: time(v: 2024-04-28T17:46:29Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend?    =>    The trend of the NQ stock is not significant. To get a more accurate analysis, please provide a specific time range or lookback period.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"ES\",\\n  \"start_datetime\": \"2024-03-25 11:12:17\",\\n  \"end_datetime\": \"2024-04-01 9:31:23\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D770E4250>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-03-25T18:12:17Z), stop: time(v: 2024-04-01T16:31:23Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"ES\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "Show me the trend of ES from 2024-03-25 11:12:17 to 2024-04-01 9:31:23.    =>    The trend of the ES stock from 2024-03-25 11:12:17 to 2024-04-01 9:31:23 is not significant.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"GC\",\\n  \"start_datetime\": \"2024-03-25 11:12:17\",\\n  \"end_datetime\": \"2024-04-01 9:31:23\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D770DA890>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-03-25T18:12:17Z), stop: time(v: 2024-04-01T16:31:23Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"GC\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "Trend of GC, 2024-03-25 11:12:17 to 2024-04-01 9:31:23    =>    The trend of the GC stock from 2024-03-25 11:12:17 to 2024-04-01 9:31:23 is not significant.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"GC\",\\n  \"lookback\": \"2 hours\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D770DA230>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-28T15:46:47Z), stop: time(v: 2024-04-28T17:46:47Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"GC\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "Trend of GC, past 2 hours    =>    The trend of the GC stock for the past 2 hours is not significant.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"3/4/2024 15:45:30\",\\n  \"end_datetime\": \"3/4/2024/67 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D770DA7D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-03-04T23:45:30Z), stop: time(v: 2024-03-04T23:45:30Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?    =>    I apologize, but I couldn't understand the format of the end datetime you provided (\"3/4/2024/67 15:45:30\"). Could you please provide the end datetime in a valid format, using the following example as a reference: \"3/4/2024 15:45:30\"?\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"2024/4/3 15:45:30\",\\n  \"end_datetime\": \"2024/4/13 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D770DA110>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-03T22:45:30Z), stop: time(v: 2024-04-13T22:45:30Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ stock from 2024/4/3 15:45:30 until 2024/4/13 15:45:30?    =>    The trend of the NQ stock from 2024/4/3 15:45:30 until 2024/4/13 15:45:30 is not significant.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"2024/4/13 15:45:30\",\\n  \"end_datetime\": \"2024/4/3 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D77109360>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-13T22:45:30Z), stop: time(v: 2024-04-03T22:45:30Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "The following exception occured:\n",
      "Error code: 400 - {'error': {'message': \"This model's maximum context length is 4096 tokens. However, your messages resulted in 4137 tokens (2774 in the messages, 1363 in the functions). Please reduce the length of the messages or functions.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "try:\n",
    "    llm = merged.FileProcessor()\n",
    "    for prompt in detect_trend_prompts:\n",
    "        result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "        print(f\"{prompt}    =>    {result}\")\n",
    "        results[prompt]=result\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "finally:\n",
    "    # saving the answers\n",
    "    with open(\"test_results/detect_trend_test_results.json\", \"w\") as outfile: \n",
    "        json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Support and Resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sr_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 1 hour.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM by the timeframe of 1 hour.\",\n",
    "    \"How much is the sr of CL for the past week?\",\n",
    "    # Challenging prompts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"YM\",\\n  \"lookback_days\": \"10\",\\n  \"timeframe\": \"1h\"\\n}', name='calculate_sr'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000028D773B1210>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-18T19:17:46Z), stop: time(v: 2024-04-28T19:17:46Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"YM\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m llm \u001b[38;5;241m=\u001b[39m merged\u001b[38;5;241m.\u001b[39mFileProcessor()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m calculate_sr_prompts:\n\u001b[1;32m----> 8\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m    =>    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m     results[prompt]\u001b[38;5;241m=\u001b[39mresult\n",
      "File \u001b[1;32mc:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\GradioFunctionCallingApp\\merged.py:368\u001b[0m, in \u001b[0;36mFileProcessor.get_user_input\u001b[1;34m(self, file_path, prompt, messages)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompt:\n\u001b[0;32m    367\u001b[0m     content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_with_ai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\GradioFunctionCallingApp\\merged.py:157\u001b[0m, in \u001b[0;36mFileProcessor.chat_with_ai\u001b[1;34m(self, messages, content)\u001b[0m\n\u001b[0;32m    155\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content})\n\u001b[0;32m    156\u001b[0m response \u001b[38;5;241m=\u001b[39m get_response(messages, functions, config\u001b[38;5;241m.\u001b[39mazure_GPT_MODEL_3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 157\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\GradioFunctionCallingApp\\merged.py:126\u001b[0m, in \u001b[0;36mFileProcessor.chat_with_ai.<locals>.get_result\u001b[1;34m(messages, chat_response)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlookback_days\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m function_arguments:\n\u001b[0;32m    124\u001b[0m     function_arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlookback_days\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10 days\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 126\u001b[0m sr_value, sr_start_date, sr_end_date, sr_importance \u001b[38;5;241m=\u001b[39m FC\u001b[38;5;241m.\u001b[39mcalculate_sr(parameters\u001b[38;5;241m=\u001b[39mfunction_arguments)\n\u001b[0;32m    127\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe result of the function calling with function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has become \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msr_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for levels_prices, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msr_start_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for levels_start_timestamps, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msr_end_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for levels_end_timestamps and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msr_importance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for levels_scores. Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. If the user didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified lookback_days or timeframe parameters, introduce these parameters to them so that they can use these parameters. Now generate a proper response\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m    128\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m get_response(\n\u001b[0;32m    129\u001b[0m     messages, functions, config\u001b[38;5;241m.\u001b[39mazure_GPT_MODEL_3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "llm = merged.FileProcessor()\n",
    "for prompt in calculate_sr_prompts:\n",
    "    result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "    print(f\"{prompt}    =>    {result}\")\n",
    "    results[prompt]=result\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "#     # saving the answers\n",
    "#     with open(\"test_results/calculate_sr_test_results.json\", \"w\") as outfile: \n",
    "#         json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Stop Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sl_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"How much would be the stop loss for trading based on NQ and short positions with minmax method by looking back up to 30 candles and considering 50 candles neighboring the current time and also attribute coefficient of 1.3?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "llm = merged.FileProcessor()\n",
    "for prompt in calculate_sl_prompts:\n",
    "    result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "    print(f\"{prompt}    =>    {result}\")\n",
    "    results[prompt]=result\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "#     # saving the answers\n",
    "#     with open(\"test_results/calculate_sl_test_results.json\", \"w\") as outfile: \n",
    "#         json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Take-Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_tp_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"How much would be the take-profit of the NQ with the stop loss of 10 and direction of 1?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "try:\n",
    "    llm = merged.FileProcessor()\n",
    "    for prompt in calculate_tp_prompts:\n",
    "        result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "        print(f\"{prompt}    =>    {result}\")\n",
    "        results[prompt]=result\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "finally:\n",
    "    # saving the answers\n",
    "    with open(\"test_results/calculate_tp_test_results.json\", \"w\") as outfile: \n",
    "        json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_function_calling_prompts = [\n",
    "    # Normal Prompts\n",
    "    \n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "try:\n",
    "    llm = merged.FileProcessor()\n",
    "    for prompt in calculate_tp_prompts:\n",
    "        result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "        print(f\"{prompt}    =>    {result}\")\n",
    "        results[prompt]=result\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "finally:\n",
    "    # saving the answers\n",
    "    with open(\"test_results/parallel_function_calling_test_results.json\", \"w\") as outfile: \n",
    "        json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image file detected. VisionGPT processing...\n",
      "Image processing complete.\n",
      "It seems that you've described a financial chart for Cardano (ADA) against the US Dollar (USDT), highlighting key elements such as candlestick bars, exponential moving averages (EMAs), a descending channel pattern, the relative strength index (RSI), and a timestamp. However, the description ends abruptly with \"Price Values: The right side of the chart displays price levels corresponding to...\" Is there a specific question or action you'd like to take based on this chart? Feel free to share any further details or requests you may have.\n",
      "Excel file detected. Extracting text...\n",
      "Extraction complete.\n",
      "This content appears to be a list of job vacancies and required qualifications, including details such as company names, job titles, experience requirements, application dates, salaries, phone numbers, locations, work days, start times, and site addresses. Additionally, there are mentions of work requirements, technical skills, and previous job experience related to AI, machine learning, data analysis, and other IT fields.\n",
      "\n",
      "If you have a specific question or need assistance with interpreting or processing this information, please feel free to let me know how I can help!\n",
      "Word document detected. Extracting text...\n",
      "Extraction complete.\n",
      "The content provided appears to describe the Beez algorithm as an optimization algorithm that uses a combination of exploratory local search and global search to solve complex optimization problems. The explanation includes details about the scouting process, evaluation and rearrangement of initial solutions based on their costs, and the iterative search for the best solution within the desired area. It also highlights the use of elite and non-elite solutions, random solution replacement, and the repetition of the search method to converge towards the optimal solution.\n",
      "\n",
      "Additionally, the reference to the guaranteed convergence of the Beez algorithm is noted. It seems that the content aims to provide a detailed overview of the algorithm and its application to optimization problems.\n",
      "\n",
      "If you have specific questions or need further assistance related to the Beez algorithm or any related topic, please feel free to ask!\n",
      "PDF file detected. Extracting text...\n",
      "Extraction complete.\n",
      "The content provided appears to be an informational bulletin issued by the U.S. Securities and Exchange Commission (SEC) to educate investors about different types of orders and trading instructions available for buying and selling stocks through brokerage firms. The bulletin includes general descriptions of common order types such as market orders, limit orders, stop orders, stop-limit orders, along with special orders and trading instructions like Good-til-Cancelled (GtC) orders, Day orders, Fill-Or-Kill (FOK) orders, All-Or-None (AON) orders, and Immediate-or-Cancel (IoC) orders.\n",
      "\n",
      "Additionally, it provides examples and important considerations for each type of order, including the implications of short-term market fluctuations, specific rules regarding stop and stop-limit orders for certain types of stocks, and the availability of certain order types and trading instructions based on specific brokerage firms.\n",
      "\n",
      "The document aims to help investors understand the different options available when placing orders for buying and selling stocks through brokerage firms and includes related information and references to additional educational materials provided by the SEC's Office of Investor Education and Advocacy.\n",
      "\n",
      "If there are specific details within the content that you would like to discuss or if you have further questions, please feel free to let me know!\n",
      "Text file detected. Extracting text...\n",
      "Extraction complete.\n",
      "The content provided appears to describe a model that is trained on a large dataset of English audio and text. The model is optimized for transcribing audio files containing speech in English but can also transcribe audio files with speech in other languages. The output of the model is English text, regardless of the language spoken in the audio files. The content highlights the flexibility of the model to transcribe mixed language audio input and produce English output. Additionally, it mentions the option to choose between using the \"whisper\" model via a short movie, indicating that the readability of the transcribed text remains consistent regardless of the chosen option.\n",
      "\n",
      "If there are specific details within the content that you would like to discuss further or if you have specific questions related to this model, feel free to share!\n",
      "Speech file detected. Processing speech...\n",
      "Speech processing complete.\n",
      "The main idea conveyed in the provided content is the advocacy for natural, independent learning as the most effective approach for acquiring proficiency in the English language. The passage discusses the limitations and shortcomings of traditional, institutionalized education systems, particularly in their methods of teaching English. It criticizes the inherent inefficiency of rote memorization and passive learning, highlighting that the prescribed methodology often fails to foster genuine fluency in the language.\n",
      "\n",
      "The content emphasizes the need for a departure from the institutional educational framework and encourages individuals to pursue an independent learning path. It stresses the significance of listening as the foundational skill for natural English learning and advocates for the formation of supportive and interactive learning communities to complement individual study.\n",
      "\n",
      "Furthermore, the passage suggests that English learners should prioritize enjoyable and social interactions within learning communities, fostering an environment free from pressure and stress while leveraging the brain's natural capacity for accelerated and effective learning.\n",
      "\n",
      "Ultimately, the overarching message advocates for a shift from institutional learning methods toward a natural, independent learning approach, emphasizing the advantages of enhanced efficiency and enjoyment in the language acquisition process.\n",
      "\n",
      "If there are specific aspects of this concept that you would like to explore further, feel free to share!\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"symbol\":\"NQ\",\"start_datetime\":\"2023-03-10T15:45:30\",\"end_datetime\":\"2023-03-11T15:45:30\"}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2023-03-10T23:45:30Z), stop: time(v: 2023-03-11T23:45:30Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "[Error] result output is not DataFrame\n",
      "There is no data for this period of time...\n",
      "The trend of the NQ stock from 3/10/2023 15:45:30 until 3/11/2023 15:45:30 indicates that there is no significant trend during this time period. If you have any other questions or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Define the list of file paths and prompts\n",
    "messages = merged.messages\n",
    "file_paths = [\"samplefiles/TjqcZqip.png\", 'samplefiles/applyjobs.xlsx', 'samplefiles/paper.docx',\n",
    "              'samplefiles/sample.pdf', 'samplefiles/transcription.txt', 'samplefiles/english.mp3', None]\n",
    "prompts = [\"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"What is the trend of NQ stock from 3/10/2023 15:45:30 until 3/11/2023 15:45:30?\"]\n",
    "\n",
    "# Iterate over file_paths and prompts and run the code\n",
    "for file_path, prompt in zip(file_paths, prompts):\n",
    "    try:\n",
    "        processor = merged.FileProcessor()\n",
    "        print(processor.get_user_input(file_path, prompt, messages))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The founders of Microsoft are Bill Gates and Paul Allen. They established the company on April 4, 1975, with the goal of developing and selling software for personal computers. Bill Gates is particularly known for his role in shaping the company's vision and strategy, while Paul Allen played a significant role in technical aspects and product development.\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurf.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '74b3de375b964f73a6b7668fe459e26f'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Corporation was founded by Bill Gates and Paul Allen. Bill Gates, currently one of the world's wealthiest individuals, served as Microsoft's Chairman and CEO for many years before transitioning to a role as a technology advisor. Paul Allen was a prominent philanthropist and entrepreneur who co-founded Microsoft with Bill Gates, but he passed away in 2018.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '80ddd1ad72504f2fa226755d49491a61'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
