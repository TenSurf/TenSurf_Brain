{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71718ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.signal import argrelextrema\n",
    "import bisect\n",
    "import numpy as np\n",
    "from influxdb_client import InfluxDBClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd8de2",
   "metadata": {},
   "source": [
    "# Common functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabcaa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(dt):\n",
    "    if type(dt) == type(\"\"):\n",
    "        dt = datetime(dt)\n",
    "    us_timezone = pytz.timezone('US/Pacific')\n",
    "    local_time = dt.replace(tzinfo=us_timezone)\n",
    "    utc_time = local_time.astimezone(pytz.utc)\n",
    "    return utc_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "class InfluxClient:\n",
    "    def __init__(self, token, org, url, bucket):\n",
    "        self.token = token\n",
    "        self.org = org\n",
    "        self.url = url\n",
    "        self.bucket = bucket\n",
    "        self.client = InfluxDBClient(url=self.url, token=self.token, org=self.org, timeout=None)\n",
    "        self.receiver_email = 'tensurfllc@gmail.com'\n",
    "        self.last_error_time = 0\n",
    "        self.column_convertor = {'Candle_ClosePrice': 'close', 'Candle_HighPrice': 'high', 'BarPeriod': 'end_time',\n",
    "                                 'Candle_OpenPrice': 'open', 'Candle_LowPrice': 'low', 'VP': 'volume_profile',\n",
    "                                 'Candle_AskNumberOfTrades': 'ask_number', 'Candle_AskVolumeOfTrades': 'ask_volume',\n",
    "                                 'Candle_BidNumberOfTrades': 'bid_number', 'Candle_BidVolumeOfTrades': 'bid_volume',\n",
    "                                 'Candle_LastTradePrice': 'lastprice', 'Candle_NumberOfTrades': 'numtrades',\n",
    "                                 'Candle_VolumeofTrades': 'volume', 'VAP_AskVolumes': 'vap_askvolumes',\n",
    "                                 'VAP_BidVolumes': 'vap_bidvolumes', 'VAP_NumberOfTrades': 'vap_numberoftrades',\n",
    "                                 'VAP_TotalVolume': 'vap_totalvolume', 'VAP_Volumes': 'vap_volumes',\n",
    "                                 'VAP_Prices': 'vap_prices', \"LOB_SumBid\": 'sum_lob_bid', \"LOB_SumAsk\": 'sum_lob_ask',\n",
    "                                 \"LOB_SumBidTick\": 'sum_lob_bid_tick', \"LOB_SumAskTick\": 'sum_lob_ask_tick',\n",
    "                                 \"LOB_BidPrices\": 'lob_bid_price', \"LOB_BidVolumes\": 'lob_bid_volume',\n",
    "                                 \"LOB_AskPrices\": 'lob_ask_price', \"LOB_AskVolumes\": 'lob_ask_volume'}\n",
    "\n",
    "         #self.get_last_records = memory.cache(self.get_last_records)\n",
    "\n",
    "    def retrieve_db_df_between(self, symbol, start_date, end_date):\n",
    "        start_date = convert_datetime(start_date)\n",
    "        end_date = convert_datetime(end_date)\n",
    "\n",
    "        query = f'''from(bucket:\"{self.bucket}\") \n",
    "                |> range(start: time(v:{start_date}), stop: time(v: {end_date}))\n",
    "                |> filter(fn: (r) => r[\"_measurement\"] == \"{symbol}\" and\\\n",
    "                    r[\"timeframe\"] == \"1min\" and\\\n",
    "                    r[\"liq_threshold\"] == \"-1\")\n",
    "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
    "                '''\n",
    "        return self.read_data(query)\n",
    "\n",
    "    def read_data(self, query):\n",
    "        try:\n",
    "            result_ = self.client.query_api().query(query=query)\n",
    "            records = []\n",
    "            for table in result_:\n",
    "                for record in table.records:\n",
    "                    records.append(record.values)\n",
    "\n",
    "            result = pd.DataFrame(records)\n",
    "            if isinstance(result, pd.DataFrame) and all(col in result.columns for col in\n",
    "                                                        ['_time', 'result', 'table', '_start', '_stop', '_measurement',\n",
    "                                                         'liq_threshold', 'timeframe']):\n",
    "                df = result.drop(columns={'_time', 'result', 'table', '_start', '_stop', '_measurement', 'liq_threshold',\n",
    "                             'timeframe'})\n",
    "                df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "                if 'BarPeriod' in df.columns:\n",
    "                    df['BarPeriod'] = pd.to_datetime(df['BarPeriod'])\n",
    "                self.client.close()\n",
    "                df = df.rename(columns={k: v for k, v in self.column_convertor.items() if k in df.columns})\n",
    "                return df\n",
    "            else:\n",
    "                print(query)\n",
    "                print('[Error] result output is not DataFrame')\n",
    "        except Exception as e:\n",
    "                #self.send_error_email(f'InfluxDB - Error reading data from InfluxDB', e)\n",
    "            print(f\"Error reading data from InfluxDB: {e}\\n Query is {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1934c1",
   "metadata": {},
   "source": [
    "# Supprt/Resistance detection functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe735de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRDetector:\n",
    "    def __init__(self, pre_data, timeframe, params_, detection_method_):\n",
    "        # Note: pre_data is time indexed dataframe\n",
    "        self.detection_method = detection_method_\n",
    "        self.timeframe = timeframe\n",
    "        self.params = params_\n",
    "        self.timeframe2 = re.sub(r'\\d+', '1', timeframe)\n",
    "        self.merge_percent = self.params[self.detection_method]['merge_percent'][self.timeframe2]\n",
    "        self.closeness = self.params[self.detection_method]['merge_percent'][self.timeframe2]\n",
    "        self.score_method = self.params[self.detection_method]['score']\n",
    "        self.window_size_score = self.params[self.detection_method]['window_size'][self.timeframe2]\n",
    "        self.last_date = None\n",
    "        self.recent_candle = {'time': None, 'open': 0, 'high': 0, 'low': 0, 'close': 0}\n",
    "        self.potential_support_levels = []\n",
    "        self.potential_resistance_levels = []\n",
    "        self.new_potential_level = False\n",
    "        self.remove_level = False\n",
    "        self.recent_zones = []\n",
    "        self.lines = {}\n",
    "        self.all_levels = []\n",
    "        self.last_support_index = 0\n",
    "        self.last_resistance_index = 0\n",
    "        self.distance_max_threshold = 5\n",
    "        self.current_round_date = None\n",
    "        self.resample(pre_data, self.timeframe)\n",
    "\n",
    "    def resample(self, data: pd.DataFrame, timeframe):\n",
    "        if timeframe is None:\n",
    "            return data\n",
    "        tmp = data.resample(timeframe).agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last'})\n",
    "        tmp = tmp.dropna(subset=['open'])\n",
    "        tmp['tr'] = np.maximum.reduce([tmp['high'] - tmp['low'], np.abs(tmp['high'] - tmp['close']), np.abs(tmp['low'] - tmp['close'])])\n",
    "        tmp['atr'] = tmp['tr'].rolling(14).mean()\n",
    "        tmp = tmp.iloc[14:]\n",
    "        self.data = tmp.to_dict(orient='list')\n",
    "        self.data['time'] = tmp.index.tolist()\n",
    "\n",
    "    def get_levels(self):\n",
    "        for i in range(len(self.data['time'])):\n",
    "            self.atr = self.data['atr'][i]\n",
    "            self.check_cross_line(i)\n",
    "            self.update_potential_levels(i)\n",
    "            self.score_lines(i)\n",
    "\n",
    "    def get_distance(self):\n",
    "        return self.merge_percent * self.atr\n",
    "\n",
    "    def check_cross_line(self, index):\n",
    "        close = self.data['close'][index]\n",
    "        high = self.data['high'][index]\n",
    "        low = self.data['low'][index]\n",
    "\n",
    "        endtime = self.data['time'][index]\n",
    "        max_cross = self.params[self.detection_method]['max_cross']\n",
    "        removed_levels = []\n",
    "        self.remove_level = False\n",
    "        for level in self.lines.keys():\n",
    "            if high >= level and not self.lines[level]['isSupport']:\n",
    "                self.lines[level]['cross'] += 1\n",
    "                self.lines[level]['isSupport'] = True\n",
    "                if self.lines[level]['cross'] >= max_cross:\n",
    "                    self.lines[level][\"endTime\"] = endtime\n",
    "                    removed_levels.append(level)\n",
    "                    if level in self.all_levels:\n",
    "                        self.all_levels.remove(level)\n",
    "            if low <= level and self.lines[level]['isSupport']:\n",
    "                self.lines[level]['cross'] += 1\n",
    "                self.lines[level]['isSupport'] = False\n",
    "                if self.lines[level]['cross'] >= max_cross:\n",
    "                    self.lines[level][\"endTime\"] = endtime\n",
    "                    if level in self.all_levels:\n",
    "                        self.all_levels.remove(level)\n",
    "        if len(removed_levels) > 0: self.remove_level = True\n",
    "        self.lines = {key: value for key, value in self.lines.items() if key not in removed_levels}\n",
    "\n",
    "    def update_potential_levels(self, current_index):\n",
    "        self.new_potential_level = False\n",
    "        timeframe = self.timeframe\n",
    "\n",
    "\n",
    "        window_size = self.params[self.detection_method]['window_size'][self.timeframe2]\n",
    "        if current_index < 2 * window_size + 1:\n",
    "            return\n",
    "        high_data = np.array(self.data['high'][self.last_resistance_index:current_index+1])\n",
    "        low_data = np.array(self.data['low'][self.last_support_index:current_index+1])\n",
    "        high_datalen = len(high_data)\n",
    "        low_datalen = len(low_data)\n",
    "        local_maxima = argrelextrema(high_data, lambda x, y: x >= y, order=window_size)[0]\n",
    "        while len(local_maxima) > 0 and local_maxima[0] < window_size: local_maxima = local_maxima[1:]\n",
    "        while len(local_maxima) > 0 and local_maxima[-1] >= high_datalen - window_size: local_maxima = local_maxima[:-1]\n",
    "        local_minima = argrelextrema(low_data, lambda x, y: x <= y, order=window_size)[0]\n",
    "        while len(local_minima) > 0 and local_minima[0] < window_size: local_minima = local_minima[1:]\n",
    "        while len(local_minima) > 0 and local_minima[-1] >= low_datalen - window_size: local_minima = local_minima[:-1]\n",
    "        potential_resistance_levels = []\n",
    "        potential_support_levels = []\n",
    "        last_index = self.last_resistance_index\n",
    "        if len(local_maxima) > 0:\n",
    "            potential_resistance_levels = list(high_data[local_maxima])\n",
    "            self.last_resistance_index = max(local_maxima + last_index)\n",
    "            for i, index in enumerate(local_maxima + last_index):\n",
    "                level = potential_resistance_levels[i]\n",
    "                self.new_potential_level = True\n",
    "                if level in self.lines.keys():\n",
    "                    self.lines[level]['cross'] = 0\n",
    "                else:\n",
    "                    bisect.insort(self.all_levels, level)\n",
    "                    self.lines[level] = {}\n",
    "                    self.lines[level]['time'] = self.data['time'][index]\n",
    "                    self.lines[level]['price'] = level\n",
    "                    self.lines[level]['isSupport'] = False\n",
    "                    self.lines[level]['endTime'] = None\n",
    "                    self.lines[level]['cross'] = 0\n",
    "                    self.lines[level]['importance'] = 1\n",
    "        last_index = self.last_support_index\n",
    "        if len(local_minima) > 0:\n",
    "            potential_support_levels = list(low_data[local_minima])\n",
    "            self.last_support_index = max(local_minima + last_index)\n",
    "            for i, index in enumerate(local_minima + last_index):\n",
    "                self.new_potential_level = True\n",
    "                level = potential_support_levels[i]\n",
    "                if level in self.lines.keys():\n",
    "                    self.lines[level]['importance'] += 2\n",
    "                else:\n",
    "                    bisect.insort(self.all_levels, level)\n",
    "                    self.lines[level] = {}\n",
    "                    self.lines[level]['time'] = self.data['time'][index]\n",
    "                    self.lines[level]['price'] = level\n",
    "                    self.lines[level]['isSupport'] = True\n",
    "                    self.lines[level]['endTime'] = None\n",
    "                    self.lines[level]['cross'] = 0\n",
    "                    self.lines[level]['importance'] = 1\n",
    "        self.potential_support_levels += potential_support_levels\n",
    "        self.potential_resistance_levels += potential_resistance_levels\n",
    "\n",
    "    def get_zones(self):\n",
    "        potential_level_prices = np.array(list(self.lines.keys()))\n",
    "        if self.new_potential_level:\n",
    "            levels = self.aggregate_prices_to_levels(potential_level_prices, self.get_distance())\n",
    "            self.recent_zones = levels\n",
    "            self.concat_score()\n",
    "\n",
    "    def concat_score(self):\n",
    "        \"\"\"score each zone using max level importance and update importance by max importance in zone\"\"\"\n",
    "        zones = self.recent_zones\n",
    "        if zones is not None:\n",
    "            for i, level in enumerate(zones):\n",
    "                levels = [x for x in self.lines.keys() if level['minprice'] <= x <= level['maxprice']]\n",
    "                importances = [self.lines[x]['importance'] for x in levels]\n",
    "                times = [self.lines[x]['time'] for x in levels]\n",
    "                zone_score = np.sum(importances)\n",
    "                zones[i]['importance'] = zone_score\n",
    "                zones[i]['time'] = np.min(times)\n",
    "\n",
    "    def score_lines(self, current_index):\n",
    "        open_, high_, low_, close_ = [self.data[col][current_index] for col in ['open', 'high', 'low', 'close']]\n",
    "        if self.score_method == 'candle':\n",
    "            self.score_line_candle(open_, high_, low_, close_)\n",
    "        elif self.score_method == 'swing':\n",
    "            self.score_line_swing(current_index, self.window_size_score)  # 5 is good\n",
    "        elif self.score_method == 'power':\n",
    "            self.score_line_power(current_index, self.window_size_score)  # better be same as window_size\n",
    "\n",
    "    def score_line_power(self, current_index, window_size):\n",
    "        if not self.new_potential_level:\n",
    "            return\n",
    "        if self.last_resistance_index == current_index - window_size:\n",
    "            high = self.data['high'][self.last_resistance_index]\n",
    "            window_low = min(self.data['low'][self.last_resistance_index:current_index+1])\n",
    "            distance = round((high - window_low) / self.atr, 1)\n",
    "            high_minprice = high - (self.atr * self.closeness)\n",
    "            high_maxprice = high + (self.atr * self.closeness)\n",
    "            low_index = bisect.bisect_left(self.all_levels, high_minprice)\n",
    "            high_index = bisect.bisect_right(self.all_levels, high_maxprice)\n",
    "            for level in self.all_levels[low_index:high_index]:\n",
    "                self.lines[level]['importance'] += distance\n",
    "                self.lines[level]['importance'] = round(self.lines[level]['importance'], 1)\n",
    "\n",
    "        if self.last_support_index == current_index - window_size:\n",
    "            low = self.data['low'][self.last_support_index]\n",
    "            window_high = max(self.data['high'][self.last_support_index:current_index+1])\n",
    "            distance = round((window_high - low) / self.atr, 1)\n",
    "            low_minprice = low - (self.atr * self.closeness)\n",
    "            low_maxprice = low + (self.atr * self.closeness)\n",
    "            low_index = bisect.bisect_left(self.all_levels, low_minprice)\n",
    "            high_index = bisect.bisect_right(self.all_levels, low_maxprice)\n",
    "            for level in self.all_levels[low_index:high_index]:\n",
    "                self.lines[level]['importance'] += distance\n",
    "                self.lines[level]['importance'] = round(self.lines[level]['importance'], 1)\n",
    "\n",
    "    def score_line_candle(self, open, high, low, close):\n",
    "        high_minprice = high - (self.atr * self.closeness)\n",
    "        high_maxprice = high + (self.atr * self.closeness)\n",
    "        low_minprice = low - (self.atr * self.closeness)\n",
    "        low_maxprice = low + (self.atr * self.closeness)\n",
    "        for level in self.lines.keys():\n",
    "            if (level >= close and (high_minprice <= level <= high_maxprice) or\n",
    "                    level <= close and (low_minprice <= level <= low_maxprice)):\n",
    "                self.lines[level][\"importance\"] += 1\n",
    "\n",
    "    def score_line_swing(self, current_index, window_size):\n",
    "        if not self.new_potential_level:\n",
    "            return\n",
    "        if self.last_resistance_index == current_index - window_size:\n",
    "            high = self.data['high'][self.last_resistance_index]\n",
    "            high_minprice = high - (self.atr * self.closeness)\n",
    "            high_maxprice = high + (self.atr * self.closeness)\n",
    "            low_index = bisect.bisect_left(self.all_levels, high_minprice)\n",
    "            high_index = bisect.bisect_right(self.all_levels, high_maxprice)\n",
    "            for level in self.all_levels[low_index:high_index]:\n",
    "                self.lines[level]['importance'] += 1\n",
    "\n",
    "        if self.last_support_index == current_index - window_size:\n",
    "            low = self.data['low'][self.last_support_index]\n",
    "            low_minprice = low - (self.atr * self.closeness)\n",
    "            low_maxprice = low + (self.atr * self.closeness)\n",
    "            low_index = bisect.bisect_left(self.all_levels, low_minprice)\n",
    "            high_index = bisect.bisect_right(self.all_levels, low_maxprice)\n",
    "            for level in self.all_levels[low_index:high_index]:\n",
    "                self.lines[level]['importance'] += 1\n",
    "\n",
    "    def aggregate_prices_to_levels(self, prices, distance):\n",
    "        clustering = AgglomerativeClustering(distance_threshold=distance, n_clusters=None)\n",
    "        try:\n",
    "            clustering.fit(prices.reshape(-1, 1))\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(data=prices, columns=('price',))\n",
    "        df['cluster'] = clustering.labels_\n",
    "        df['peak_count'] = 1\n",
    "\n",
    "        grouped = df.groupby('cluster').agg(\n",
    "            {\n",
    "                'price': \"min\",\n",
    "                'peak_count': 'sum'\n",
    "            }\n",
    "        ).reset_index()\n",
    "\n",
    "        grouped2 = df.groupby('cluster').agg(\n",
    "            {\n",
    "                'price': \"max\",\n",
    "                'peak_count': 'sum'\n",
    "            }\n",
    "        ).reset_index()\n",
    "        grouped3 = df.groupby('cluster').agg(\n",
    "            {\n",
    "                'price': \"mean\",\n",
    "                'peak_count': 'sum'\n",
    "            }\n",
    "        ).reset_index()\n",
    "\n",
    "        grouped['meanprice'] = grouped3[\"price\"]\n",
    "        grouped['maxprice'] = grouped2[\"price\"]\n",
    "        grouped = grouped.rename(columns={\"price\": 'minprice'})\n",
    "        return grouped.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f63c9f",
   "metadata": {},
   "source": [
    "# Trend detection functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivots(data_dict, data_index):\n",
    "    pivot_indices = []\n",
    "    pivot_values = []\n",
    "    pivot_state = -1\n",
    "    new_index = 0\n",
    "    if len(data_index) <= 1:\n",
    "        return [], []\n",
    "    for i in range(len(data_index)):\n",
    "        zz_text = data_dict['zigzag_text'][i]\n",
    "        if zz_text == 11:\n",
    "            zz_text = 2\n",
    "        if zz_text == 12:\n",
    "            zz_text = 4\n",
    "        if zz_text == 0:\n",
    "            continue\n",
    "        current_state = (zz_text - 1) // 2\n",
    "        if pivot_state != current_state:\n",
    "            if pivot_state == -1 and current_state >= 0:\n",
    "                pivot_state = current_state\n",
    "                continue\n",
    "            if pivot_state == -1: pivot_state = 1 - current_state\n",
    "            if new_index == 0 and pivot_state == 0:\n",
    "                pivot_values.append(data_dict['high'][0])\n",
    "            elif new_index == 0 and pivot_state == 1:\n",
    "                pivot_values.append(data_dict['low'][0])\n",
    "            else:\n",
    "                pivot_values.append(data_dict['zigzag'][new_index])\n",
    "            pivot_indices.append(new_index)\n",
    "            pivot_state = current_state\n",
    "            new_index = i\n",
    "        else:\n",
    "            new_index = i\n",
    "    if len(pivot_indices) == 0:\n",
    "        return [], []\n",
    "    if pivot_indices[0] != 0:\n",
    "        pivot_indices.insert(0, 0)\n",
    "        if data_dict['low'][0] < pivot_values[0]:\n",
    "            pivot_values.insert(0, data_dict['low'][0])\n",
    "        else:\n",
    "            pivot_values.insert(0, data_dict['high'][0])\n",
    "    if len(data_index) - 1 not in pivot_indices and len(pivot_values) > 0:\n",
    "        pivot_indices.append(len(data_index) - 1)\n",
    "        if data_dict['close'][-1] > pivot_values[-1]:\n",
    "            pivot_values.append(data_dict['high'][-1])\n",
    "        else:\n",
    "            pivot_values.append(data_dict['low'][-1])\n",
    "    return pivot_indices, pivot_values\n",
    "\n",
    "def make_new_pivots(first_pivot, interval, pivot_values, pivot_indices):\n",
    "    current_pivot = first_pivot\n",
    "    new_pivot_values = [pivot_values[0]]\n",
    "    new_pivot_indices = [pivot_indices[0]]\n",
    "    i = 0\n",
    "    while i < len(pivot_indices) - 1:\n",
    "        if current_pivot == 1:\n",
    "            if i + 3 >= len(pivot_indices):\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            elif pivot_values[i + 1] < pivot_values[i + 3]:\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            elif (pivot_values[i + 2] - pivot_values[i + 1]) > (pivot_values[i] - pivot_values[i + 1]):\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            else:\n",
    "                if pivot_values[i + 2] > pivot_values[i]:\n",
    "                    new_pivot_values[-1] = pivot_values[i + 2]\n",
    "                    # new_pivot_indices[-1] = pivot_indices[i + 2]\n",
    "                new_pivot_values.append(pivot_values[i + 3])\n",
    "                new_pivot_indices.append(pivot_indices[i + 3])\n",
    "                i += 3\n",
    "        else:\n",
    "            if i + 3 >= len(pivot_indices):\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            elif pivot_values[i + 1] > pivot_values[i + 3]:\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            elif (pivot_values[i + 1] - pivot_values[i + 2]) > interval * .3 and \\\n",
    "                    pivot_values[i + 1] - pivot_values[i + 2] > (pivot_values[i + 1] - pivot_values[i]) * .7:\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            else:\n",
    "                if pivot_values[i + 2] < pivot_values[i]:\n",
    "                    new_pivot_values[-1] = pivot_values[i + 2]\n",
    "                    # new_pivot_indices[-1] = pivot_indices[i + 2]\n",
    "                new_pivot_values.append(pivot_values[i + 3])\n",
    "                new_pivot_indices.append(pivot_indices[i + 3])\n",
    "                i += 3\n",
    "        current_pivot = -current_pivot\n",
    "    return new_pivot_indices, new_pivot_values\n",
    "\n",
    "def find_trend(data_dict, data_index, start_index, end_index):\n",
    "    data = {x: data_dict[x][start_index:end_index] for x in ['open', 'high', 'low', 'close', 'zigzag', 'zigzag_text']}\n",
    "    data['DateTime'] = data_index[start_index:end_index]\n",
    "    data_len = len(data['close'])\n",
    "    close_data = data['close']\n",
    "    datetimes = data['DateTime']\n",
    "    window_size = 5\n",
    "    # datetimes = datetimes[window_size -1:]\n",
    "    pivot_indices, pivot_values = get_pivots(data, datetimes)\n",
    "    if len(pivot_indices) < 2:\n",
    "        return 0\n",
    "    sum_red_bars, sum_green_bars = 0, 0\n",
    "    weighted_sum_red_bars, weighted_sum_green_bars = 0, 0\n",
    "    sum_up_pct, sum_down_pct = 0, 0\n",
    "    sum_up, sum_down = 0, 0\n",
    "    highs = 0\n",
    "    lows = 0\n",
    "    higher_highs = 0\n",
    "    lower_lows = 0\n",
    "    last_high = 0\n",
    "    last_low = 0\n",
    "    if pivot_values[1] > pivot_values[0]:\n",
    "        last_low = pivot_values[0]\n",
    "    else:\n",
    "        last_high = pivot_values[0]\n",
    "    first_pivot = 0\n",
    "    if len(pivot_indices) > 2:\n",
    "        if pivot_values[1] > pivot_values[2]:\n",
    "            first_pivot = -1\n",
    "        else:\n",
    "            first_pivot = 1\n",
    "    elif len(pivot_indices) == 2:\n",
    "        if pivot_values[1] > pivot_values[0]:\n",
    "            first_pivot = -1\n",
    "        else:\n",
    "            first_pivot = 1\n",
    "    if first_pivot == 1 and close_data[0] > pivot_values[0]:\n",
    "        pivot_values[0] = close_data[0]\n",
    "        pivot_indices[0] = 0\n",
    "    if first_pivot == -1 and close_data[0] < pivot_values[0]:\n",
    "        pivot_values[0] = close_data[0]\n",
    "        pivot_indices[0] = 0\n",
    "    min_price = np.min(close_data)\n",
    "    max_price = np.max(close_data)\n",
    "    interval = max_price - min_price\n",
    "    while True:\n",
    "        new_pivot_indices, new_pivot_values = make_new_pivots(first_pivot, interval, pivot_values, pivot_indices)\n",
    "        if len(new_pivot_values) == len(pivot_values):\n",
    "            break\n",
    "        pivot_indices, pivot_values = new_pivot_indices, new_pivot_values\n",
    "    high_pct = 0\n",
    "    low_pct = 0\n",
    "    first_price = data['open'][0]\n",
    "    last_price = close_data[-1]\n",
    "    overall_change = ((last_price - first_price) / first_price) * 100\n",
    "    num_of_legs = len(pivot_values) - 1\n",
    "    num_of_pairs = num_of_legs // 2\n",
    "    if num_of_pairs <= 0:\n",
    "        if overall_change > 0:\n",
    "            return 3\n",
    "        else:\n",
    "            return -3\n",
    "    high_count = 0\n",
    "    high_sum = 0\n",
    "    low_count = 0\n",
    "    low_sum = 0\n",
    "    high_len = 0\n",
    "    low_len = 0\n",
    "    low_legs = []\n",
    "    high_legs = []\n",
    "    for i in range(1, len(pivot_indices)):\n",
    "        change = pivot_values[i] - pivot_values[i - 1]\n",
    "        if change > 0:\n",
    "            high_count += 1\n",
    "            high_sum += change\n",
    "            high_legs.append(change)\n",
    "            high_len += pivot_indices[i] - pivot_indices[i - 1]\n",
    "        else:\n",
    "            low_count += 1\n",
    "            low_sum += abs(change)\n",
    "            low_legs.append(abs(change))\n",
    "            low_len += pivot_indices[i] - pivot_indices[i - 1]\n",
    "        pct_change = change / pivot_values[i - 1] * 100\n",
    "        if pct_change > 0:\n",
    "            if last_high == 0:\n",
    "                last_high = pivot_values[i]\n",
    "            else:\n",
    "                if pivot_values[i] > last_high:\n",
    "                    highs += 1\n",
    "                    higher_highs += 1\n",
    "                    high_pct += abs(pivot_values[i] - last_high) / last_high * 100\n",
    "                else:\n",
    "                    lows += 1\n",
    "                    low_pct += abs(pivot_values[i] - last_high) / last_high * 100\n",
    "                last_high = pivot_values[i]\n",
    "            sum_green_bars += pivot_indices[i] - pivot_indices[i - 1]\n",
    "            weighted_sum_green_bars += (pivot_indices[i] - pivot_indices[i - 1]) * pct_change\n",
    "            sum_up_pct += pct_change\n",
    "            sum_up += 1\n",
    "        elif pct_change < 0:\n",
    "            if last_low == 0:\n",
    "                last_low = pivot_values[i]\n",
    "            else:\n",
    "                if pivot_values[i] > last_low:\n",
    "                    highs += 1\n",
    "                    high_pct += abs(pivot_values[i] - last_low) / last_low * 100\n",
    "                else:\n",
    "                    lows += 1\n",
    "                    lower_lows += 1\n",
    "                    low_pct += abs(pivot_values[i] - last_low) / last_low * 100\n",
    "                last_low = pivot_values[i]\n",
    "            sum_red_bars += pivot_indices[i] - pivot_indices[i - 1]\n",
    "            weighted_sum_red_bars += (pivot_indices[i] - pivot_indices[i - 1]) * pct_change\n",
    "            sum_down_pct += pct_change\n",
    "            sum_down += 1\n",
    "    diff_sum_pct = sum_up_pct + sum_down_pct\n",
    "    # Calculating the percent changes\n",
    "    if high_sum >= 4 * low_sum:\n",
    "        return 3\n",
    "    if low_sum >= 4 * high_sum:\n",
    "        return -3\n",
    "    max_increase = ((max_price - first_price) / first_price) * 100\n",
    "    min_decrease = ((first_price - min_price) / first_price) * 100\n",
    "    bullish_retracement = ((max_price - last_price) / max_price) * 100\n",
    "    bearish_retracement = ((last_price - min_price) / min_price) * 100\n",
    "    mean_price = np.mean(close_data)\n",
    "    up_mean = mean_price > (np.max(close_data) + np.min(close_data)) / 2\n",
    "    down_mean = mean_price < (np.max(close_data) + np.min(close_data)) / 2\n",
    "    pivot_dist = [(pivot_values[i] - pivot_values[i - 1]) for i in range(1, len(pivot_values))]\n",
    "    max_leg = np.max(pivot_dist)\n",
    "    min_leg = np.min(pivot_dist)\n",
    "    if overall_change > 0 and last_price > (\n",
    "            first_price + max_price) * .4995 and first_price - min_price < last_price - first_price:\n",
    "        if last_price > (first_price + max_price) * .5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "        if max_leg * .5 < abs(min_leg):\n",
    "            result = -1\n",
    "        if max_leg * .75 < abs(min_leg):\n",
    "            return 0\n",
    "        # if up_mean:\n",
    "        if high_pct > low_pct:\n",
    "            if highs >= 1.2 * lows or high_pct > 1.2 * low_pct:\n",
    "                return (result + 2)\n",
    "            else:\n",
    "                return (result + 1)\n",
    "        elif highs > lows:\n",
    "            return (result + 1)\n",
    "        if bullish_retracement < .5 * max_increase:\n",
    "            return result\n",
    "        return 0\n",
    "    elif overall_change < 0 and last_price <= (\n",
    "            first_price + min_price) * .5005 and max_price - first_price < first_price - last_price:\n",
    "        result = -1\n",
    "        if last_price <= (first_price + min_price) * .5:\n",
    "            result = -1\n",
    "        else:\n",
    "            result = 0\n",
    "        if abs(min_leg) * .5 < max_leg:\n",
    "            result = 1\n",
    "        if abs(min_leg) * .75 < max_leg:\n",
    "            return 0\n",
    "        # if down_mean:\n",
    "        if high_pct < low_pct:\n",
    "            if lows >= 1.2 * highs or 1.2 * high_pct < low_pct:\n",
    "                return result - 2\n",
    "            else:\n",
    "                return result - 1\n",
    "        elif highs < lows:\n",
    "            return result - 1\n",
    "        if bearish_retracement < .5 * min_decrease:\n",
    "            return result\n",
    "        return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f661559d",
   "metadata": {},
   "source": [
    "# Function call class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "\t\"ES\": {\n",
    "        \"point_value\": 50,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"NQ\": {\n",
    "        \"point_value\": 20,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"RT\": {\n",
    "        \"point_value\": 50,\n",
    "        \"tick_size\": 0.1\n",
    "    },\n",
    "    \"YM\": {\n",
    "        \"point_value\": 5,\n",
    "        \"tick_size\": 1\n",
    "    },\n",
    "\t\"MES\": {\n",
    "        \"point_value\": 5,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"MNQ\": {\n",
    "        \"point_value\": 2,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"CL\": {\n",
    "        \"point_value\": 1000,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"MCL\": {\n",
    "        \"point_value\": 100,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"GC\": {\n",
    "        \"point_value\": 1000,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"MGC\": {\n",
    "        \"point_value\": 10,\n",
    "        \"tick_size\": 0.1\n",
    "    },\n",
    "    \"NG\": {\n",
    "        \"point_value\": 10000,\n",
    "        \"tick_size\": 0.001\n",
    "    },\n",
    "    \"M2K\": {\n",
    "        \"point_value\": 5,\n",
    "        \"tick_size\": 0.1\n",
    "    },\n",
    "    \"ZB\": {\n",
    "        \"point_value\": 31.25,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"ZC\": {\n",
    "        \"point_value\": 25,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"ZM\": {\n",
    "        \"point_value\": 100,\n",
    "        \"tick_size\": 0.1\n",
    "    },\n",
    "    \"ZL\": {\n",
    "        \"point_value\": 600,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"ZS\": {\n",
    "        \"point_value\": 50,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"ZW\": {\n",
    "        \"point_value\": 50,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"HG\": {\n",
    "        \"point_value\": 25000,\n",
    "        \"tick_size\": 0.005\n",
    "    },\n",
    "    \"MHG\": {\n",
    "        \"point_value\": 2500,\n",
    "        \"tick_size\": 0.005\n",
    "    },\n",
    "    \"HE\": {\n",
    "        \"point_value\": 400,\n",
    "        \"tick_size\": 0.025\n",
    "    },\n",
    "    \"LE\": {\n",
    "        \"point_value\": 400,\n",
    "        \"tick_size\": 0.025\n",
    "    },\n",
    "    \"SI\": {\n",
    "        \"point_value\": 5000,\n",
    "        \"tick_size\": 0.005\n",
    "    },\n",
    "    \"SIL\": {\n",
    "        \"point_value\": 1000,\n",
    "        \"tick_size\": 0.005\n",
    "    },\n",
    "    \"MYM\": {\n",
    "        \"point_value\": 0.5,\n",
    "        \"tick_size\": 1\n",
    "    },\n",
    "    \"6A\": {\n",
    "        \"point_value\": 125000,\n",
    "        \"tick_size\": 5e-05\n",
    "    },\n",
    "    \"6B\": {\n",
    "        \"point_value\": 62500,\n",
    "        \"tick_size\": 0.0001\n",
    "    },\n",
    "    \"6C\": {\n",
    "        \"point_value\": 100000,\n",
    "        \"tick_size\": 5e-05\n",
    "    },\n",
    "    \"6E\": {\n",
    "        \"point_value\": 125000,\n",
    "        \"tick_size\": 5e-05\n",
    "    },\n",
    "    \"6J\": {\n",
    "        \"point_value\": 125000,\n",
    "        \"tick_size\": 5e-05\n",
    "    }\n",
    "}\n",
    "class FunctionCalls:\n",
    "    def __init__(self):\n",
    "        url = 'http://localhost:8086'\n",
    "        token = 'WrSMwFo5b-ngd_gMqp1ZjGijae9QtQRKlNXd9U_8ExvcY0oVjQjZ7-dtmruJX_joU_pMzH72YUibcOX7XrvbBw=='\n",
    "        org = 'TenSurf'\n",
    "        self.bronze_client = InfluxClient(token, org, url, 'bronze')\n",
    "        self.url = url\n",
    "        self.token = token\n",
    "        self.org = org\n",
    "\n",
    "    def detect_trend(self, parameters):\n",
    "        # trends range are in [-3,3]\n",
    "        # -3 represents a strong downtrend, -2: moderate downtrend, -1: weak downtrend, 0: neutral,\n",
    "        # 1: weak uptrend, 2: moderate uptrend, and 3: strong uptrend.\n",
    "        symbol = parameters[\"symbol\"]\n",
    "        start_datetime = parameters[\"start_datetime\"]\n",
    "        end_datetime = parameters[\"end_datetime\"]\n",
    "        if end_datetime is None:\n",
    "            end_datetime = datetime.now()\n",
    "        if start_datetime is None:\n",
    "            start_datetime = end_datetime - timedelta(days=7)\n",
    "        if isinstance(start_datetime, str):\n",
    "            start_datetime = pd.to_datetime(start_datetime)\n",
    "        if isinstance(end_datetime, str):\n",
    "            end_datetime = pd.to_datetime(end_datetime)\n",
    "        df = self.bronze_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        if df is None or len(df) == 0:\n",
    "            print('There is no data for this period of time...')\n",
    "            return 0\n",
    "        else:\n",
    "            data_dict = df.to_dict(orient='list')\n",
    "            data_index = data_dict['DateTime']\n",
    "            return find_trend(data_dict, data_index, 0, len(data_index) - 1)\n",
    "\n",
    "    def calculate_sr(self, parameters):\n",
    "        symbol = parameters[\"symbol\"]\n",
    "        timeframe = parameters[\"timeframe\"]\n",
    "        lookback_days = int(parameters[\"lookback_days\"].split(\" \")[0])\n",
    "        end_datetime = datetime.now()\n",
    "        start_datetime = end_datetime - timedelta(days=lookback_days)\n",
    "        df = self.bronze_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        if df is None or len(df) == 0:\n",
    "            print('There is no data for this period of time...')\n",
    "            return 0\n",
    "        df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "        df = df.set_index('DateTime')\n",
    "        params = {'agglomerative': {'window_size': {'1h': 2, '1d': 2, '1w': 2, '1min': 5}, 'use_maxima': True,\n",
    "                                    'merge_percent': {'1h': .5, '1d': .5, '1w': .25, '1min': .75}, 'max_cross': 2,\n",
    "                                    'score': 'power', 'closeness': {'1h': .25, '1d': .25, '1w': .25, '1min': .25}}}\n",
    "        detector = SRDetector(df, timeframe, params, 'agglomerative')\n",
    "        detector.get_levels()\n",
    "        levels = list(detector.lines.keys())\n",
    "        start_times = [detector.lines[x]['time'] for x in levels]\n",
    "        end_datetimes = [df.index[-1]] * len(levels)\n",
    "        scores = [detector.lines[x]['importance'] for x in levels]\n",
    "        return [levels, start_times, end_datetimes, scores]\n",
    "\n",
    "    def round(self, x):\n",
    "        coef = 1 / self.ticksize\n",
    "        return round(x * coef) / coef\n",
    "    \n",
    "    def calculate_sl(self, parameters):\n",
    "        def get_vwap_stop(vwap_level_names, vwap_values, fill_price, direction):\n",
    "            delta_vwap = vwap_values[1] - vwap_values[0]\n",
    "            if direction == 1:\n",
    "                for i in range(1, 8):\n",
    "                    if vwap_values[i] <= fill_price <= vwap_values[i + 1]:\n",
    "                        return vwap_values[i - 1], vwap_level_names[i - 1]\n",
    "                if fill_price > vwap_values[-1]:\n",
    "                    dist = np.floor((fill_price - vwap_values[-1]) / delta_vwap)\n",
    "                    name = f'{vwap_level_names[-1][:-1]}{int(4 + dist - 1)}'\n",
    "                    return vwap_values[-1] + (dist - 1) * delta_vwap, name\n",
    "                if fill_price > vwap_values[0]:\n",
    "                    return vwap_values[0] - delta_vwap, f'{vwap_level_names[0][:-1]}5'\n",
    "                dist = np.ceil((vwap_values[0] - fill_price) / delta_vwap)\n",
    "                name = f'{vwap_level_names[0][:-1]}{int(4 + dist + 1)}'\n",
    "                return vwap_values[0] - (dist + 1) * delta_vwap, name\n",
    "            else:  # direction == -1\n",
    "                for i in range(1, 8):\n",
    "                    if vwap_values[i - 1] <= fill_price <= vwap_values[i]:\n",
    "                        return vwap_values[i + 1], vwap_level_names[i + 1]\n",
    "                if fill_price < vwap_values[0]:\n",
    "                    dist = np.floor((vwap_values[0] - fill_price) / delta_vwap)\n",
    "                    name = f'{vwap_level_names[0][:-1]}{int(4 + dist - 1)}'\n",
    "                    return vwap_values[0] - (dist - 1) * delta_vwap, name\n",
    "                if fill_price < vwap_values[-1]:\n",
    "                    return vwap_values[-1] + delta_vwap, f'{vwap_level_names[-1][:-1]}5'\n",
    "                dist = np.ceil((fill_price - vwap_values[-1]) / delta_vwap)\n",
    "                name = f'{vwap_level_names[-1][:-1]}{int(4 + dist + 1)}'\n",
    "                return vwap_values[-1] + (dist + 1) * delta_vwap, name\n",
    "\n",
    "        symbol = parameters[\"symbol\"]\n",
    "        ticksize = config[symbol]['tick_size']\n",
    "        self.ticksize = ticksize\n",
    "        direction = parameters[\"direction\"]\n",
    "        method = parameters[\"method\"] if 'method' in parameters else 'nothing'\n",
    "        if method is None or method == '' or method == 'all':\n",
    "            method = 'nothing'\n",
    "        neighborhood = parameters[\"neighborhood\"] if 'neighborhood' in parameters else 20\n",
    "        atr_coef = parameters[\"atr_coef\"] if 'atr_coef' in parameters else 1.5\n",
    "        lookback = parameters[\"lookback\"] if 'lookback' in parameters else 100\n",
    "        min_sl_ticks = parameters[\"min_sl_ticks\"] if 'min_sl_ticks' in parameters else 4\n",
    "        minimum_risk = min_sl_ticks * ticksize\n",
    "        end_datetime = datetime.now()\n",
    "        start_datetime = end_datetime - timedelta(days=4)\n",
    "        df = self.bronze_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        if df is None or len(df) == 0:\n",
    "            print('There is no data for this period of time...')\n",
    "            return {}\n",
    "        siver_client = InfluxClient(self.token, self.org, self.url, 'silver')\n",
    "        df = df.iloc[-23 * 60:]  # Approximately last one day\n",
    "        data_dict = df.to_dict(orient='list')\n",
    "        data_index = data_dict['DateTime']\n",
    "        atr = data_dict['ATR'][-1]\n",
    "        current_index = len(data_dict['close']) - 1\n",
    "        fill_price = data_dict['close'][current_index]\n",
    "        answer = {'sl': [], 'risk': [], 'info': []}\n",
    "        sl_dict = {}\n",
    "        if method in ['swing', 'nothing']:\n",
    "            if direction == 1:\n",
    "                data = np.array(data_dict['low'])\n",
    "                swing_indices = argrelextrema(data, lambda x, y: x < y, order=neighborhood, mode='clip')[0]\n",
    "                if len(swing_indices) and swing_indices[0] < neighborhood:\n",
    "                    swing_indices = swing_indices[1:]\n",
    "                if len(swing_indices) and swing_indices[-1] > len(data) - neighborhood // 2:\n",
    "                    swing_indices = swing_indices[:-1]\n",
    "                for x in swing_indices[::-1]:\n",
    "                    if data[x] < fill_price - minimum_risk:\n",
    "                        sl_dict['swing'] = data[x]\n",
    "                        answer['sl'].append(self.round(data[x]))\n",
    "                        answer['risk'].append(self.round(abs(fill_price - data[x])))\n",
    "                        answer['info'].append(\n",
    "                            f'calculated based on low swing with neighborhood parameter of {neighborhood} candles')\n",
    "            else:\n",
    "                data = np.array(data_dict['high'])\n",
    "                swing_indices = argrelextrema(data, lambda x, y: x > y, order=neighborhood, mode='clip')[0]\n",
    "                if len(swing_indices) and swing_indices[0] < neighborhood:\n",
    "                    swing_indices = swing_indices[1:]\n",
    "                if len(swing_indices) and swing_indices[-1] > len(data) - neighborhood // 2:\n",
    "                    swing_indices = swing_indices[:-1]\n",
    "                for x in swing_indices[::-1]:\n",
    "                    if data[x] > fill_price + minimum_risk:\n",
    "                        sl_dict['swing'] = data[x]\n",
    "                        answer['sl'].append(self.round(data[x]))\n",
    "                        answer['risk'].append(self.round(abs(fill_price - data[x])))\n",
    "                        answer['info'].append(\n",
    "                            f'calculated based on high swing with neighborhood parameter of {neighborhood} candles')\n",
    "        if method in ['minmax', 'nothing']:\n",
    "            if direction == 1:\n",
    "                mm_stop = min(data_dict['low'][- lookback:])\n",
    "                sl_dict['minmax'] = mm_stop\n",
    "                answer['sl'].append(self.round(mm_stop))\n",
    "                answer['risk'].append(self.round(abs(fill_price - mm_stop)))\n",
    "                answer['info'].append(f'calculated based on minimum low price of previous {lookback} candles')\n",
    "\n",
    "            else:\n",
    "                mm_stop = min(data_dict['high'][- lookback:])\n",
    "                sl_dict['minmax'] = mm_stop\n",
    "                answer['sl'].append(self.round(mm_stop))\n",
    "                answer['risk'].append(self.round(abs(fill_price - mm_stop)))\n",
    "                answer['info'].append(f'calculated based on maximum high price of previous {lookback} candles')\n",
    "\n",
    "        if method in ['atr', 'nothing']:\n",
    "            if direction == 1:\n",
    "                atr_stop = fill_price - atr_coef * atr\n",
    "            else:\n",
    "                atr_stop = fill_price + atr_coef * atr\n",
    "            sl_dict['atr'] = atr_stop\n",
    "            answer['sl'].append(self.round(atr_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - atr_stop)))\n",
    "            answer['info'].append(f'calculated based on ATR with length 14 multiplied by the coefficient {atr_coef}')\n",
    "        if method in ['DVWAP_band', 'nothing']:\n",
    "            vwap_level_names = [f'VWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['VWAP'] + [f'VWAP_Top_Band_{i}'\n",
    "                                                                                                    for\n",
    "                                                                                                    i in\n",
    "                                                                                                    range(1, 5)]\n",
    "            vwap_values = [data_dict[x][-1] for x in vwap_level_names]\n",
    "            vwap_stop, level_name = get_vwap_stop(vwap_level_names, vwap_values, fill_price, direction)\n",
    "            answer['sl'].append(self.round(vwap_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - vwap_stop)))\n",
    "            if level_name == 'VWAP':\n",
    "                level_number = 0\n",
    "            elif 'Top' in level_name:\n",
    "                level_number = int(level_name.split('_')[-1])\n",
    "            else:\n",
    "                level_number = -1 * int(level_name.split('_')[-1])\n",
    "            if direction == 1:\n",
    "                if level_number >= 0:\n",
    "                    cur_level = level_number + 2\n",
    "                    bottop = level_number + 1\n",
    "                else:\n",
    "                    cur_level = level_number + 1\n",
    "                    bottop = level_number\n",
    "                    if level_number == -1: cur_level += 1\n",
    "            else:\n",
    "                if level_number <= 0:\n",
    "                    cur_level = level_number - 2\n",
    "                    bottop = level_number - 1\n",
    "                else:\n",
    "                    cur_level = level_number - 1\n",
    "                    bottop = level_number\n",
    "                    if level_number == 1: cur_level -= 1\n",
    "\n",
    "            if direction == 1:\n",
    "                answer['info'].append(\n",
    "                    f'calculated based on {level_name} as the bottom of vwap zone {bottop} (current price is inside vwap zone {cur_level})')\n",
    "            else:\n",
    "                answer['info'].append(\n",
    "                    f'calculated based on {level_name} as the ceiling of vwap zone {bottop} (current price is inside vwap zone {cur_level})')\n",
    "        if method in ['WVWAP_band', 'nothing']:\n",
    "            vwap_level_names = [f'WVWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['WVWAP'] + [\n",
    "                f'WVWAP_Top_Band_{i}'\n",
    "                for i in\n",
    "                range(1, 5)]\n",
    "            vwap_values = [data_dict[x][-1] for x in vwap_level_names]\n",
    "            vwap_stop, level_name = get_vwap_stop(vwap_level_names, vwap_values, fill_price, direction)\n",
    "            answer['sl'].append(self.round(vwap_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - vwap_stop)))\n",
    "            if level_name == 'WVWAP':\n",
    "                level_number = 0\n",
    "            elif 'Top' in level_name:\n",
    "                level_number = int(level_name.split('_')[-1])\n",
    "            else:\n",
    "                level_number = -1 * int(level_name.split('_')[-1])\n",
    "            if direction == 1:\n",
    "                if level_number >= 0:\n",
    "                    cur_level = level_number + 2\n",
    "                    bottop = level_number + 1\n",
    "                else:\n",
    "                    cur_level = level_number + 1\n",
    "                    bottop = level_number\n",
    "                    if level_number == -1: cur_level += 1\n",
    "            else:\n",
    "                if level_number <= 0:\n",
    "                    cur_level = level_number - 2\n",
    "                    bottop = level_number - 1\n",
    "                else:\n",
    "                    cur_level = level_number - 1\n",
    "                    bottop = level_number\n",
    "                    if level_number == 1: cur_level -= 1\n",
    "\n",
    "            if direction == 1:\n",
    "                answer['info'].append(\n",
    "                    f'calculated based on {level_name} as the bottom of wvwap zone {bottop} (current price is inside wvwap zone {cur_level})')\n",
    "            else:\n",
    "                answer['info'].append(\n",
    "                    f'calculated based on {level_name} as the ceiling of wvwap zone {bottop} (current price is inside wvwap zone {cur_level})')\n",
    "        if method in ['zigzag', 'level', 'nothing']:\n",
    "            # Read Silver data\n",
    "            sdf = siver_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "            sdf = sdf.iloc[-1]\n",
    "        if method in ['zigzag', 'nothing']:\n",
    "            if direction == 1:\n",
    "                zz_stop = fill_price  - sdf['ZZ_rth_last5']\n",
    "            else:\n",
    "                zz_stop = fill_price + sdf['ZZ_rth_last5']\n",
    "            answer['sl'].append(self.round(zz_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - zz_stop)))\n",
    "            answer['info'].append(f'Calculated based on the last 5 zigzag legs of the same day of the week')\n",
    "            if direction == 1:\n",
    "                zz_stop = fill_price  - sdf['ZZ_rth_daily']\n",
    "            else:\n",
    "                zz_stop = fill_price + sdf['ZZ_rth_daily']\n",
    "            answer['sl'].append(self.round(zz_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - zz_stop)))\n",
    "            answer['info'].append(f'Calculated based on the last session zigzag')\n",
    "\n",
    "        if method in ['level', 'nothing']:\n",
    "            answer = {'sl': [], 'risk': [], 'info': []}\n",
    "            vwap_level_names = [f'VWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['VWAP'] + [f'VWAP_Top_Band_{i}' for\n",
    "                                                                                                i in\n",
    "                                                                                                range(1, 5)]\n",
    "            vwap_level_names += [f'WVWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['WVWAP'] + [f'WVWAP_Top_Band_{i}'\n",
    "                                                                                                   for i in\n",
    "                                                                                                   range(1, 5)]\n",
    "            vwap_values = [data_dict[x][-1] for x in vwap_level_names]\n",
    "            initial_level_names = ['VP_POC', 'VP_VAL', 'VP_VAH', 'Overnight_high', 'Overnight_low', 'Overnight_mid',\n",
    "                                   'initial_balance_high',\n",
    "                                   'initial_balance_low', 'initial_balance_mid', 'prev_session_max', 'prev_session_min',\n",
    "                                   'prev_session_mid']\n",
    "            level_names = []\n",
    "            level_values = []\n",
    "            for i in range(len(initial_level_names)):\n",
    "                level = initial_level_names[i]\n",
    "                if direction == 1 and sdf[level] < fill_price - minimum_risk or direction == -1 and sdf[\n",
    "                    level] > fill_price + minimum_risk:\n",
    "                    level_values.append(sdf[level])\n",
    "                    level_names.append(level)\n",
    "            for i in range(len(vwap_level_names)):\n",
    "                level = vwap_level_names[i]\n",
    "                if direction == 1 and vwap_values[i] < fill_price - minimum_risk or direction == -1 and vwap_values[\n",
    "                    i] > fill_price + minimum_risk:\n",
    "                    level_values.append(vwap_values[i])\n",
    "                    level_names.append(level)\n",
    "            for x, y in zip(level_names, level_values):\n",
    "                answer['sl'].append(self.round(y))\n",
    "                answer['risk'].append(self.round(abs(fill_price - y)))\n",
    "                answer['info'].append(f'calculated based on the level {x}')\n",
    "\n",
    "            best_level = {}\n",
    "            for col in [ 'weekly_SR', 'daily_SR', 'hourly_SR','5min_SR']:\n",
    "                if col not in sdf:\n",
    "                    continue\n",
    "                sr_levels = eval(sdf[col])\n",
    "                for i, val in enumerate(sr_levels['values']):\n",
    "                    if direction == 1 and val < fill_price - minimum_risk:\n",
    "                        if col not in best_level or val > best_level[col]['sl']:\n",
    "                            best_level[col] = {'sl': val, 'info':f'calculate based on {\" \".join(col.split(\"_\"))} level starting from {sr_levels[\"start_time\"][i]}'}\n",
    "                    if direction == -1 and val > fill_price + minimum_risk:\n",
    "                        if col not in best_level or val < best_level[col]['sl']:\n",
    "                            best_level[col] = {'sl': val, 'info':f'calculate based on {\" \".join(col.split(\"_\"))} level starting from {sr_levels[\"start_time\"][i]}'}\n",
    "            for col in best_level:\n",
    "                answer['sl'].append(self.round(best_level[col]['sl']))\n",
    "                answer['risk'].append(self.round(abs(fill_price - best_level[col]['sl'])))\n",
    "                answer['info'].append(best_level[col]['info'])\n",
    "        if direction == 1:\n",
    "            sorted_items = sorted(zip(answer['sl'], answer['risk'], answer['info']), key=lambda x: x[0], reverse=True)\n",
    "        else:\n",
    "            sorted_items = sorted(zip(answer['sl'], answer['risk'], answer['info']), key=lambda x: x[0])\n",
    "        return {'sl': [item[0] for item in sorted_items],\n",
    "                'risk': [item[1] for item in sorted_items],\n",
    "                'info': [item[2] for item in sorted_items]}\n",
    "\n",
    "    def calculate_tp(self, parameters):\n",
    "        symbol = parameters[\"symbol\"]\n",
    "        ticksize = config[symbol]['tick_size']\n",
    "        self.ticksize = ticksize\n",
    "        direction = parameters[\"direction\"]\n",
    "        sl = parameters[\"stoploss\"]\n",
    "        method = parameters[\"method\"] if 'method' in parameters else 'nothing'\n",
    "        end_datetime = datetime.now()\n",
    "        start_datetime = end_datetime - timedelta(days=4)\n",
    "        df = self.bronze_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        if df is None or len(df) == 0:\n",
    "            print('There is no data for this period of time...')\n",
    "            return {}\n",
    "        siver_client = InfluxClient(self.token, self.org, self.url, 'silver')\n",
    "        df = df.iloc[-23 * 60:]  # Approximately last one day\n",
    "        data_dict = df.to_dict(orient='list')\n",
    "        data_index = data_dict['DateTime']\n",
    "        atr = data_dict['ATR'][-1]\n",
    "        current_index = len(data_dict['close']) - 1\n",
    "        fill_price = data_dict['close'][current_index]\n",
    "        risk = abs(fill_price - sl)\n",
    "        answer = {'tp': [], 'info': []}\n",
    "        sdf = siver_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        sdf = sdf.iloc[-1]\n",
    "        answer = {'tp': [], 'info': []}\n",
    "        vwap_level_names = [f'VWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['VWAP'] + [f'VWAP_Top_Band_{i}' for\n",
    "                                                                                            i in\n",
    "                                                                                            range(1, 5)]\n",
    "        vwap_level_names += [f'WVWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['WVWAP'] + [f'WVWAP_Top_Band_{i}'\n",
    "                                                                                               for i in\n",
    "                                                                                               range(1, 5)]\n",
    "        vwap_values = [data_dict[x][-1] for x in vwap_level_names]\n",
    "        initial_level_names = ['VP_POC', 'VP_VAL', 'VP_VAH', 'Overnight_high', 'Overnight_low', 'Overnight_mid',\n",
    "                               'initial_balance_high',\n",
    "                               'initial_balance_low', 'initial_balance_mid', 'prev_session_max', 'prev_session_min',\n",
    "                               'prev_session_mid']\n",
    "        level_names = []\n",
    "        level_values = []\n",
    "        for i in range(len(initial_level_names)):\n",
    "            level = initial_level_names[i]\n",
    "            if direction == 1 and sdf[level] > fill_price + risk or direction == -1 and sdf[\n",
    "                level] < fill_price - risk:\n",
    "                level_values.append(sdf[level])\n",
    "                level_names.append(level)\n",
    "        for i in range(len(vwap_level_names)):\n",
    "            level = vwap_level_names[i]\n",
    "            if direction == 1 and  vwap_values[i] > fill_price + risk or direction == -1 and vwap_values[i] < fill_price - risk:\n",
    "                level_values.append(vwap_values[i])\n",
    "                level_names.append(level)\n",
    "        for x, y in zip(level_names, level_values):\n",
    "            answer['tp'].append(self.round(y))\n",
    "            answer['info'].append(f'calculated based on the level {x}')\n",
    "\n",
    "        best_level = {}\n",
    "        for col in [ 'weekly_SR', 'daily_SR', 'hourly_SR','5min_SR']:\n",
    "            if col not in sdf:\n",
    "                continue\n",
    "            sr_levels = eval(sdf[col])\n",
    "            for i, val in enumerate(sr_levels['values']):\n",
    "                if direction == 1 and val > fill_price + risk:\n",
    "                    if col not in best_level or val < best_level[col]['tp']:\n",
    "                        best_level[col] = {'tp': val, 'info':f'calculate based on {\" \".join(col.split(\"_\"))} level starting from {str(sr_levels[\"start_time\"][i])[:19]}'}\n",
    "                if direction == -1 and val > fill_price + risk:\n",
    "                    if col not in best_level or val < best_level[col]['tp']:\n",
    "                        best_level[col] = {'tp': val, 'info':f'calculate based on {\" \".join(col.split(\"_\"))} level starting from {str(sr_levels[\"start_time\"][i])[:19]}'}\n",
    "        for col in best_level:\n",
    "            answer['tp'].append(self.round(best_level[col]['tp']))\n",
    "            answer['info'].append(best_level[col]['info'])\n",
    "        if direction == -1:\n",
    "            sorted_items = sorted(zip(answer['tp'], answer['info']), key=lambda x: x[0], reverse=True)\n",
    "        else:\n",
    "            sorted_items = sorted(zip(answer['tp'], answer['info']), key=lambda x: x[0])\n",
    "        return {'tp': [item[0] for item in sorted_items],\n",
    "                'info': [item[1] for item in sorted_items]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffacbe58",
   "metadata": {},
   "source": [
    "### Make object of FunctionCalls class and call a method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd2e9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #You should create an instance of the FunctionCalls class whenever you want to call a function of it.\n",
    "\n",
    "# #Example: To find trend of last 10 days\n",
    "# now = datetime.now()\n",
    "# fc = FunctionCalls()\n",
    "# parameters = {\n",
    "#     \"symbol\": \"ES\",\n",
    "#     \"start_datetime\": f\"{now - timedelta(days=10)}\",\n",
    "#     \"end_datetime\": f\"{now}\"\n",
    "# }\n",
    "# trend = fc.detect_trend(parameters)\n",
    "# trend_name = {-3:'Strong downward',-2:'Downward',-1:'Weak downward', 0:'No trend', 3:'Strong upward', 2:'Upward', 1:'Weak upward'}\n",
    "# print(f'Trend type: <<{trend_name[trend]}>>')\n",
    "# print('-'*40)\n",
    "# #Example: To find S/R of last 10 days on 1h timeframe data\n",
    "# fc = FunctionCalls()\n",
    "# parameters = {\n",
    "#     \"symbol\": \"ES\",\n",
    "#     \"timeframe\": \"1h\",\n",
    "#     \"lookback_days\": \"10 days\"\n",
    "# }\n",
    "# sr_value, sr_start_date, sr_end_date, sr_importance = fc.calculate_sr(parameters)\n",
    "# print(f'sr_values = {sr_value}\\nsr_start_dates = {sr_start_date}\\nsr_end_dates = {sr_end_date}\\nsr_importances = {sr_importance}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd13f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #'method' key in the parameters can be one of the following methods:\n",
    "# # swing , minmax , atr , zigzag , DVWAP_band , WVWAP_band , level , all\n",
    "# # if method not set, the result is based on all methods\n",
    "# fc = FunctionCalls()\n",
    "# # parameters = {\"symbol\": \"ES\",\"direction\": 1, 'method':'level'}\n",
    "# parameters = {\"symbol\": \"NQ\", \"method\": \"minmax\", \"direction\": \"-1\", \"lookback\": 30, \"neighborhood\": 50, \"atr_coef\": 1.3}\n",
    "# stoploss = fc.calculate_sl(parameters)\n",
    "# print(stoploss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #'method' key in the parameters can be one of the following methods:\n",
    "# # swing , minmax , atr , zigzag , DVWAP_band , WVWAP_band , level , all\n",
    "# # if method not set, the result is based on all methods\n",
    "# fc = FunctionCalls()\n",
    "# parameters = {\"symbol\": \"ES\",\"direction\": 1, 'stoploss':5124.75}\n",
    "# takeprofit = fc.calculate_tp(parameters)\n",
    "# print(takeprofit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
