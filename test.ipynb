{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from main import llm_surf\n",
    "import input_filter\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing each function individualy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "detect_trend_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the trend of NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00?\",\n",
    "    \"What is the trend of NQ stock for the past week?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"What is the trend?\",\n",
    "    # \"Show me the trend of ES from May-1-2024 12:00:00 to May-5-2024 12:00:00.\",\n",
    "    # \"Trend of GC, May-1-2024 12:00:00 to May-5-2024 12:00:00\",\n",
    "    # \"Trend of GC, past 2 hours\",\n",
    "    # \"What is the trend of NQ from May-1-2024 12:00:00 until now?\",\n",
    "    # # Challenging Prompts\n",
    "    # \"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\",\n",
    "    \"What is the trend of NQ stock from May-20-2024 15:45:30 until Apr-24-2024 15:45:30?\",\n",
    "    # \"What is the trend of NQ stock from 20/4/2024 15:45:30 until 24/3/2024 15:45:30?\",\n",
    "    # \"What is the trend of NQ stock from 4/20/2024 15:45:30 until 4/24/2024 15:45:30?\",\n",
    "    \"Trend of Gold in the last month?\",\n",
    "    # \"Trend in the last month\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'async_generator' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m input_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_message\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m prompt\n\u001b[1;32m     10\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 11\u001b[0m output_json \u001b[38;5;241m=\u001b[39m \u001b[43mllm_surf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m    =>    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Work/TenSurf/TenSurf_Brain/main.py:205\u001b[0m, in \u001b[0;36mllm_surf\u001b[0;34m(llm_input)\u001b[0m\n\u001b[1;32m    201\u001b[0m     MA \u001b[38;5;241m=\u001b[39m Multi_Agent(\n\u001b[1;32m    202\u001b[0m         ChatWithOpenai\u001b[38;5;241m=\u001b[39mChatWithOpenai, client\u001b[38;5;241m=\u001b[39mazure_connector_surf\u001b[38;5;241m.\u001b[39mclient\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m     graph \u001b[38;5;241m=\u001b[39m MA\u001b[38;5;241m.\u001b[39minitialize_graph()\n\u001b[0;32m--> 205\u001b[0m     llm_output \u001b[38;5;241m=\u001b[39m \u001b[43mMA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_multi_agent_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# running in single-agent mode\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODE\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Work/TenSurf/TenSurf_Brain/multi_agent/multi_agent.py:132\u001b[0m, in \u001b[0;36mMulti_Agent.generate_multi_agent_answer\u001b[0;34m(self, input_json, graph)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_multi_agent_answer\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_json, graph):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# async for message in graph.astream(\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m#     {\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m#     pass\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# generated_messages = message\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     generated_messages \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mastream(\n\u001b[1;32m    122\u001b[0m         {\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m150\u001b[39m},\n\u001b[1;32m    131\u001b[0m     )\n\u001b[0;32m--> 132\u001b[0m     generated_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerated_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(generated_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generated_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][k]:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'async_generator' object is not iterable"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "detect_trend_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in detect_trend_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    detect_trend_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/detect_trend_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(detect_trend_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Support and Resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sr_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 10 minutes.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM with the timeframe of 1 hour.\",\n",
    "    \"How much is the sr of CL for the past week?\",\n",
    "    # Challenging prompts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "response: ([38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38721.0, 38842.0, 38754.0], [Timestamp('2024-06-03 10:10:00'), Timestamp('2024-06-04 03:00:00'), Timestamp('2024-06-04 06:30:00'), Timestamp('2024-06-04 09:00:00'), Timestamp('2024-06-05 07:10:00'), Timestamp('2024-06-07 05:40:00'), Timestamp('2024-06-07 07:40:00'), Timestamp('2024-06-07 10:20:00'), Timestamp('2024-06-07 12:00:00'), Timestamp('2024-06-10 02:20:00'), Timestamp('2024-06-10 05:20:00'), Timestamp('2024-06-10 06:20:00')], [Timestamp('2024-06-03 11:00:00'), Timestamp('2024-06-04 03:50:00'), Timestamp('2024-06-04 07:20:00'), Timestamp('2024-06-04 09:50:00'), Timestamp('2024-06-05 08:00:00'), Timestamp('2024-06-07 06:30:00'), Timestamp('2024-06-07 08:30:00'), Timestamp('2024-06-07 11:10:00'), Timestamp('2024-06-07 12:50:00'), Timestamp('2024-06-10 03:10:00'), Timestamp('2024-06-10 06:10:00'), Timestamp('2024-06-10 21:30:00')], [Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00')], [4.7, 3.0, 5.9, 3.4, 4.1, 6.4, 3.8, 5.2, 4.3, 2.9, 4.8, 10.1], 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 10min are as follows:\\n\\n- Levels: [38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38721.0, 38842.0, 38754.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.')\n",
      "\n",
      "Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 10 minutes.    =>    {'response': 'Great! If you have any more questions or need further assistance, feel free to ask. Happy trading!\\nSure! I can help you with that. Let me calculate the support and resistance levels for YM based on a lookback period of 10 days and a timeframe of 10 minutes.', 'chart_info': {'levels_prices': [38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38721.0, 38842.0, 38754.0], 'levels_start_timestamps': [Timestamp('2024-06-03 10:10:00'), Timestamp('2024-06-04 03:00:00'), Timestamp('2024-06-04 06:30:00'), Timestamp('2024-06-04 09:00:00'), Timestamp('2024-06-05 07:10:00'), Timestamp('2024-06-07 05:40:00'), Timestamp('2024-06-07 07:40:00'), Timestamp('2024-06-07 10:20:00'), Timestamp('2024-06-07 12:00:00'), Timestamp('2024-06-10 02:20:00'), Timestamp('2024-06-10 05:20:00'), Timestamp('2024-06-10 06:20:00')], 'levels_detect_timestamps': [Timestamp('2024-06-03 11:00:00'), Timestamp('2024-06-04 03:50:00'), Timestamp('2024-06-04 07:20:00'), Timestamp('2024-06-04 09:50:00'), Timestamp('2024-06-05 08:00:00'), Timestamp('2024-06-07 06:30:00'), Timestamp('2024-06-07 08:30:00'), Timestamp('2024-06-07 11:10:00'), Timestamp('2024-06-07 12:50:00'), Timestamp('2024-06-10 03:10:00'), Timestamp('2024-06-10 06:10:00'), Timestamp('2024-06-10 21:30:00')], 'levels_end_timestamps': [Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00')], 'levels_scores': [4.7, 3.0, 5.9, 3.4, 4.1, 6.4, 3.8, 5.2, 4.3, 2.9, 4.8, 10.1], 'function_name': 'calculate_sr', 'symbol': 'YM', 'timeframe': '10min', 'response': 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 10min are as follows:\\n\\n- Levels: [38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38721.0, 38842.0, 38754.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.'}}\n",
      "Inference Time: 30.869540452957153 seconds\n",
      "\n",
      "response: ([38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38721.0, 38842.0, 38754.0], [Timestamp('2024-06-03 10:10:00'), Timestamp('2024-06-04 03:00:00'), Timestamp('2024-06-04 06:30:00'), Timestamp('2024-06-04 09:00:00'), Timestamp('2024-06-05 07:10:00'), Timestamp('2024-06-07 05:40:00'), Timestamp('2024-06-07 07:40:00'), Timestamp('2024-06-07 10:20:00'), Timestamp('2024-06-07 12:00:00'), Timestamp('2024-06-10 02:20:00'), Timestamp('2024-06-10 05:20:00'), Timestamp('2024-06-10 06:20:00')], [Timestamp('2024-06-03 11:00:00'), Timestamp('2024-06-04 03:50:00'), Timestamp('2024-06-04 07:20:00'), Timestamp('2024-06-04 09:50:00'), Timestamp('2024-06-05 08:00:00'), Timestamp('2024-06-07 06:30:00'), Timestamp('2024-06-07 08:30:00'), Timestamp('2024-06-07 11:10:00'), Timestamp('2024-06-07 12:50:00'), Timestamp('2024-06-10 03:10:00'), Timestamp('2024-06-10 06:10:00'), Timestamp('2024-06-10 21:30:00')], [Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00'), Timestamp('2024-06-10 21:35:00')], [4.7, 3.0, 5.9, 3.4, 4.1, 6.4, 3.8, 5.2, 4.3, 2.9, 4.8, 10.1], 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 10min are as follows:\\n\\n- Levels: [38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38721.0, 38842.0, 38754.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_sr_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_sr_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    calculate_sr_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_sr_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_sr_results, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'response': 'The support and resistance levels for YM (E-mini Dow Jones Industrial Average) based on historical price data with a lookback period of 10 days and a timeframe of 10 minutes are as follows:\\n\\n- Support Levels: 38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38837.0\\n- Resistance Levels: 38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38837.0\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.', 'chart_info': {'levels_prices': [38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38837.0], 'levels_start_timestamps': [Timestamp('2024-06-03 10:10:00'), Timestamp('2024-06-04 03:00:00'), Timestamp('2024-06-04 06:30:00'), Timestamp('2024-06-04 09:00:00'), Timestamp('2024-06-05 07:10:00'), Timestamp('2024-06-07 05:40:00'), Timestamp('2024-06-07 07:40:00'), Timestamp('2024-06-07 10:20:00'), Timestamp('2024-06-07 12:00:00'), Timestamp('2024-06-07 13:00:00')], 'levels_detect_timestamps': [Timestamp('2024-06-03 11:00:00'), Timestamp('2024-06-04 03:50:00'), Timestamp('2024-06-04 07:20:00'), Timestamp('2024-06-04 09:50:00'), Timestamp('2024-06-05 08:00:00'), Timestamp('2024-06-07 06:30:00'), Timestamp('2024-06-07 08:30:00'), Timestamp('2024-06-07 11:10:00'), Timestamp('2024-06-07 12:50:00'), Timestamp('2024-06-07 13:50:00')], 'levels_end_timestamps': [Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00')], 'levels_scores': [4.7, 3.0, 5.9, 3.4, 4.1, 4.5, 3.8, 5.2, 4.3, 2.2], 'function_name': 'calculate_sr', 'symbol': 'YM', 'timeframe': '10min'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Stop Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sl_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?\",\n",
    "    \"What would be the stop loss of trading long positinos based on ES and swing method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and atr method and attribute coefficient of 1.3?\",\n",
    "    \"What would be the stop loss of trading long positinos based on YM and level method?\",\n",
    "    \"What would be the stop loss of trading long positinos based on NQ and DVWAP_band method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and WVWAP_band method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on GC and zigzag method?\",\n",
    "    \"What would be the stop loss of trading long positinos based on ES?\",\n",
    "    # Challenging prompts\n",
    "    \"How much would be the stop loss for trading?\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?    =>    {'response': 'FINAL ANSWER\\n\\nThe stop loss for trading short positions based on NQ using the minmax method and looking back up to 30 candles would be at 19018.5. The risk on this trade is 11.25 points. This stop loss is calculated based on the maximum high price of the previous 30 candles.', 'chart_info': {}}\n",
      "Inference Time: 26.93732476234436 seconds\n",
      "What would be the stop loss of trading long positinos based on ES and swing method?    =>    {'response': 'The stop loss for trading long positions based on ES using the swing method is determined to be at the following levels: 5351.25, 5341.0, and 5329.0. The associated risks for these trades are 2.25, 12.5, and 24.5 points, respectively. These stop loss levels were calculated based on low swings with a neighborhood parameter of 20 candles.', 'chart_info': {}}\n",
      "Inference Time: 26.80545997619629 seconds\n",
      "What would be the stop loss of trading short positinos based on NQ and atr method and attribute coefficient of 1.3?    =>    {'response': 'The stop loss for trading short positions based on the NQ and ATR method with an attribute coefficient of 1.3 is 19045.25. The risk on the trade is 15.5 points. This calculation is based on the ATR (Average True Range) with a length of 14, multiplied by the coefficient of 1.3.', 'chart_info': {}}\n",
      "Inference Time: 21.1414577960968 seconds\n",
      "What would be the stop loss of trading long positinos based on YM and level method?    =>    {'response': 'These stop loss levels are determined based on historical price data and indicate the price levels at which a trader should consider exiting a long position to limit potential losses. The associated risk values indicate the potential loss if the price moves against the trade. It is important to note that these levels are calculated based on different levels such as VWAP_Bottom_Band, prev_session_min, hourly SR levels, WVWAP, initial_balance_low, and 5min SR levels.', 'chart_info': {}}\n",
      "Inference Time: 46.951791524887085 seconds\n",
      "What would be the stop loss of trading long positinos based on NQ and DVWAP_band method?    =>    {'response': 'The stop loss for trading long positions on NQ based on the DVWAP_band method would be set at 18994.25. This stop loss is calculated based on the VWAP_Bottom_Band_3 as the bottom of the VWAP zone -3, with the current price being inside the VWAP zone -2. The risk on this trade is 35.5 points.', 'chart_info': {}}\n",
      "Inference Time: 19.487579822540283 seconds\n",
      "What would be the stop loss of trading short positinos based on NQ and WVWAP_band method?    =>    {'response': 'The stop loss for trading short positions on NQ based on the WVWAP_band method would be at 19165.5. The risk on this trade is 135.75 points. This stop loss is calculated based on WVWAP_Top_Band_3 as the ceiling of the WVWAP zone 3, with the current price being inside the WVWAP zone 2.', 'chart_info': {}}\n",
      "Inference Time: 178.77534079551697 seconds\n",
      "What would be the stop loss of trading short positinos based on GC and zigzag method?    =>    {'response': 'Based on the GC symbol and the zigzag method, the stop loss for short positions would be at 2315.86 and 2316.9. The risk associated with these stop loss levels is 4.66 and 5.7, respectively. These stop loss levels were calculated based on the last 5 zigzag legs of the same day of the week and the last session zigzag.', 'chart_info': {}}\n",
      "Inference Time: 117.76244521141052 seconds\n",
      "What would be the stop loss of trading long positinos based on ES?    =>    {'response': 'The stop loss for trading long positions based on ES would be 5347.5 and 5346.25. The risk on each trade would be 6.0 and 7.25 respectively. These values are calculated based on the last 5 zigzag legs of the same day of the week and the last session zigzag.', 'chart_info': {}}\n",
      "Inference Time: 36.70917105674744 seconds\n",
      "How much would be the stop loss for trading?    =>    {'response': 'Sure, I can help you calculate the stop loss for trading. Please provide me with the ticker symbol of the financial instrument you want to trade.', 'chart_info': None}\n",
      "Inference Time: 6.681099891662598 seconds\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_sl_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_sl_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    calculate_sl_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_sl_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_sl_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Take-Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_tp_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"How much would be the take-profit of trading based on NQ, long positions and stop loss of 100?\",\n",
    "    \"How much would be the take-profit of trading based on NQ and stop loss of 100?\",\n",
    "    \"How much would be the take-profit of trading based on NQ and long positions?\",\n",
    "    \"How much would be the take-profit of trading based on long positions and stop loss of 100?\",\n",
    "    \"How much would be the take-profit?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much would be the take-profit of trading based on NQ, long positions and stop loss of 100?    =>    {'response': 'I apologize, but it seems that there are no specific take-profit levels available for trading based on NQ, long positions, and a stop loss of 100. The calculation did not provide any results.', 'chart_info': {}}\n",
      "Inference Time: 35.621543407440186 seconds\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_tp_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_tp_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    calculate_tp_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_tp_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_tp_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "get_bias_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Tell me about the bias of ES on the market.\",\n",
    "    \"What is the current trading bias for ES?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about the bias of ES on the market.    =>    {'response': 'Based on the analysis of different methods, the bias of ES on the market is determined to be bullish. This conclusion is supported by multiple indicators, including the weekly VWAP, VAL/VAH of volume profile, short-term trend, mid-term trend, long-term trend, trend of the last hour, and counter ratio and power ratio. The combined bias is also bullish.', 'chart_info': {}}\n",
      "What is the current trading bias for ES?    =>    {'response': 'The current trading bias for ES is bullish. This is determined based on various methods including weekly VWAP, VAL/VAH of volume profile, short term trend, mid term trend, long term trend, trend of last hour, and counter ratio and power ratio. The combined bias is also bullish.', 'chart_info': {}}\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "get_bias_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in get_bias_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    get_bias_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/get_bias_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(get_bias_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "introduction_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Who are you?\",\n",
    "    \"What are you?\",\n",
    "    \"What can you do for me?\",\n",
    "    \"What are your functionalities?\",\n",
    "    \"How can you help me?\",\n",
    "    # Challenging prompts\n",
    "    \"Hi!\",\n",
    "    \"Good Morning!\",\n",
    "    \"What's up!?\",\n",
    "    \"How can I start?\",\n",
    "    \"Please help me!\",\n",
    "    \"What is TenSurf?\",\n",
    "    \"How could you help me?\",\n",
    "    # \"What about market today?\",\n",
    "    \"Could you guide me on how to use tensurf?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "introduction_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in introduction_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    introduction_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/introduction_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(introduction_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odd Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "odd_prompts = [\n",
    "\t\"Trend in the last month\" ,\n",
    "\t\"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\" ,\n",
    "\t\"What about market today?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "odd_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in odd_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    odd_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/odd_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(odd_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close Irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Chat Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_chat_scenario_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Hello\",\n",
    "    \"Who are you?\",\n",
    "    \"What can you do for me?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"For the past week\",\n",
    "    \"Can you also calculate the sr of it, too?\",\n",
    "    \"But how about the trend of it for the last month?\",\n",
    "    \"But how about the trend of it for the last year?\",\n",
    "    \"But how about the trend of it for the last day?\",\n",
    "    \"But how about the trend of it for the last hour?\",\n",
    "    \"Hi!\",\n",
    "    \"Can you calculate the sr of it?\",\n",
    "    \"What else can you do?\",\n",
    "    \"So how would be the stop loss for the short position?\",\n",
    "    \"How about long ones?\",\n",
    "    \"So what would be the take profit based on this stop loss?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "long_chat_scenario_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in long_chat_scenario_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    long_chat_scenario_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/long_chat_scenario_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(long_chat_scenario_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_function_calling_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the ternd and sr of NQ?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "parallel_function_calling_results = {}\n",
    "\n",
    "# # getting the answer of the prompts\n",
    "# try:\n",
    "for prompt in parallel_function_calling_prompts:\n",
    "    input_json = {\n",
    "        \"file_path\": None,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    parallel_function_calling_results[prompt]=output_json\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"test_results/parallel_function_calling_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(parallel_function_calling_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of file paths and prompts\n",
    "messages = []\n",
    "\n",
    "file_paths = [\"samplefiles/TjqcZqip.png\", 'samplefiles/applyjobs.xlsx', 'samplefiles/paper.docx',\n",
    "              'samplefiles/sample.pdf', 'samplefiles/transcription.txt', 'samplefiles/english.mp3', None]\n",
    "\n",
    "general_prompts = [\"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"What is the trend of NQ stock from 3/10/2023 15:45:30 until 3/11/2023 15:45:30?\"]\n",
    "\n",
    "# Iterate over file_paths and prompts and run the code\n",
    "for file_path, prompt in zip(file_paths, general_prompts):\n",
    "    input_json = {\n",
    "        \"file_path\": file_path,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the speed of light?    =>    I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\n",
      "tell me about english teaching    =>    I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\n"
     ]
    }
   ],
   "source": [
    "irrelevant_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the speed of light?\",\n",
    "    \"tell me about english teaching\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]\n",
    "\n",
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "irrelevant_results = {}\n",
    "\n",
    "# # getting the answer of the prompts\n",
    "# try:\n",
    "for prompt in irrelevant_prompts:\n",
    "    input_json = {\n",
    "        \"file_path\": file_path,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    irrelevant_results[prompt]=output_json\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"test_results/irrelevant_prompts_results.json\", \"w\") as outputfile: \n",
    "    json.dump(irrelevant_results, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech file detected. Processing speech...\n",
      "Speech processing complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The main idea of this file is to provide information about long-term trading in the stock market. It explains that long-term trading involves buying shares of a company and holding onto them for an extended period, with the goal of benefiting from the company's growth over time and earning dividends. Long-term traders are often categorized as investors or position traders.\",\n",
       " {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'samplefiles/tts_test.mp3'\n",
    "messages = []\n",
    "prompt = None\n",
    "\n",
    "input_json = {\n",
    "    \"file_path\": file_path,\n",
    "    \"prompt\": None,\n",
    "    \"messages\": messages,\n",
    "    \"front_json\": input_filter.front_end_json_sample\n",
    "}\n",
    "\n",
    "output_json = main.main(input_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The founders of Microsoft are Bill Gates and Paul Allen. They established the company on April 4, 1975, with the goal of developing and selling software for personal computers. Bill Gates is particularly known for his role in shaping the company's vision and strategy, while Paul Allen played a significant role in technical aspects and product development.\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurf.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '74b3de375b964f73a6b7668fe459e26f'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Corporation was founded by Bill Gates and Paul Allen. Bill Gates, currently one of the world's wealthiest individuals, served as Microsoft's Chairman and CEO for many years before transitioning to a role as a technology advisor. Paul Allen was a prominent philanthropist and entrepreneur who co-founded Microsoft with Bill Gates, but he passed away in 2018.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '80ddd1ad72504f2fa226755d49491a61'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\deepeval\\__init__.py:42: UserWarning: You are using deepeval version 0.21.43, however version 0.21.45 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from UnitTest import unit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_test.unit_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
