{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VkDMcuAkyfpD"
      },
      "outputs": [],
      "source": [
        "# from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "# class CustomCallbackHandler(BaseCallbackHandler):\n",
        "#     def on_tool_start(self, tool_name: str, **kwargs):\n",
        "#         print(f\"Tool {tool_name} started with arguments: {kwargs}\")\n",
        "\n",
        "#     def on_tool_end(self, tool_name: str, output: str, **kwargs):\n",
        "#         print(f\"Tool {tool_name} finished with output: {output}\")\n",
        "\n",
        "#     def on_llm_start(self, **kwargs):\n",
        "#         print(\"LLM started\")\n",
        "\n",
        "#     def on_llm_end(self, output: str, **kwargs):\n",
        "#         print(f\"LLM finished with output: {output}\")\n",
        "\n",
        "# # Example usage\n",
        "# handler = CustomCallbackHandler()\n",
        "\n",
        "# # Simulating some events\n",
        "# handler.on_tool_start(\"example_tool\", arg1=\"value1\", arg2=\"value2\")\n",
        "# handler.on_tool_end(\"example_tool\", output=\"tool output\")\n",
        "# handler.on_llm_start()\n",
        "# handler.on_llm_end(output=\"LLM output\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfknVBncqyyR"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvP4kQpiU3bz",
        "outputId": "ee8b36e8-91b4-4e1c-c5d1-c5da3c0e45d1"
      },
      "outputs": [],
      "source": [
        "# !pip install Openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcrPkYWKEnFJ",
        "outputId": "5ca313f0-57f9-4535-eefb-218849064323"
      },
      "outputs": [],
      "source": [
        "# !apt install libgraphviz-dev\n",
        "# !pip install pygraphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V8z7XbSFNAh",
        "outputId": "6fca4cde-7c14-4fc6-ee1a-d6a9531359ca"
      },
      "outputs": [],
      "source": [
        "# !pip install zigzag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnLtdz5cFwdn",
        "outputId": "664d8643-cd1f-465b-fba5-d996cbc3be5e"
      },
      "outputs": [],
      "source": [
        "# !pip install influxdb_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiiOvTlEm1vz",
        "outputId": "ef19ed85-d9c6-4a7c-9530-fb1219332b96"
      },
      "outputs": [],
      "source": [
        "# !pip install import_ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZo2S6-jmtdz",
        "outputId": "d23e3cba-be7b-4420-8ff4-0a1f3a7702d5"
      },
      "outputs": [],
      "source": [
        "# !pip install crewai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m7_gzAqnAk7",
        "outputId": "f24c19f3-58ec-4f8b-9740-4e9f9252f130"
      },
      "outputs": [],
      "source": [
        "# !pip install unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_bBjlk-nErZ",
        "outputId": "45237238-d28c-4eb9-ceb9-60caa7e2592f"
      },
      "outputs": [],
      "source": [
        "# !pip install langgraph langchain langchain_openai langchainhub langchain-core langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et1N1I-snLxA",
        "outputId": "956705fb-8d92-478a-8fad-c9ae3b594c88"
      },
      "outputs": [],
      "source": [
        "# !pip install sec_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1zEYTDlG2iP",
        "outputId": "4684dc57-8a34-40c3-d483-7ea8437f1141"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBv2qwKEGp18",
        "outputId": "32381004-cac3-4287-db60-b948dd1305af"
      },
      "outputs": [],
      "source": [
        "# !pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yp-I-elhFmoz",
        "outputId": "a8babb51-ae33-4db8-cba7-32a688154d41"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/saeid976/researcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVaURl9SEzMm"
      },
      "source": [
        "# Function_call notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q40lkyLGnjWy"
      },
      "outputs": [],
      "source": [
        "# %run functions_python.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QVnAbvAnZIi-"
      },
      "outputs": [],
      "source": [
        "# fc = FunctionCalls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "chkHPIgMZATp"
      },
      "outputs": [],
      "source": [
        "import functions_python\n",
        "import input_filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sqCrGtqPn8zd"
      },
      "outputs": [],
      "source": [
        "# fc = functions_python.FunctionCalls()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScRdMcIrHYZX"
      },
      "source": [
        "# Langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3e30lMEBHFcy"
      },
      "outputs": [],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool\n",
        "from langgraph.prebuilt import ToolExecutor\n",
        "from typing import Optional, Type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlPLaNe4GjgH"
      },
      "source": [
        "## On boarding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "446r9He4Go5K"
      },
      "outputs": [],
      "source": [
        "# !pip install psycopg2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gCKEDbC-ogr2"
      },
      "outputs": [],
      "source": [
        "# import psycopg2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gPAJPkmMGsbX"
      },
      "outputs": [],
      "source": [
        "# class SaveTradingStyle(BaseModel):\n",
        "#     \"\"\"save the style of trading.\"\"\"\n",
        "\n",
        "#     userId: float = Field(..., description=\"user id\")\n",
        "\n",
        "\n",
        "# def trading_style_saver(userId: float) -> str:\n",
        "#     try:\n",
        "#         # Connect to the PostgreSQL server\n",
        "#         conn = psycopg2.connect(\n",
        "#             dbname=\"tensurf\",\n",
        "#             user=\"tensurf\",\n",
        "#             password=\"tensurf\",\n",
        "#             host=\"135.181.158.245\",\n",
        "#             port=\"5432\"\n",
        "#         )\n",
        "\n",
        "#         # Create a cursor object\n",
        "#         cur = conn.cursor()\n",
        "\n",
        "#         trading_style = input(\"What is your trading style (day trader, swing trader, or both)? \")\n",
        "#         cur.execute(\"SELECT COUNT(*) FROM onboarding_user WHERE id = %s\",(userId,))\n",
        "#         count = cur.fetchone()[0]\n",
        "#         if count > 0:\n",
        "#             cur.execute(\"UPDATE onboarding_user SET trading_style=%s WHERE id=%s\",(trading_style, userId))\n",
        "#         else:\n",
        "#             cur.execute(\"INSERT INTO onboarding_user (id,trading_style) values (%s,%s)\", (userId, trading_style))\n",
        "\n",
        "#         conn.commit()\n",
        "#         cur.close()\n",
        "#         conn.close()\n",
        "\n",
        "#         return \"Trading style is saved successfully.\"\n",
        "\n",
        "#     except psycopg2.Error as e:\n",
        "#         return f\"Error in trading_style_saver: {e}\"\n",
        "\n",
        "\n",
        "# databaseStyle = StructuredTool.from_function(\n",
        "#     func=trading_style_saver,\n",
        "#     name=\"SaveTradingStyle\",\n",
        "#     description=\"save the style of trading\",\n",
        "#     args_schema=SaveTradingStyle,\n",
        "#     return_direct=False,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pMvPszfGG0VH"
      },
      "outputs": [],
      "source": [
        "# class SaveRiskPercentage(BaseModel):\n",
        "#     \"\"\"Get the info of the trader about how much risk they take for trading.\"\"\"\n",
        "\n",
        "#     userId: float = Field(..., description=\"user id\")\n",
        "\n",
        "# def risk_percentage_saver(userId) -> str:\n",
        "#     # Save risk percentage to the database\n",
        "#     try:\n",
        "#         # Connect to the PostgreSQL server\n",
        "#         conn = psycopg2.connect(\n",
        "#             dbname=\"tensurf\",\n",
        "#             user=\"tensurf\",\n",
        "#             password=\"tensurf\",\n",
        "#             host=\"135.181.158.245\",\n",
        "#             port=\"5432\"\n",
        "#         )\n",
        "\n",
        "#         # Create a cursor object\n",
        "#         cur = conn.cursor()\n",
        "\n",
        "#         cur.execute(\"SELECT COUNT(*) FROM onboarding_user WHERE id = %s\",(userId,))\n",
        "#         while True:\n",
        "#             percentage = float(input(\"What is the maximum percentage of your capital that you want to risk in trade (0-100)? \"))\n",
        "#             if 0 <= percentage <= 100:\n",
        "#                 break\n",
        "#             else:\n",
        "#                 print(\"Please enter a positive float number between 0 and 100.\")\n",
        "#         count = cur.fetchone()[0]\n",
        "#         if count > 0:\n",
        "#             cur.execute(\"UPDATE onboarding_user SET risk_parameter=%s WHERE id=%s\",(percentage, userId))\n",
        "#         else:\n",
        "#             cur.execute(\"INSERT INTO onboarding_user (id,risk_parameter) values (%s,%s)\", (userId, percentage))\n",
        "\n",
        "#         # Commit the transaction\n",
        "#         conn.commit()\n",
        "#         cur.close()\n",
        "#         conn.close()\n",
        "\n",
        "#         return \"percentage of risk is saved successfully.\"\n",
        "\n",
        "#     except psycopg2.Error as e:\n",
        "#         return f\"Error in risk_percentage_saver: {e}\"\n",
        "\n",
        "\n",
        "# databaseRisk = StructuredTool.from_function(\n",
        "#     func=risk_percentage_saver,\n",
        "#     name=\"SaveRiskPercentage\",\n",
        "#     description=\"Get the info of the trader about how much risk they take for trading.\",\n",
        "#     args_schema=SaveRiskPercentage,\n",
        "#     return_direct=False,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5mB3KvXDG06h"
      },
      "outputs": [],
      "source": [
        "# def check_user_id():\n",
        "#     try:\n",
        "#         # Connect to the PostgreSQL server\n",
        "#         conn = psycopg2.connect(\n",
        "#             dbname=\"tensurf\",\n",
        "#             user=\"tensurf\",\n",
        "#             password=\"tensurf\",\n",
        "#             host=\"135.181.158.245\",\n",
        "#             port=\"5432\"\n",
        "#         )\n",
        "\n",
        "#         # Create a cursor object\n",
        "#         cur = conn.cursor()\n",
        "#         user_id = input(\"What is your id?\")\n",
        "#         # Query to check if the user_id exists in the table\n",
        "#         cur.execute(\"SELECT COUNT(*) FROM onboarding_user WHERE id = %s\",(user_id,))\n",
        "#         count = cur.fetchone()[0]\n",
        "\n",
        "#         if count > 0:\n",
        "#           return user_id\n",
        "\n",
        "#         else:\n",
        "#           return f\"User with user_id= {user_id} does not exist in the table.\"\n",
        "\n",
        "#     except psycopg2.Error as e:\n",
        "#       return f\"Error in check_user_id: {e}\"\n",
        "\n",
        "# databaseId = StructuredTool.from_function(\n",
        "#     func=check_user_id,\n",
        "#     name=\"CheckUserId\",\n",
        "#     description=\"Checking the id of the user\",\n",
        "#     return_direct=False,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "behgQf7V1wNk"
      },
      "source": [
        "## Calculate Stop Loss:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "enrMEMS7HaTe"
      },
      "outputs": [],
      "source": [
        "class PropertiesCalculateSl(BaseModel):\n",
        "\tsymbol: Optional[str] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\n",
        "\tmethod: Optional[str] = Field(None, description=\"shows the method of SL calculation.\")\n",
        "\n",
        "\tdirection: Optional[int] = Field(None, description=\"-1: means the user want to calculate stoploss for a short position. 1: means the user want to calculate stoploss for a long position\")\n",
        "\n",
        "\tlookback: Optional[int] = Field(None, description=\"it is used when the method is set to 'minmax' and shows the number of candles that the SL is calculated based on them.\")\n",
        "\n",
        "\tneighborhood: Optional[int] = Field(None, description=\"A parameter that is used in the swing method to define the range or window within which swings are detected. example: \\\n",
        "If the 'neighborhood' parameter is set to 3, it means that the swing detection is based on considering 3 candles to the \\\n",
        "left and 3 candles to the right of the swing point.\")\n",
        "\n",
        "\tatr_coef: Optional[int] = Field(None, description=\"it is used if the method is 'atr' and shows the coefficient of atr\")\n",
        "\n",
        "\n",
        "class CalculateSL(BaseTool):\n",
        "\tname = \"calculate_sl\"\n",
        "\tdescription = \"\"\"Stoploss (SL) is a limitation for potential losses in a position. It's below the current price for long position and above it for short position. \\\n",
        "Distance between the SL and current price is named risk value. This function calculates the SL based o some different methods. \\\n",
        "Returns A dictionary same as this: \\\n",
        "{'sl': [17542.5], 'risk': [268.5], 'info': ['calculated based on maximum high price of previous 100 candles']} \\\n",
        "which includes sl value, risk on the trade and an information. \\\n",
        "If user don't select any method for sl calculation or select \"level\" method, or zigzag method the otput can include \\\n",
        "more than one stoploss and the values type in the output can be a list such as this \\\n",
        "{'sl': [17542.5, 17818.25, 17858.5, 17882.5, 18518.75], 'risk': [268.5, 7.25, 47.5, 71.5, 707.75], 'info': ['minmax', 'swing', 'atr', '5min_SR', 'daily_SR']} \\\n",
        "It includes a list of stoplosses and the risk on them and finally the level or method name of stoploss.\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesCalculateSl\n",
        "\n",
        "\tdef _run(\n",
        "        self, symbol: str = None, method: str = None, direction: int = None,\n",
        "\t\tlookback: int = None, neighborhood: int = None, atr_coef: int = None\n",
        "    ) -> int:\n",
        "\t\tparameters = {\n",
        "                      \"symbol\": symbol,\n",
        "                      \"method\": method,\n",
        "                      \"direction\": direction,\n",
        "                      \"lookback\": lookback,\n",
        "                      \"neighborhood\": neighborhood,\n",
        "                      \"atr_coef\": atr_coef\n",
        "                      }\n",
        "\t\t\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\t\t\n",
        "\t\treturn fc.calculate_sl(parameters)\n",
        "\n",
        "SL = CalculateSL()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EciRRD4YELCo"
      },
      "source": [
        "## Calculate Take-Profit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JianU1wXGZL3"
      },
      "outputs": [],
      "source": [
        "class PropertiesCalculateTp(BaseModel):\n",
        "\tsymbol: Optional[str] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\n",
        "\tdirection: Optional[int] = Field(None, description=\"-1: means the user want to calculate stoploss for a short position. 1: means the user want to calculate stoploss for a long position\")\n",
        "\n",
        "\tstoploss: Optional[int] = Field(None, description=\"the value for stoploss\")\n",
        "\n",
        "\n",
        "class CalculateTp(BaseTool):\n",
        "\tname = \"calculate_tp\"\n",
        "\tdescription = \"\"\"Take profit (TP) is opposite of the stop-loss (SL) and is based on maximum reward that we intend to achieve from a trade. \\\n",
        "It represents the price level at which a trader aims to close a position to secure profits before the market reverses. \\\n",
        "Returns list of price for take-profit and information for each price For exampe: \\\n",
        "{'tp': [5139.25, 5140.25, 5144.0], 'info': ['calculated based on the level VWAP_Top_Band_2', 'calculated based on the level Overnight_high', 'calculated based on the level VWAP_Top_Band_3']}\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesCalculateTp\n",
        "\n",
        "\tdef _run(\n",
        "        self, symbol: str = None, direction: int = None, stoploss: int = None\n",
        "    ) -> int:\n",
        "\t\tparameters = {\n",
        "\t\t\t\t\t\t\"symbol\": symbol,\n",
        "\t\t\t\t\t\t\"direction\": direction,\n",
        "\t\t\t\t\t\t\"stoploss\": stoploss\n",
        "\t\t\t\t\t\t}\n",
        "\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\t\t\n",
        "\t\treturn fc.calculate_tp(parameters)\n",
        "\n",
        "TP = CalculateTp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt4sSmAQH1Ph"
      },
      "source": [
        "## Trend Detection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZM38gBSZEjBk"
      },
      "outputs": [],
      "source": [
        "class PropertiesCalculateTrend(BaseModel):\n",
        "\tsymbol: Optional[str] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\n",
        "\tstart_datetime: Optional[str] = Field(None, description=\"The start timestamp of period over which the analysis is done. \\\n",
        "\tThe format of the date should be in the following format %b-%d-%y %H:%M:%S like this example: May-1-2024 13:27:49\")\n",
        "\tend_datetime: Optional[str] = Field(None, description=\"The end timestamp of period over which the analysis is done. \\\n",
        "\tThe format of the date should be in the following format %b-%d-%y %H:%M:%S like this example: May-1-2024 13:27:49. \\\n",
        "\tThe user can set this parameter to now. In this situation this parameter's value is the current date time.\")\n",
        "\n",
        "\tlookback: Optional[str] = Field(None, description=\"The number of seconds, minutes, hours, days, weeks, months or years to look back for calculating the trend of the given symbol. \\\n",
        "This parameter determines the depth of historical data to be considered in the analysis. The format of this value must obey one of the following examples: 30 seconds, 10 minutes, 2 hours, 5 days, 3 weeks, 2 months and 3 years. \\\n",
        "Either start_datetime along with end_datetime should be specified or lookback should be specified but both cases should not happen simultaneously.\")\n",
        "\n",
        "class CalculateTrend(BaseTool):\n",
        "\tname = \"detect_trend\"\n",
        "\tdescription = \"\"\"Analyzes the trend of a specified financial instrument over a given time range. \\\n",
        "It is designed primarily for financial data analysis, enabling users to gauge the general direction of a security or market index. \\\n",
        "Whether start_datetime with end_datetime, end_datetime with lookback or lookback parameters could be valued for determining the period over which's trend wants to be detected. \\\n",
        "The function returns a numerical value that indicates the trend intensity and direction within the specified parameters. \\\n",
        "Returns a number between -3 and 3 that represents the trend’s intensity and direction. The value is interpreted as follows: \\\n",
        "\\n -3: strong bearish (downward) trend \\\n",
        "\\n -2: moderate bearish (downward) trend \\\n",
        "\\n -1: mild bearish (downward) trend \\\n",
        "\\n 0: without significant trend \\\n",
        "\\n 3: strong bullish (upward) trend \\\n",
        "\\n 2: moderate bullish (upward) trend \\\n",
        "\\n 1: mild bullish (upward) trend\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesCalculateTrend\n",
        "\n",
        "\tdef _run(\n",
        "\t\t\tself, symbol: str = None, start_datetime: str = None, end_datetime: str = None, lookback: str = None\n",
        "    ) -> dict:\n",
        "\n",
        "\t\tfunction_arguments = {\n",
        "\t\t\t\t\t\t\"symbol\": symbol,\n",
        "\t\t\t\t\t\t\"start_datetime\": start_datetime,\n",
        "\t\t\t\t\t\t\"end_datetime\": end_datetime,\n",
        "\t\t\t\t\t\t\"lookback\": lookback\n",
        "\t\t\t\t\t\t}\n",
        "\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\t\t\n",
        "\t\treturn fc.detect_trend(function_arguments)\n",
        "\n",
        "\n",
        "Trend = CalculateTrend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AahZLwrkH-G-"
      },
      "source": [
        "## Calculate Support and Resistance Levels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Gv2RBUw3H6s_"
      },
      "outputs": [],
      "source": [
        "class PropertiesCalculateSR(BaseModel):\n",
        "\tsymbol: Optional[str] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\ttimeframe: Optional[str] = Field(None, description=\"Specifies the timeframe of the candlestick chart to be analyzed. \\\n",
        "\tThis parameter defines the granularity of the data used for calculating the levels. The only allowed formats would like 3h, 20min, 1d.\")\n",
        "\tlookback_days: Optional[str] = Field(None, description=\"The number of days to look back for calculating the support and resistance levels. \\\n",
        "This parameter determines the depth of historical data to be considered in the analysis. (e.g. 10 days)\")\n",
        "\n",
        "class CalculateSR(BaseTool):\n",
        "\tname = \"calculate_sr\"\n",
        "\tdescription = \"\"\"Support and resistance levels represent price points on a chart where the odds favor a pause or reversal of a prevailing trend. \\\n",
        "This function analyzes candlestick charts over a specified timeframe and lookback period to calculate these levels and their respective strengths. \\\n",
        "Returns a dictionary containing five lists, each corresponding to a specific aspect of the calculated support and resistance levels: \\\n",
        "1. levels_prices (list of floats): The prices at which support and resistance levels have been identified. \\\n",
        "2. levels_start_timestamps (list of timestamps) \\\n",
        "3. levels_detect_timestamps (list of timestamps) \\\n",
        "4. levels_end_timestamps (list of timestamps) \\\n",
        "5. levels_scores (list of floats): Scores associated with each level, indicating the strength or significance of the level. Higher scores typically imply stronger levels.\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesCalculateSR\n",
        "\n",
        "\tdef _run(\n",
        "\t\t\tself, symbol: str = None, timeframe: str = None, lookback_days: str = None\n",
        "    ) -> dict:\n",
        "\t\tparameters = {\n",
        "\t\t\t\t\t\t\"symbol\": symbol,\n",
        "\t\t\t\t\t\t\"timeframe\": timeframe,\n",
        "\t\t\t\t\t\t\"lookback_days\": lookback_days\n",
        "\t\t\t\t\t\t}\n",
        "\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\t\t\n",
        "\t\treturn fc.calculate_sr(parameters)\n",
        "\n",
        "SR = CalculateSR()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALEtGCoWoI_2"
      },
      "source": [
        "## Bias detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Xj0NnY7OoRtF"
      },
      "outputs": [],
      "source": [
        "class PropertiesBiasDetection(BaseModel):\n",
        "\tsymbol: Optional[str] = Field(None, description=\"The ticker symbol of the financial instrument to be analyzed.\")\n",
        "\n",
        "\tmethod: Optional[str] = Field(None, description=\"The user can choose from different methods including MC, Zigzag trend, \\\n",
        "Trend detection, weekly wvap, candle stick pattern, cross ma, vp detection ,power & counter ratio.\")\n",
        "\n",
        "class BiasDetection(BaseTool):\n",
        "\tname = \"bias_detection\"\n",
        "\tdescription = \"\"\"Detecting trading bias through different methods or Detecting the appropriate entry point for a long or short trade.\n",
        "Returns a number between -3 and 3 that represents the trend’s intensity and direction. The value is interpreted as follows:\n",
        "-3: Strong downward , -2: downward -1: Weak downward, 0: No significant trend / Neutral, 1: Weak upward, 2.upward, 3: Strong upward\"\"\"\n",
        "\n",
        "\targs_schema: Type[BaseModel] = PropertiesBiasDetection\n",
        "\n",
        "\tdef _run(\n",
        "        self, symbol: str = None, method: str = None\n",
        "    ) -> dict:\n",
        "\n",
        "\t\tparameters = {\n",
        "\t\t\t\t\t\t\"symbol\": symbol,\n",
        "\t\t\t\t\t\t\"method\": method\n",
        "\t\t\t\t\t\t}\n",
        "\n",
        "\t\tfc = functions_python.FunctionCalls()\n",
        "\t\t\n",
        "\t\treturn fc.get_bias(parameters)\n",
        "\n",
        "Bias = BiasDetection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwjkTlbXlsgC"
      },
      "source": [
        "## Financial tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tPZezZDc4HaZ"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['AZURE_EMBEDDING_MODEL'] ='embedding-ada-002'\n",
        "# os.environ['LLM_PROVIDER'] = 'groq'\n",
        "# os.environ[\"AZURE_OPENAI_API_KEY\"] =  \"80ddd1ad72504f2fa226755d49491a61\"\n",
        "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://tensurfbrain1.openai.azure.com/\"\n",
        "# os.environ[\"OPENAI_API_VERSION\"] = \"2023-10-01-preview\"\n",
        "# os.environ['EMBEDDING_PROVIDER']='azureopenai'\n",
        "# os.environ['SMART_LLM_MODEL']='llama3-70b-8192'\n",
        "# os.environ['TAVILY_API_KEY']='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'\n",
        "# os.environ['GROQ_API_KEY'] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6BLvYUSu9cJs",
        "outputId": "f897ed80-3169-4aa4-db66-d31d6baaead4"
      },
      "outputs": [],
      "source": [
        "# from gpt_researcher import GPTResearcher\n",
        "# import asyncio\n",
        "# from dotenv import load_dotenv\n",
        "# import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "2pgbq2vu9c2W",
        "outputId": "d4ac3024-7897-441b-8ff1-88a7886dc60e"
      },
      "outputs": [],
      "source": [
        "# query = \"what day is today?\"\n",
        "# report_type = \"research_report\"\n",
        "\n",
        "# researcher = GPTResearcher(query, report_type)\n",
        "# report = await researcher.conduct_research()\n",
        "# report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7_Y5zF-Ol0oi",
        "outputId": "b2582d80-7491-4691-bfb0-4385732f30f8"
      },
      "outputs": [],
      "source": [
        "# from langchain.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
        "# from langchain.text_splitter            import CharacterTextSplitter\n",
        "# from langchain.embeddings               import AzureOpenAIEmbeddings\n",
        "# from langchain_community.vectorstores   import FAISS\n",
        "# from unstructured.partition.html        import partition_html\n",
        "# from sec_api                            import QueryApi\n",
        "# import requests\n",
        "# import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "k1sZSRy4cGWU"
      },
      "outputs": [],
      "source": [
        "# api_type = \"azure\"\n",
        "# api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "# api_version = '2023-10-01-preview'\n",
        "# api_key = '80ddd1ad72504f2fa226755d49491a61'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Uj86R_SODN7t"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "IojgHYsIDP7j"
      },
      "outputs": [],
      "source": [
        "# api_type = \"azure\"\n",
        "# api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "# api_version = '2023-10-01-preview'\n",
        "# api_key = '80ddd1ad72504f2fa226755d49491a61'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Z4wONgm_DpdO"
      },
      "outputs": [],
      "source": [
        "# client = AzureOpenAI(\n",
        "#     api_key=api_key,\n",
        "#     api_version=api_version,\n",
        "#     azure_endpoint=api_endpoint\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qNPoFrgXDVvZ"
      },
      "outputs": [],
      "source": [
        "# def generate_embeddings(text, model='embedding-ada-002'):\n",
        "#   return client.embeddings.create(input = [text], model=model).data[0].embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXLc0iHYZ48v"
      },
      "source": [
        "### Search tools:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "280xJBiDmFrH"
      },
      "outputs": [],
      "source": [
        "# class PropertiesSearchTheInternet(BaseModel):\n",
        "#     query: str = Field(..., description=\"A random topic that will be searched on the internet\")\n",
        "\n",
        "\n",
        "# class SearchTheInternet(BaseTool):\n",
        "#     name = \"SearchTheInternet\"\n",
        "#     description = \"\"\"Useful to search the internet about a a given topic and return relevant results\"\"\"\n",
        "\n",
        "#     args_schema: Type[BaseModel] = PropertiesSearchTheInternet\n",
        "\n",
        "#     def _run(\n",
        "#         self, query: str\n",
        "#     ) -> dict:\n",
        "#             top_result_to_return = 4\n",
        "#             url = \"https://google.serper.dev/search\"\n",
        "#             payload = json.dumps({\"q\": query})\n",
        "#             headers = {\n",
        "#                 'X-API-KEY': '77976766163a61a4bae1ed8672ae79e916955783',\n",
        "#                 'content-type': 'application/json'\n",
        "#             }\n",
        "#             response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "#             results = response.json()['organic']\n",
        "#             string = []\n",
        "#             for result in results[:top_result_to_return]:\n",
        "#               try:\n",
        "#                 string.append('\\n'.join([\n",
        "#                     f\"Title: {result['title']}\", f\"Link: {result['link']}\",\n",
        "#                     f\"Snippet: {result['snippet']}\", \"\\n-----------------\"\n",
        "#                 ]))\n",
        "#               except KeyError:\n",
        "#                 next\n",
        "\n",
        "#             return '\\n'.join(string)\n",
        "\n",
        "# SearchInternet = SearchTheInternet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "J6Ou8CTPZIp9"
      },
      "outputs": [],
      "source": [
        "# SearchInternet.run(\"Apple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "EawXSHEOXRFq"
      },
      "outputs": [],
      "source": [
        "# class PropertiesSearchNews(BaseModel):\n",
        "#     query: str = Field(..., description=\"A random topic that will be searched on the internet\")\n",
        "\n",
        "\n",
        "# class SearchNews(BaseTool):\n",
        "#     name = \"SearchNews\"\n",
        "#     description = \"\"\"Useful to search news about a company, stock or any other topic and return relevant results\"\"\"\n",
        "\n",
        "#     args_schema: Type[BaseModel] = PropertiesSearchNews\n",
        "\n",
        "#     def _run(\n",
        "#         self, query: str\n",
        "#     ) -> dict:\n",
        "#             top_result_to_return = 4\n",
        "#             url = \"https://google.serper.dev/news\"\n",
        "#             payload = json.dumps({\"q\": query})\n",
        "#             headers = {\n",
        "#                 'X-API-KEY': '77976766163a61a4bae1ed8672ae79e916955783',\n",
        "#                 'content-type': 'application/json'\n",
        "#             }\n",
        "#             response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "#             results = response.json()['news']\n",
        "#             string = []\n",
        "#             for result in results[:top_result_to_return]:\n",
        "#               try:\n",
        "#                 string.append('\\n'.join([\n",
        "#                     f\"Title: {result['title']}\", f\"Link: {result['link']}\",\n",
        "#                     f\"Snippet: {result['snippet']}\", \"\\n-----------------\"\n",
        "#                 ]))\n",
        "#               except KeyError:\n",
        "#                 next\n",
        "\n",
        "#             return '\\n'.join(string)\n",
        "\n",
        "# NewsSearch = SearchNews()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nNVEG3bmZzf0"
      },
      "outputs": [],
      "source": [
        "# NewsSearch.run(\"NQ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etCFxbh3Z8iv"
      },
      "source": [
        "### SECTools:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "TvUHS5EHbzb2"
      },
      "outputs": [],
      "source": [
        "# def download_form_html(url):\n",
        "#   headers = {\n",
        "#     'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
        "#     'Accept-Encoding': 'gzip, deflate, br',\n",
        "#     'Accept-Language': 'en-US,en;q=0.9,pt-BR;q=0.8,pt;q=0.7',\n",
        "#     'Cache-Control': 'max-age=0',\n",
        "#     'Dnt': '1',\n",
        "#     'Sec-Ch-Ua': '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\"',\n",
        "#     'Sec-Ch-Ua-Mobile': '?0',\n",
        "#     'Sec-Ch-Ua-Platform': '\"macOS\"',\n",
        "#     'Sec-Fetch-Dest': 'document',\n",
        "#     'Sec-Fetch-Mode': 'navigate',\n",
        "#     'Sec-Fetch-Site': 'none',\n",
        "#     'Sec-Fetch-User': '?1',\n",
        "#     'Upgrade-Insecure-Requests': '1',\n",
        "#     'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
        "#   }\n",
        "\n",
        "#   response = requests.get(url, headers=headers)\n",
        "\n",
        "#   return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Pl1QuMSZb2sL"
      },
      "outputs": [],
      "source": [
        "# def embedding_search(url, ask):\n",
        "#   text = download_form_html(url)\n",
        "#   elements = partition_html(text=text)\n",
        "#   content = \"\\n\".join([str(el) for el in elements])\n",
        "#   text_splitter = CharacterTextSplitter(\n",
        "#       separator = \"\\n\",\n",
        "#       chunk_size = 1000,\n",
        "#       chunk_overlap  = 150,\n",
        "#       length_function = len,\n",
        "#       is_separator_regex = False,\n",
        "#   )\n",
        "#   docs = text_splitter.create_documents([content])\n",
        "#   retriever = FAISS.from_documents(\n",
        "#       docs, AzureOpenAIEmbeddings()\n",
        "#     ).as_retriever()\n",
        "#   retriever = FAISS.from_documents(\n",
        "#     docs, client.embeddings\n",
        "#   ).as_retriever()\n",
        "#   answers = retriever.get_relevant_documents(ask, top_k=4)\n",
        "#   answers = \"\\n\\n\".join([a.page_content for a in answers])\n",
        "\n",
        "#   return answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "CbRpT87iaNZy"
      },
      "outputs": [],
      "source": [
        "# class PropertiesSearch10q(BaseModel):\n",
        "#     stock: str = Field(..., description=\"A random stock.\")\n",
        "#     ask: str = Field(..., description=\"Question from the 10-Q of the stock\")\n",
        "\n",
        "\n",
        "# class Search10q(BaseTool):\n",
        "#     name = \"Search10q\"\n",
        "#     description = \"\"\"Useful to search information from the latest 10-Q form for a given stock.\n",
        "#                      The input to this tool should be a pipe (|) separated text of\n",
        "#                      length two, representing the stock ticker you are interested and what\n",
        "#                      question you have from it.\n",
        "#                      For example, `AAPL|what was last quarter's revenue`.\"\"\"\n",
        "\n",
        "#     args_schema: Type[BaseModel] = PropertiesSearch10q\n",
        "\n",
        "#     def _run(\n",
        "#         self, stock: str, ask: str\n",
        "#     ) -> dict:\n",
        "#             queryApi = QueryApi(api_key=\"befd094ddadf6a9e080bf194b6d9197e753ec1d4226fc8e595ed717b2f1bc3a5\")\n",
        "#             query = {\n",
        "#               \"query\": {\n",
        "#                 \"query_string\": {\n",
        "#                   \"query\": f\"ticker:{stock} AND formType:\\\"10-Q\\\"\"\n",
        "#                 }\n",
        "#               },\n",
        "#               \"from\": \"0\",\n",
        "#               \"size\": \"1\",\n",
        "#               \"sort\": [{ \"filedAt\": { \"order\": \"desc\" }}]\n",
        "#             }\n",
        "\n",
        "#             fillings = queryApi.get_filings(query)['filings']\n",
        "#             if len(fillings) == 0:\n",
        "#               return \"Sorry, I couldn't find any filling for this stock, check if the ticker is correct.\"\n",
        "#             link = fillings[0]['linkToFilingDetails']\n",
        "#             answer = embedding_search(link, ask)\n",
        "#             return answer\n",
        "\n",
        "# TenQ = Search10q()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "zpdtHTRAcJ72"
      },
      "outputs": [],
      "source": [
        "# TenQ.run({\"stock\":\"AAPL\", \"ask\":\"what was last quarter's revenue.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "g4Qb73vldAkP"
      },
      "outputs": [],
      "source": [
        "# class PropertiesSearch10k(BaseModel):\n",
        "#     stock: str = Field(..., description=\"A random stock.\")\n",
        "#     ask: str = Field(..., description=\"Question from the 10-k of the stock\")\n",
        "\n",
        "\n",
        "# class Search10k(BaseTool):\n",
        "#     name = \"Search10k\"\n",
        "#     description = \"\"\"Useful to search information from the latest 10-K form for a given stock.\n",
        "#                      The input to this tool should be a pipe (|) separated text of\n",
        "#                      length two, representing the stock ticker you are interested, what\n",
        "#                      question you have from it.\n",
        "#                      For example, `AAPL|what was last year's revenue`.\"\"\"\n",
        "\n",
        "#     args_schema: Type[BaseModel] = PropertiesSearch10k\n",
        "\n",
        "#     def _run(\n",
        "#         self, stock: str, ask: str\n",
        "#     ) -> dict:\n",
        "#             queryApi = QueryApi(api_key=\"befd094ddadf6a9e080bf194b6d9197e753ec1d4226fc8e595ed717b2f1bc3a5\")\n",
        "#             query = {\n",
        "#               \"query\": {\n",
        "#                 \"query_string\": {\n",
        "#                   \"query\": f\"ticker:{stock} AND formType:\\\"10-K\\\"\"\n",
        "#                 }\n",
        "#               },\n",
        "#               \"from\": \"0\",\n",
        "#               \"size\": \"1\",\n",
        "#               \"sort\": [{ \"filedAt\": { \"order\": \"desc\" }}]\n",
        "#             }\n",
        "\n",
        "#             fillings = queryApi.get_filings(query)['filings']\n",
        "#             if len(fillings) == 0:\n",
        "#               return \"Sorry, I couldn't find any filling for this stock, check if the ticker is correct.\"\n",
        "#             link = fillings[0]['linkToFilingDetails']\n",
        "#             answer = embedding_search(link, ask)\n",
        "#             return answer\n",
        "\n",
        "# Tenk = Search10k()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhFk82hXFm2b"
      },
      "source": [
        "## Openai utilites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "rivfZPicJUKb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "W16S_ST_JQA0"
      },
      "outputs": [],
      "source": [
        "api_type = \"azure\"\n",
        "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "api_version = '2023-10-01-preview'\n",
        "api_key = '80ddd1ad72504f2fa226755d49491a61'\n",
        "client = AzureOpenAI(\n",
        "    api_key= api_key,\n",
        "    api_version= api_version,\n",
        "    azure_endpoint= api_endpoint\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "JHliSi6UsYzU"
      },
      "outputs": [],
      "source": [
        "class ChatWithOpenai:\n",
        "  def __init__(self, system_message, model, temperature, max_tokens, client, default_user_messages=None):\n",
        "    self.system_message = system_message\n",
        "    self.model = model\n",
        "    self.temperature = temperature\n",
        "    self.max_tokens = max_tokens\n",
        "    self.client = client\n",
        "    self.messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    if default_user_messages:\n",
        "      for user_message in default_user_messages:\n",
        "        self.messages += [{\"role\": \"user\", \"content\": user_message}]\n",
        "\n",
        "  def chat(self, user_input):\n",
        "    # print(self.messages + user_input)\n",
        "    response = self.client.chat.completions.create(\n",
        "        model=self.model,\n",
        "        messages=self.messages + user_input,\n",
        "        temperature=self.temperature,\n",
        "        max_tokens=self.max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr_s_UHkFGCT"
      },
      "source": [
        "## Irrelevant handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "v5b3pyZJNYl3"
      },
      "outputs": [],
      "source": [
        "# message = \"'check the grammer for me?'\"\n",
        "# user_input = [{\"role\": \"user\", \"content\": message}]\n",
        "# handler_zero_openai.chat(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "T6nK6QWyOlx-"
      },
      "outputs": [],
      "source": [
        "# Handler.run(\"check the grammer for me?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "GvR7waNZrJSZ"
      },
      "outputs": [],
      "source": [
        "default_message = [\"Check the following text for greeting words and do as the system message said.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ry7DgJSZQT0g"
      },
      "outputs": [],
      "source": [
        "handler_zero_openai = ChatWithOpenai(system_message=\"You are an assistant. Your job is to check the user input Not answer it.\\\n",
        "If the user input contains greeting words like ‘hello’, ‘hi’, and so on, \\\n",
        "then you should remove these words. \\\n",
        "Note that the final response is either the input with the greeting word removed, \\\n",
        "or ‘None’ if the input consists only of a greeting word. \\\n",
        "if there is no greeting word in the input, the response is the last user input itself \\\n",
        "without any changes. \\\n",
        "No other responses are possible. \\\n",
        "Here are some examples and the valid responses: \\\n",
        "Example 1 (when there is no greeting word): \\\n",
        "{ input: ‘What is the weather?’ response: ‘What is the weather?’ } \\\n",
        "Example 2 (when there is a greeting word): \\\n",
        "{ input: ‘Hi can you speak French?’ response: ‘Can you speak French?’ } \\\n",
        "Example 3 (when there is just one or more greeting words): \\\n",
        "{ input: ‘Hello.’ response: ‘None’ } \\\n",
        "Note that you are not permitted to answer user requests directly. \\\n",
        "Only perform the tasks instructed by system messages.\",\n",
        "\n",
        "                                      default_user_messages=default_message,\n",
        "                                      model=\"gpt_35_16k\",\n",
        "                                      temperature=0.2,\n",
        "                                      max_tokens=100,\n",
        "                                      client=client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dx8bLNJsCY0U"
      },
      "outputs": [],
      "source": [
        "handler_one_openai = ChatWithOpenai(system_message=\"You are an assistant. Your job is to check the user input, not answer it. \\\n",
        "We are a system with the name 'Tensurf Brain' or 'Tensurf'. \\\n",
        "If the user needs any information about us or needs a tutorial for \\\n",
        "how our system is working, your job is to detect these scenarios and respond with 'True'. \\\n",
        "If the user asks about you, the answer is also 'True'. \\\n",
        "Also, when the user is confused and doesn't know how to start or what to do, \\\n",
        "the answer is also 'True'. \\\n",
        "For any other input that doesn't classify in the tutorial or information \\\n",
        "about 'Tensurf Brain' or 'Tensurf' you should return false. \\\n",
        "Note that you are not permitted to answer user requests directly. \\\n",
        "Only perform the tasks instructed by system messages.\",\n",
        "                                    model=\"gpt_35_16k\",\n",
        "                                    temperature=0.2,\n",
        "                                    max_tokens=100,\n",
        "                                    client=client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Deg_ndB8NhcO"
      },
      "outputs": [],
      "source": [
        "handler_two_openai = ChatWithOpenai(system_message=\"You are an assistant. Your job is to check the user input. \\\n",
        "If the user input does not contain any financial and \\\n",
        "trading topics or requests, then you should answer only\\\n",
        "with ‘True’. Otherwise, return ‘False’. \\\n",
        "Possible responses for you are 'True' or 'False'. \\\n",
        "For example, the correct response to the question \\\n",
        "'What is the trend?' is 'False'.\",\n",
        "                              model=\"gpt_35_16k\",\n",
        "                              temperature=0,\n",
        "                              max_tokens=100,\n",
        "                              client=client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "J8UHKYBEEfH5"
      },
      "outputs": [],
      "source": [
        "class HandleIrrelevantSchema(BaseModel):\n",
        "    massage: str = Field(..., description=\"The humanmassage\")\n",
        "\n",
        "\n",
        "class HandleIrrelevant(BaseTool):\n",
        "    name = \"HandleIrrelevant\"\n",
        "    description = \"\"\"This function checks if the message contains financial or trading subjects or not. \\\n",
        "The output of this function is either True or False and the possible output of this function are 'True' or 'False'.: \\\n",
        "True: when the message contains financial or trading subjects. \\\n",
        "False: when the message request is not in these fields.\"\"\"\n",
        "\n",
        "    args_schema: Type[BaseModel] = HandleIrrelevantSchema\n",
        "\n",
        "    def _run(\n",
        "        self, massage: str\n",
        "    ) -> dict:\n",
        "\n",
        "        user_input = [{\"role\": \"user\", \"content\": \"'\" + massage + \"'\"}]\n",
        "\n",
        "        modified_input = handler_zero_openai.chat(user_input)\n",
        "        # print(f\"inside handler func: {modified_input}\")\n",
        "        if modified_input == 'None':\n",
        "          return 'Greeting'\n",
        "\n",
        "        modified_user_input = [{\"role\": \"user\", \"content\": modified_input}]\n",
        "\n",
        "        if handler_one_openai.chat(modified_user_input) == 'True':\n",
        "          return \"Tutorial\"\n",
        "        # print(f\"in the handler: {modified_user_input}\")\n",
        "        else:\n",
        "          return handler_two_openai.chat(modified_user_input)\n",
        "\n",
        "        # chat_with_openai(user_input)\n",
        "        # return chat_with_openai(user_input)\n",
        "\n",
        "Handler = HandleIrrelevant()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ZzsXJuayUsk2"
      },
      "outputs": [],
      "source": [
        "# Handler.run(\"What is the trend?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "5NqR7iXE65aV"
      },
      "outputs": [],
      "source": [
        "# tools = [trend, SR, TP, Sl, Bias, databaseId, databaseRisk, databaseStyle, Handler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "AmVaq852XjDt"
      },
      "outputs": [],
      "source": [
        "tools = [Trend, SR, TP, SL, Bias, Handler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "mmuJdTx-LkO3"
      },
      "outputs": [],
      "source": [
        "tool_executor = ToolExecutor(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nDgbgr9HdZl"
      },
      "source": [
        "## Helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "j1mr9W5nxLW6"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, BaseMessage, ChatMessage, FunctionMessage, HumanMessage\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
        "from langchain_core.tools import tool\n",
        "from typing import Annotated, List, Sequence, Tuple, TypedDict, Union\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, BasePromptTemplate, MessagesPlaceholder\n",
        "import operator\n",
        "import functools\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "QDz0tK9PxPDJ"
      },
      "outputs": [],
      "source": [
        "def create_agent(llm, tools, system_message: str):\n",
        "  \"\"\"Create an agent.\"\"\"\n",
        "  functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "      [\n",
        "          (\n",
        "              \"system\",\n",
        "              \" You are a helpful AI assistant, collaborating with other assistants.\"\n",
        "              \" Use the provided tools to progress towards answering the question.\"\n",
        "              \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
        "              \" will help where you left off. Execute what you can to make progress.\"\n",
        "              \" If you or any of the other assistants have the final answer or deliverable,\"\n",
        "              \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
        "              f\" You have access to the following tools: {tool}.\\n{system_message}\",\n",
        "          ),\n",
        "          MessagesPlaceholder(variable_name=\"messages\"),\n",
        "      ]\n",
        "  )\n",
        "  prompt = prompt.partial(system_message=system_message)\n",
        "  prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
        "  return prompt | llm.bind_functions(functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "qmFMyzFvxkVl"
      },
      "outputs": [],
      "source": [
        "def agent_node(state, agent, name):\n",
        "  result = agent.invoke(state)\n",
        "\n",
        "  if isinstance(result, FunctionMessage):\n",
        "      pass\n",
        "\n",
        "  else:\n",
        "      result = HumanMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
        "\n",
        "  return {\n",
        "      \"messages\": [result],\n",
        "      \"sender\": name,\n",
        "      \"output_json\": state[\"output_json\"]\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG5-7xPrWAEO"
      },
      "source": [
        "## Agents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "I3GZHhQgWrtm"
      },
      "outputs": [],
      "source": [
        "from langchain_core.agents import AgentActionMessageLog\n",
        "from langchain_openai import AzureChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "LW8US-J3xzUH"
      },
      "outputs": [],
      "source": [
        "api_type = \"azure\"\n",
        "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
        "api_version = '2023-10-01-preview'\n",
        "api_key = '80ddd1ad72504f2fa226755d49491a61'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "P7L2tpF8xzUH"
      },
      "outputs": [],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "                  api_key=api_key,\n",
        "                  api_version=api_version,\n",
        "                  azure_endpoint=api_endpoint,\n",
        "                  deployment_name=\"gpt_35_16k\",\n",
        "                  temperature=0,\n",
        "                  streaming=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "k9XEZ_r8xscp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.3.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# Trend:At any situations, never return the number which is the output of the Trend function. Instead, use its correcsponding explanation which is in the Trend tool's description. Make sure to mention the start_datetime and end_datetime or the lookback parameter if the user have mentioned in their last message. If the user provide neither specified both start_datetime and end_datetime nor lookback parameters, politely tell them that they should and introduce these parameters to them so that they can use them. Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Now generate a proper response. \\\n",
        "trading_agent = create_agent(\n",
        "    llm,\n",
        "    [Trend, SR, TP, SL, Bias],\n",
        "    system_message=\"\"\"You are an assistant with the following capabilities given to you by your tools:\n",
        "SR: Calculate support and resistance levels. \\\n",
        "Trend: Calculate the trend of a specified financial instrument over a given time range and timeframe. \\\n",
        "TP: Calculate Take profit (TP), \\\n",
        "SL: Calculate Stoploss (SL), \\\n",
        "Bias: Detecting trading bias. \\\n",
        "Note the following rules for result of each tool: \\\n",
        "SR:Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Do not mention the name of the levels that the level is support or resistance. The final answer should also contain the following texts: These levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels. \\\n",
        "Trend:At any situations, never return the number which is the output of the Trend function. Instead, use its correcsponding explanation which is in the Trend tool's description. Make sure to mention the start_datetime and end_datetime or the lookback parameter. Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Now generate a proper response. \\\n",
        "TP: Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Now generate a proper response. \\\n",
        "SL: Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. The unit of every number in the answer should be mentioned. Now generate a proper response. \\\n",
        "Bias: Do not mention the name of the parameters of the functions directly in the final answer. Instead, briefly explain them and use other meaningfuly related synonyms. Now generate a proper response.\"\"\"\n",
        ")\n",
        "trading_node = functools.partial(agent_node, agent=trading_agent, name=\"Trading\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "DlECe-H-yZaV"
      },
      "outputs": [],
      "source": [
        "# onboarding_agent = create_agent(\n",
        "#     llm,\n",
        "#     [databaseId, databaseRisk, databaseStyle],\n",
        "#     \"\"\"You are an onboarding assistant who helps new users set and change some of the user fields in the database.\n",
        "#        Note that user requests in our systems must only pertain to financial and trading topics.\n",
        "#        If the user’s request is not related to these topics, this tool will handle it.\"\"\",\n",
        "# )\n",
        "# onboarding_node = functools.partial(agent_node, agent=onboarding_agent, name=\"Onboarding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjyNdJzWW4-C"
      },
      "source": [
        "## Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elx78emqXsiT"
      },
      "source": [
        "### adding sub graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Thp0qoYhCrDj"
      },
      "outputs": [],
      "source": [
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "5KxGO5t6CobZ"
      },
      "outputs": [],
      "source": [
        "def reduce_list(left: list | None, right: list | None) -> list:\n",
        "  \"\"\"Append the right-hand list, replacing any elements with the same id in the left-hand list.\"\"\"\n",
        "  if not left:\n",
        "      left = []\n",
        "  if not right:\n",
        "      right = []\n",
        "  left_, right_ = [], []\n",
        "  for orig, new in [(left, left_), (right, right_)]:\n",
        "      for val in orig:\n",
        "          if not isinstance(val, dict):\n",
        "              val = {\"val\": val}\n",
        "          if \"id\" not in val:\n",
        "              val[\"id\"] = str(uuid.uuid4())\n",
        "          new.append(val)\n",
        "  # Merge the two lists\n",
        "  left_idx_by_id = {val[\"id\"]: i for i, val in enumerate(left_)}\n",
        "  merged = left_.copy()\n",
        "  for val in right_:\n",
        "      if (existing_idx := left_idx_by_id.get(val[\"id\"])) is not None:\n",
        "          merged[existing_idx] = val\n",
        "      else:\n",
        "          merged.append(val)\n",
        "  return merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "MB1Z12UJxPLB"
      },
      "outputs": [],
      "source": [
        "# class AgentState(TypedDict):\n",
        "#   messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "#   path: Annotated[list[str], reduce_list]\n",
        "#   # sender: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "q9bdSVwA4iPg"
      },
      "outputs": [],
      "source": [
        "# subGraphOne = StateGraph(AgentState)\n",
        "# mainGraph = StateGraph(AgentState)\n",
        "\n",
        "# mainGraph.add_node(\"Handler\", run_Handler)\n",
        "\n",
        "# subGraphOne.add_node(\"Greeting\", run_greeting)\n",
        "# subGraphOne.add_node(\"Tutorial\", run_tutorial)\n",
        "\n",
        "# subGraphOne.add_edge(\"Greeting\", END)\n",
        "# subGraphOne.add_edge(\"Tutorial\", END)\n",
        "# subGraphOne.add_conditional_edges(\n",
        "#     \"Handler\",\n",
        "#     router,\n",
        "#     {\"Greeting\": \"Greeting\", \"Tutorial\": \"Tutorial\", \"end\": END},\n",
        "# )\n",
        "\n",
        "# subGraphOne.set_entry_point(\"Handler\")\n",
        "# # subGraphOne.set_finish_point(\"Trading\")\n",
        "\n",
        "# mainGraph.add_node(\"Trading\", trading_node)\n",
        "# mainGraph.add_node(\"Onboarding\", onboarding_node)\n",
        "# mainGraph.add_node(\"call_tool\", tool_node)\n",
        "# mainGraph.add_node(\"child\", subGraphOne.compile())\n",
        "\n",
        "# mainGraph.add_conditional_edges(\n",
        "#     \"Trading\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        "# )\n",
        "# mainGraph.add_conditional_edges(\n",
        "#     \"Onboarding\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        "# )\n",
        "\n",
        "\n",
        "# mainGraph.add_conditional_edges(\n",
        "#     \"call_tool\",\n",
        "#     lambda x: x[\"sender\"],\n",
        "#     {\n",
        "#         \"Trading\": \"Trading\",\n",
        "#         \"Onboarding\": \"Onboarding\",\n",
        "#     },\n",
        "# )\n",
        "# mainGraph.set_entry_point(\"Handler\")\n",
        "\n",
        "# graph = mainGraph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pXiBnGkX13I"
      },
      "source": [
        "### normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "tVkwTo3E48dI"
      },
      "outputs": [],
      "source": [
        "def run_Handler(state):\n",
        "  tool_name = \"HandleIrrelevant\"\n",
        "\n",
        "  messages = state[\"messages\"]\n",
        "  last_message = messages[-1]\n",
        "\n",
        "  # print(\"&\"*50)\n",
        "  # print(last_message.content)\n",
        "  # print(\"&\"*50)\n",
        "\n",
        "  action = ToolInvocation(\n",
        "      tool=tool_name,\n",
        "      tool_input=last_message.content,\n",
        "  )\n",
        "\n",
        "  response = tool_executor.invoke(action)\n",
        "  # print(response)\n",
        "  standard_response = \"\"\n",
        "  if response == 'True':\n",
        "    standard_response = \"I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\"\n",
        "\n",
        "  function_message = FunctionMessage(\n",
        "       content=standard_response, HandleIrrelevant_response=f\"{str(response)}\", name=action.tool\n",
        "  )\n",
        "\n",
        "  return {\"messages\": [function_message]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "JkjI0fgMbhT2"
      },
      "outputs": [],
      "source": [
        "def run_greeting(state):\n",
        "  # tool_name = \"HandleIrrelevant\"\n",
        "\n",
        "  # action = ToolInvocation(\n",
        "  #     tool=tool_name,\n",
        "  #     tool_input=\"Hi\",\n",
        "  # )\n",
        "\n",
        "  # response = tool_executor.invoke(action)\n",
        "\n",
        "  greeting = ChatWithOpenai(system_message=\"You are an financial and trading assistant.\",\n",
        "                            model=\"gpt_35_16k\",\n",
        "                            temperature=0.2,\n",
        "                            max_tokens=100,\n",
        "                            client=client)\n",
        "  input = [{\"role\": \"user\", \"content\": \"Hi\"}]\n",
        "  response = greeting.chat(input)\n",
        "\n",
        "  function_message = FunctionMessage(\n",
        "       content=response ,name='openai chat'\n",
        "  )\n",
        "\n",
        "  return {\"messages\": [function_message]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "wxNA-zRPTE42"
      },
      "outputs": [],
      "source": [
        "def run_tutorial(state):\n",
        "  response = \"\"\"I'm TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools:\n",
        "1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\"\n",
        "2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\"\n",
        "3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\"\n",
        "4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\"\n",
        "5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\"\n",
        "Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!\"\"\"\n",
        "\n",
        "  function_message = FunctionMessage(\n",
        "       content=response ,name='hardcoded string'\n",
        "  )\n",
        "\n",
        "  return {\"messages\": [function_message]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "BfUv6qxqbDDg"
      },
      "outputs": [],
      "source": [
        "def output_json_assigner(tool_name, response):\n",
        "  output_json = {}\n",
        "  if tool_name == \"calculate_sr\":\n",
        "    sr_value, sr_start_date, sr_detect_date, sr_end_date, sr_importance = response\n",
        "    output_json[\"levels_prices\"] = sr_value\n",
        "    output_json[\"levels_start_timestamps\"] = sr_start_date\n",
        "    output_json[\"levels_detect_timestamps\"] = sr_detect_date\n",
        "    output_json[\"levels_end_timestamps\"] = sr_end_date\n",
        "    output_json[\"levels_scores\"] = sr_importance\n",
        "  return output_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "nS7yahoQzOaI"
      },
      "outputs": [],
      "source": [
        "def tool_node(state):\n",
        "  \"\"\"This runs tools in the graph\n",
        "      It takes in an agent action\n",
        "      and calls that tool and\n",
        "      returns the result.\"\"\"\n",
        "  messages = state[\"messages\"]\n",
        "  last_message = messages[-1]\n",
        "  tool_input = json.loads(\n",
        "      last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
        "  )\n",
        "\n",
        "  if len(tool_input) == 1 and \"__arg1\" in tool_input:\n",
        "      tool_input = next(iter(tool_input.values()))\n",
        "  # tool_name = last_message.additional_kwargs[\"function_call\"][\"name\"]\n",
        "\n",
        "  tool_name = last_message.additional_kwargs[\"function_call\"][\"name\"].split(\".\")[-1]\n",
        "\n",
        "  action = ToolInvocation(\n",
        "      tool=tool_name,\n",
        "      tool_input=tool_input,\n",
        "  )\n",
        "\n",
        "  response = tool_executor.invoke(action)\n",
        "\n",
        "  out_json = output_json_assigner(tool_name, response)\n",
        "\n",
        "\n",
        "  function_message = FunctionMessage(\n",
        "      content=f\"{tool_name} response: {str(response)}\", name=action.tool\n",
        "  )\n",
        "\n",
        "  return {\"messages\": [function_message], \"output_json\":out_json}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "ZqafxFRLzXlm"
      },
      "outputs": [],
      "source": [
        "def router(state):\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    if last_message.name != 'HandleIrrelevant':\n",
        "      last_message = messages[-2]\n",
        "\n",
        "      if \"function_call\" in last_message.additional_kwargs:\n",
        "        return \"call_tool\"\n",
        "\n",
        "      if not \"function_call\" in last_message.additional_kwargs and last_message.type == \"function\":\n",
        "        return \"continue\"\n",
        "\n",
        "      if not last_message.additional_kwargs and last_message.type == \"human\":\n",
        "        return \"end\"\n",
        "\n",
        "    else:\n",
        "      if \"Greeting\" in last_message.HandleIrrelevant_response and last_message.name == 'HandleIrrelevant':\n",
        "        return \"Greeting\"\n",
        "\n",
        "      if \"Tutorial\" in last_message.HandleIrrelevant_response and last_message.name == 'HandleIrrelevant':\n",
        "        return \"Tutorial\"\n",
        "\n",
        "      if \"True\" in last_message.HandleIrrelevant_response and last_message.name == 'HandleIrrelevant':\n",
        "        return \"end\"\n",
        "\n",
        "      if \"False\" in last_message.HandleIrrelevant_response and last_message.name == 'HandleIrrelevant':\n",
        "        return \"continue\"\n",
        "\n",
        "      if \"False\" in last_message.content and last_message.name == \"HandleGreeting\":\n",
        "        return \"continue\"\n",
        "\n",
        "      if \"False\" not in last_message.content and last_message.name == \"HandleGreeting\":\n",
        "        return \"end\"\n",
        "\n",
        "\n",
        "    return \"continue\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "rQJEV9IJYO0r"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "  output_json: dict\n",
        "  input_json: dict\n",
        "  sender: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "HWKy0Tnuzr7P"
      },
      "outputs": [],
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"Trading\", trading_node)\n",
        "# workflow.add_node(\"Onboarding\", onboarding_node)\n",
        "workflow.add_node(\"call_tool\", tool_node)\n",
        "workflow.add_node(\"Handler\", run_Handler)\n",
        "workflow.add_node(\"Greeting\", run_greeting)\n",
        "workflow.add_node(\"Tutorial\", run_tutorial)\n",
        "\n",
        "# workflow.add_node(\"Inquiry\", inquiry_node)\n",
        "# workflow.add_node(\"Support\", support_node)\n",
        "# workflow.add_node(\"Inquiry\", inquiry_node)\n",
        "\n",
        "# workflow.add_edge(\"Inquiry\", \"call_tool\")\n",
        "\n",
        "# workflow.add_edge(\"Handler\", \"Trading\")\n",
        "\n",
        "workflow.add_edge(\"Greeting\", END)\n",
        "workflow.add_edge(\"Tutorial\", END)\n",
        "\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"Inquiry\",\n",
        "#     router,\n",
        "#     {\"call_tool\": \"call_tool\", \"continue\": \"Inquiry\"},\n",
        "# )\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"Support\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        "# )\n",
        "workflow.add_conditional_edges(\n",
        "    \"Handler\",\n",
        "    router,\n",
        "    {\"continue\": \"Trading\", \"Greeting\": \"Greeting\", \"Tutorial\": \"Tutorial\", \"end\": END},\n",
        ")\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"Greeting\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"end\": END},\n",
        "# )\n",
        "workflow.add_conditional_edges(\n",
        "    \"Trading\",\n",
        "    router,\n",
        "    {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        ")\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"Onboarding\",\n",
        "#     router,\n",
        "#     {\"continue\": \"Trading\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        "# )\n",
        "\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"call_tool\",\n",
        "    lambda x: x[\"sender\"],\n",
        "    {\n",
        "        \"Trading\": \"Trading\",\n",
        "        # \"Onboarding\": \"Onboarding\",\n",
        "        # \"Inquiry\": \"Inquiry\",\n",
        "        # \"Support\": END\n",
        "    },\n",
        ")\n",
        "workflow.set_entry_point(\"Handler\")\n",
        "\n",
        "graph = workflow.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8B2R2gjXU6A"
      },
      "source": [
        "## Graph visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "MogS2xefyYIf"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "import base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "-3izld86Xfj9"
      },
      "outputs": [],
      "source": [
        "def display_image(image_bytes: bytes, width=300):\n",
        "    decoded_img_bytes = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "    html = f'<img src=\"data:image/png;base64,{decoded_img_bytes}\" style=\"width: {width}px;\" />'\n",
        "    display(HTML(html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "OlsVc0H1xviv",
        "outputId": "a7442c6f-6d56-41c6-d15e-2a29d9c552ca"
      },
      "outputs": [],
      "source": [
        "# display_image(graph.get_graph().draw_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FWNCO4ZXlMp"
      },
      "source": [
        "## Test prompts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt:  \tCalculate Support and Resistance Levels based on YM by looking back up to past 5 days and timeframe of 10 minutes.\n",
            "{'Handler': {'messages': [FunctionMessage(content='', name='HandleIrrelevant', HandleIrrelevant_response='False')]}}\n",
            "{'Trading': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"symbol\": \"YM\",\\n  \"lookback_days\": \"5\",\\n  \"timeframe\": \"10min\"\\n}', 'name': 'calculate_sr'}}, response_metadata={'finish_reason': 'function_call'}, name='Trading', id='run-009e8632-f9c4-4fec-b0cf-d690cf3c35bb-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': None, 'sender': 'Trading'}}\n",
            "{'Trading': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"symbol\": \"YM\",\\n  \"lookback_days\": \"5\",\\n  \"timeframe\": \"10min\"\\n}', 'name': 'calculate_sr'}}, response_metadata={'finish_reason': 'function_call'}, name='Trading', id='run-ff1eab67-fd69-4c20-940e-1888def84e29-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': None, 'sender': 'Trading'}}\n",
            "{'call_tool': {'messages': [FunctionMessage(content=\"calculate_sr response: [[40033.0, 40017.0, 40009.0, 39979.0, 39690.0, 39715.0, 39774.0, 39882.0, 39451.0, 39546.0, 39315.0, 39105.0], [Timestamp('2024-05-21 19:00:00'), Timestamp('2024-05-21 22:50:00'), Timestamp('2024-05-22 07:30:00'), Timestamp('2024-05-22 10:10:00'), Timestamp('2024-05-22 12:50:00'), Timestamp('2024-05-22 18:00:00'), Timestamp('2024-05-23 02:00:00'), Timestamp('2024-05-23 05:10:00'), Timestamp('2024-05-23 08:20:00'), Timestamp('2024-05-23 08:50:00'), Timestamp('2024-05-24 08:10:00'), Timestamp('2024-05-24 12:00:00')], [Timestamp('2024-05-21 19:50:00'), Timestamp('2024-05-21 23:40:00'), Timestamp('2024-05-22 08:20:00'), Timestamp('2024-05-22 11:00:00'), Timestamp('2024-05-22 13:40:00'), Timestamp('2024-05-22 18:50:00'), Timestamp('2024-05-23 02:50:00'), Timestamp('2024-05-23 06:00:00'), Timestamp('2024-05-23 09:10:00'), Timestamp('2024-05-23 09:40:00'), Timestamp('2024-05-24 09:00:00'), Timestamp('2024-05-24 12:50:00')], [Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00')], [3.9, 7.8, 3.3, 7.0, 3.5, 5.8, 4.8, 2.9, 2.8, 3.6, 3.1, 3.3]]\", name='calculate_sr')], 'output_json': {'levels_prices': [40033.0, 40017.0, 40009.0, 39979.0, 39690.0, 39715.0, 39774.0, 39882.0, 39451.0, 39546.0, 39315.0, 39105.0], 'levels_start_timestamps': [Timestamp('2024-05-21 19:00:00'), Timestamp('2024-05-21 22:50:00'), Timestamp('2024-05-22 07:30:00'), Timestamp('2024-05-22 10:10:00'), Timestamp('2024-05-22 12:50:00'), Timestamp('2024-05-22 18:00:00'), Timestamp('2024-05-23 02:00:00'), Timestamp('2024-05-23 05:10:00'), Timestamp('2024-05-23 08:20:00'), Timestamp('2024-05-23 08:50:00'), Timestamp('2024-05-24 08:10:00'), Timestamp('2024-05-24 12:00:00')], 'levels_detect_timestamps': [Timestamp('2024-05-21 19:50:00'), Timestamp('2024-05-21 23:40:00'), Timestamp('2024-05-22 08:20:00'), Timestamp('2024-05-22 11:00:00'), Timestamp('2024-05-22 13:40:00'), Timestamp('2024-05-22 18:50:00'), Timestamp('2024-05-23 02:50:00'), Timestamp('2024-05-23 06:00:00'), Timestamp('2024-05-23 09:10:00'), Timestamp('2024-05-23 09:40:00'), Timestamp('2024-05-24 09:00:00'), Timestamp('2024-05-24 12:50:00')], 'levels_end_timestamps': [Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00')], 'levels_scores': [3.9, 7.8, 3.3, 7.0, 3.5, 5.8, 4.8, 2.9, 2.8, 3.6, 3.1, 3.3]}}}\n",
            "{'Trading': {'messages': [HumanMessage(content='Based on historical price data, the support and resistance levels for YM (E-mini Dow Jones Industrial Average) with a lookback period of 5 days and a timeframe of 10 minutes are as follows:\\n\\n- Support Levels: 40033.0, 40017.0, 40009.0, 39979.0, 39690.0, 39715.0, 39774.0, 39882.0, 39451.0, 39546.0, 39315.0, 39105.0\\n- Resistance Levels: 3.9, 7.8, 3.3, 7.0, 3.5, 5.8, 4.8, 2.9, 2.8, 3.6, 3.1, 3.3\\n\\nThese levels indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.', response_metadata={'finish_reason': 'stop'}, name='Trading', id='run-1a3583e3-0606-4a08-a773-0e7ead960225-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': {'levels_prices': [40033.0, 40017.0, 40009.0, 39979.0, 39690.0, 39715.0, 39774.0, 39882.0, 39451.0, 39546.0, 39315.0, 39105.0], 'levels_start_timestamps': [Timestamp('2024-05-21 19:00:00'), Timestamp('2024-05-21 22:50:00'), Timestamp('2024-05-22 07:30:00'), Timestamp('2024-05-22 10:10:00'), Timestamp('2024-05-22 12:50:00'), Timestamp('2024-05-22 18:00:00'), Timestamp('2024-05-23 02:00:00'), Timestamp('2024-05-23 05:10:00'), Timestamp('2024-05-23 08:20:00'), Timestamp('2024-05-23 08:50:00'), Timestamp('2024-05-24 08:10:00'), Timestamp('2024-05-24 12:00:00')], 'levels_detect_timestamps': [Timestamp('2024-05-21 19:50:00'), Timestamp('2024-05-21 23:40:00'), Timestamp('2024-05-22 08:20:00'), Timestamp('2024-05-22 11:00:00'), Timestamp('2024-05-22 13:40:00'), Timestamp('2024-05-22 18:50:00'), Timestamp('2024-05-23 02:50:00'), Timestamp('2024-05-23 06:00:00'), Timestamp('2024-05-23 09:10:00'), Timestamp('2024-05-23 09:40:00'), Timestamp('2024-05-24 09:00:00'), Timestamp('2024-05-24 12:50:00')], 'levels_end_timestamps': [Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00')], 'levels_scores': [3.9, 7.8, 3.3, 7.0, 3.5, 5.8, 4.8, 2.9, 2.8, 3.6, 3.1, 3.3]}, 'sender': 'Trading'}}\n",
            "{'Trading': {'messages': [HumanMessage(content='These levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.', response_metadata={'finish_reason': 'stop'}, name='Trading', id='run-ffc8a0fc-29ef-4f5b-a6d2-d54211923ff8-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': {'levels_prices': [40033.0, 40017.0, 40009.0, 39979.0, 39690.0, 39715.0, 39774.0, 39882.0, 39451.0, 39546.0, 39315.0, 39105.0], 'levels_start_timestamps': [Timestamp('2024-05-21 19:00:00'), Timestamp('2024-05-21 22:50:00'), Timestamp('2024-05-22 07:30:00'), Timestamp('2024-05-22 10:10:00'), Timestamp('2024-05-22 12:50:00'), Timestamp('2024-05-22 18:00:00'), Timestamp('2024-05-23 02:00:00'), Timestamp('2024-05-23 05:10:00'), Timestamp('2024-05-23 08:20:00'), Timestamp('2024-05-23 08:50:00'), Timestamp('2024-05-24 08:10:00'), Timestamp('2024-05-24 12:00:00')], 'levels_detect_timestamps': [Timestamp('2024-05-21 19:50:00'), Timestamp('2024-05-21 23:40:00'), Timestamp('2024-05-22 08:20:00'), Timestamp('2024-05-22 11:00:00'), Timestamp('2024-05-22 13:40:00'), Timestamp('2024-05-22 18:50:00'), Timestamp('2024-05-23 02:50:00'), Timestamp('2024-05-23 06:00:00'), Timestamp('2024-05-23 09:10:00'), Timestamp('2024-05-23 09:40:00'), Timestamp('2024-05-24 09:00:00'), Timestamp('2024-05-24 12:50:00')], 'levels_end_timestamps': [Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00'), Timestamp('2024-05-24 13:58:00')], 'levels_scores': [3.9, 7.8, 3.3, 7.0, 3.5, 5.8, 4.8, 2.9, 2.8, 3.6, 3.1, 3.3]}, 'sender': 'Trading'}}\n",
            "Prompt:  \tWhat would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?\n",
            "{'Handler': {'messages': [FunctionMessage(content='', name='HandleIrrelevant', HandleIrrelevant_response='False')]}}\n",
            "{'Trading': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"symbol\": \"NQ\",\\n  \"method\": \"minmax\",\\n  \"direction\": -1,\\n  \"lookback\": 30\\n}', 'name': 'calculate_sl'}}, response_metadata={'finish_reason': 'function_call'}, name='Trading', id='run-efab671d-d2d8-4ddc-8342-a23c378a5f29-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': None, 'sender': 'Trading'}}\n",
            "{'Trading': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"symbol\": \"NQ\",\\n  \"method\": \"minmax\",\\n  \"direction\": -1,\\n  \"lookback\": 30\\n}', 'name': 'calculate_sl'}}, response_metadata={'finish_reason': 'function_call'}, name='Trading', id='run-faf4b427-4f89-46a5-b2ee-7a23c25996c0-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': None, 'sender': 'Trading'}}\n",
            "{'call_tool': {'messages': [FunctionMessage(content=\"calculate_sl response: {'sl': [18868.0], 'risk': [3.75], 'info': ['calculated based on maximum high price of previous 30 candles']}\", name='calculate_sl')], 'output_json': {}}}\n",
            "{'Trading': {'messages': [HumanMessage(content='Based on the NQ symbol and using the minmax method with a lookback of 30 candles, the stop loss for short positions would be at 18868.0. This is calculated based on the maximum high price of the previous 30 candles, with a risk of 3.75.', response_metadata={'finish_reason': 'stop'}, name='Trading', id='run-83764cb0-749c-41b4-81b2-ff64884304a0-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': {}, 'sender': 'Trading'}}\n",
            "{'Trading': {'messages': [HumanMessage(content='Based on the NQ symbol and using the minmax method with a lookback of 30 candles, the stop loss for short positions would be at 18868.0. This is calculated based on the maximum high price of the previous 30 candles, with a risk of 3.75.', response_metadata={'finish_reason': 'stop'}, name='Trading', id='run-a58df2de-631d-49a0-a321-84d60f716903-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': {}, 'sender': 'Trading'}}\n",
            "Prompt:  \tHow much would be the take-profit of the NQ with the stop loss of 10 and direction of 1?\n",
            "{'Handler': {'messages': [FunctionMessage(content='', name='HandleIrrelevant', HandleIrrelevant_response='False')]}}\n",
            "{'Trading': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"symbol\": \"NQ\",\\n  \"direction\": 1,\\n  \"stoploss\": 10\\n}', 'name': 'calculate_tp'}}, response_metadata={'finish_reason': 'function_call'}, name='Trading', id='run-5357ef5b-2903-4498-bd3a-df49687ac725-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': None, 'sender': 'Trading'}}\n",
            "{'Trading': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"symbol\": \"NQ\",\\n  \"direction\": 1,\\n  \"stoploss\": 10\\n}', 'name': 'calculate_tp'}}, response_metadata={'finish_reason': 'function_call'}, name='Trading', id='run-08a7a0de-39f7-4277-b99f-2468d18b920b-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': None, 'sender': 'Trading'}}\n",
            "{'call_tool': {'messages': [FunctionMessage(content=\"calculate_tp response: {'tp': [], 'info': []}\", name='calculate_tp')], 'output_json': {}}}\n",
            "{'Trading': {'messages': [HumanMessage(content='Based on the provided information, the take-profit (TP) for the NQ with a stop loss of 10 and a direction of 1 cannot be determined. The calculate_tp function did not return any values for the TP.', response_metadata={'finish_reason': 'stop'}, name='Trading', id='run-22063350-b0f2-4476-acba-f585b94cb463-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': {}, 'sender': 'Trading'}}\n",
            "{'Trading': {'messages': [HumanMessage(content='I apologize, but it seems that I am unable to calculate the take-profit (TP) for the NQ with the given parameters. The calculate_tp function did not provide any results for the TP. Is there anything else I can assist you with?', response_metadata={'finish_reason': 'stop'}, name='Trading', id='run-1d9a1775-ca52-423b-aa8b-e7679482615a-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': {}, 'sender': 'Trading'}}\n",
            "Prompt:  \tTell me about the bias of ES on the market.\n",
            "{'Handler': {'messages': [FunctionMessage(content='', name='HandleIrrelevant', HandleIrrelevant_response='False')]}}\n",
            "{'Trading': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"symbol\": \"ES\"\\n}', 'name': 'bias_detection'}}, response_metadata={'finish_reason': 'function_call'}, name='Trading', id='run-08cb11f5-1626-45a6-891e-e621f1d305c0-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': None, 'sender': 'Trading'}}\n",
            "{'Trading': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"symbol\": \"ES\"\\n}', 'name': 'bias_detection'}}, response_metadata={'finish_reason': 'function_call'}, name='Trading', id='run-fa6f58ae-1499-4840-8be8-315a63c0da63-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': None, 'sender': 'Trading'}}\n",
            "{'call_tool': {'messages': [FunctionMessage(content=\"bias_detection response: {'bias': [], 'info': [], 'combined_bias': 0}\", name='bias_detection')], 'output_json': {}}}\n",
            "{'Trading': {'messages': [HumanMessage(content='Based on the available data, there is no specific bias detected for ES (E-mini S&P 500) in the market. The combined bias value is 0, indicating a neutral or no significant trend.', response_metadata={'finish_reason': 'stop'}, name='Trading', id='run-f151a475-225a-42e2-8944-0a7113d1843c-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': {}, 'sender': 'Trading'}}\n",
            "{'Trading': {'messages': [HumanMessage(content='Based on the available data, there is no specific bias detected for ES (E-mini S&P 500) in the market. The combined bias value is 0, indicating a neutral or no significant trend.', response_metadata={'finish_reason': 'stop'}, name='Trading', id='run-b7881a39-efc0-4df1-9e8d-cc8909e7ef5e-0', tool_calls=[], invalid_tool_calls=[])], 'output_json': {}, 'sender': 'Trading'}}\n",
            "Prompt:  \tWhat are the rules of basketball?\n",
            "{'Handler': {'messages': [FunctionMessage(content=\"I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\", name='HandleIrrelevant', HandleIrrelevant_response='True')]}}\n"
          ]
        }
      ],
      "source": [
        "# sample prompt for each function \n",
        "prompts = [ \n",
        "    # # detect_trend \n",
        "    # \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\", \n",
        "    # calculate_sr \n",
        "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 5 days and timeframe of 10 minutes.\", \n",
        "    # calculate_sl \n",
        "    \"What would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?\", \n",
        "    # calculate_tp \n",
        "    \"How much would be the take-profit of the NQ with the stop loss of 10 and direction of 1?\", \n",
        "    # bias_detection \n",
        "    \"Tell me about the bias of ES on the market.\",\n",
        "\t# irrelevant\n",
        "\t\"What are the rules of basketball?\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "\tprint(f\"Prompt:  \t{prompt}\") \n",
        "\tfor s in graph.stream( \n",
        "\t\t\t{ \n",
        "\t\t\t\t\"messages\": [ \n",
        "\t\t\t\t\tHumanMessage( \n",
        "\t\t\t\t\tcontent=prompt \n",
        "\t\t\t\t\t) \n",
        "\t\t\t\t], \n",
        "\t\t\t\t\"input_json\": input_filter.front_end_json_sample \n",
        "\t\t\t}, \n",
        "\t\t\t# Maximum number of steps to take in the graph \n",
        "\t\t\t{\"recursion_limit\": 150}, \n",
        "\t\t): \n",
        "\t\tprint(s)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nlPLaNe4GjgH",
        "behgQf7V1wNk",
        "EciRRD4YELCo",
        "lt4sSmAQH1Ph",
        "AahZLwrkH-G-",
        "ALEtGCoWoI_2",
        "LwjkTlbXlsgC",
        "elx78emqXsiT",
        "1FWNCO4ZXlMp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
