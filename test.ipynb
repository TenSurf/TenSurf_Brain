{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mf:\\TensurfTasks\\main\\TenSurf_Brain\\test.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/TensurfTasks/main/TenSurf_Brain/test.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/TensurfTasks/main/TenSurf_Brain/test.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmain\u001b[39;00m \u001b[39mimport\u001b[39;00m llm_surf\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/TensurfTasks/main/TenSurf_Brain/test.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minput_filter\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/TensurfTasks/main/TenSurf_Brain/test.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtime\u001b[39;00m \u001b[39mimport\u001b[39;00m time\n",
      "File \u001b[1;32mf:\\TensurfTasks\\main\\TenSurf_Brain\\main.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfile_processor\u001b[39;00m \u001b[39mimport\u001b[39;00m FileProcessor\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msingle_agent\u001b[39;00m \u001b[39mimport\u001b[39;00m Single_Agent\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmulti_agent\u001b[39;00m \u001b[39mimport\u001b[39;00m Multi_Agent\n\u001b[0;32m     11\u001b[0m load_dotenv()\n\u001b[0;32m     12\u001b[0m DEBUG \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mDEBUG\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mf:\\TensurfTasks\\main\\TenSurf_Brain\\multi_agent\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmulti_agent\u001b[39;00m \u001b[39mimport\u001b[39;00m Multi_Agent\n\u001b[0;32m      3\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mMulti_Agent\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mf:\\TensurfTasks\\main\\TenSurf_Brain\\multi_agent\\multi_agent.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlanggraph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph\u001b[39;00m \u001b[39mimport\u001b[39;00m END, StateGraph\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmessages\u001b[39;00m \u001b[39mimport\u001b[39;00m HumanMessage\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmulti_agent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m Utils, AgentState\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmulti_agent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctions_agents\u001b[39;00m \u001b[39mimport\u001b[39;00m create_agent_tools\n\u001b[0;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMulti_Agent\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\TensurfTasks\\main\\TenSurf_Brain\\multi_agent\\utils.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_openai\u001b[39;00m \u001b[39mimport\u001b[39;00m AzureChatOpenAI\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlanggraph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprebuilt\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtool_executor\u001b[39;00m \u001b[39mimport\u001b[39;00m ToolInvocation\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmulti_agent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctions_agents\u001b[39;00m \u001b[39mimport\u001b[39;00m create_agent_tools\n\u001b[0;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minput_filter\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mUtils\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\TensurfTasks\\main\\TenSurf_Brain\\multi_agent\\functions_agents.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime, timedelta\n\u001b[1;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myfinance\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39myf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minput_filter\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m########## Yahoo finance agent #########\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from main import llm_surf\n",
    "import input_filter\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing each function individualy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "detect_trend_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the trend of NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00?\",\n",
    "    \"What is the trend of NQ stock for the past week?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"What is the trend?\",\n",
    "    # \"Show me the trend of ES from May-1-2024 12:00:00 to May-5-2024 12:00:00.\",\n",
    "    # \"Trend of GC, May-1-2024 12:00:00 to May-5-2024 12:00:00\",\n",
    "    # \"Trend of GC, past 2 hours\",\n",
    "    # \"What is the trend of NQ from May-1-2024 12:00:00 until now?\",\n",
    "    # # Challenging Prompts\n",
    "    # \"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\",\n",
    "    \"What is the trend of NQ stock from May-20-2024 15:45:30 until Apr-24-2024 15:45:30?\",\n",
    "    # \"What is the trend of NQ stock from 20/4/2024 15:45:30 until 24/3/2024 15:45:30?\",\n",
    "    # \"What is the trend of NQ stock from 4/20/2024 15:45:30 until 4/24/2024 15:45:30?\",\n",
    "    \"Trend of Gold in the last month?\",\n",
    "    # \"Trend in the last month\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the trend of NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00?    =>    {'response': 'The trend of the NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00 is without a significant trend.', 'chart_info': {}}\n",
      "Inference Time: 32.82179307937622 seconds\n",
      "What is the trend of NQ stock for the past week?    =>    {'response': 'Based on the analysis of the NQ stock for the past week, there is no significant trend detected.', 'chart_info': {}}\n",
      "Inference Time: 22.480265140533447 seconds\n",
      "What is the trend of NQ?    =>    {'response': 'Based on the analysis, the current trend of NQ is without a significant trend or neutral.', 'chart_info': {}}\n",
      "Inference Time: 23.84973168373108 seconds\n",
      "What is the trend?    =>    {'response': 'Sure, I can help you with that. Please provide me with the symbol of the financial instrument and the time range or lookback period you would like to analyze.', 'chart_info': None}\n",
      "Inference Time: 5.66260290145874 seconds\n",
      "What is the trend of NQ stock from May-20-2024 15:45:30 until Apr-24-2024 15:45:30?    =>    {'response': 'No problem! If you provide me with a valid time range, I can help you determine the trend of the NQ stock.', 'chart_info': {}}\n",
      "Inference Time: 15.270185232162476 seconds\n",
      "Trend of Gold in the last month?    =>    {'response': 'Based on the trend analysis, the trend of Gold in the last month is without a significant trend or neutral.', 'chart_info': {}}\n",
      "Inference Time: 8.655912399291992 seconds\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "detect_trend_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in detect_trend_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    detect_trend_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/detect_trend_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(detect_trend_results, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate Support and Resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sr_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 10 minutes.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM with the timeframe of 1 hour.\",\n",
    "    \"How much is the sr of CL for the past week?\",\n",
    "    # Challenging prompts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 10 minutes.    =>    {'response': 'These support and resistance levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.', 'chart_info': {'levels_prices': [38333.0, 38425.0, 38488.0, 38564.0, 38628.0, 38716.0, 39174.0, 39080.0, 39011.0, 38837.0], 'levels_start_timestamps': [Timestamp('2024-06-03 10:10:00'), Timestamp('2024-06-04 03:00:00'), Timestamp('2024-06-04 06:30:00'), Timestamp('2024-06-04 09:00:00'), Timestamp('2024-06-05 07:10:00'), Timestamp('2024-06-07 05:40:00'), Timestamp('2024-06-07 07:40:00'), Timestamp('2024-06-07 10:20:00'), Timestamp('2024-06-07 12:00:00'), Timestamp('2024-06-07 13:00:00')], 'levels_detect_timestamps': [Timestamp('2024-06-03 11:00:00'), Timestamp('2024-06-04 03:50:00'), Timestamp('2024-06-04 07:20:00'), Timestamp('2024-06-04 09:50:00'), Timestamp('2024-06-05 08:00:00'), Timestamp('2024-06-07 06:30:00'), Timestamp('2024-06-07 08:30:00'), Timestamp('2024-06-07 11:10:00'), Timestamp('2024-06-07 12:50:00'), Timestamp('2024-06-07 13:50:00')], 'levels_end_timestamps': [Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00'), Timestamp('2024-06-07 13:58:00')], 'levels_scores': [4.7, 3.0, 5.9, 3.4, 4.1, 4.5, 3.8, 5.2, 4.3, 2.2], 'function_name': 'calculate_sr', 'symbol': 'YM', 'timeframe': '10min'}}\n",
      "Inference Time: 29.487149000167847 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m input_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_message\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m prompt\n\u001b[1;32m     10\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 11\u001b[0m output_json \u001b[38;5;241m=\u001b[39m \u001b[43mllm_surf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m    =>    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Work/TenSurf/TenSurf_Brain/main.py:166\u001b[0m, in \u001b[0;36mllm_surf\u001b[0;34m(llm_input)\u001b[0m\n\u001b[1;32m    162\u001b[0m     MA \u001b[38;5;241m=\u001b[39m Multi_Agent(\n\u001b[1;32m    163\u001b[0m         ChatWithOpenai\u001b[38;5;241m=\u001b[39mChatWithOpenai, client\u001b[38;5;241m=\u001b[39mazure_connector_surf\u001b[38;5;241m.\u001b[39mclient\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     graph \u001b[38;5;241m=\u001b[39m MA\u001b[38;5;241m.\u001b[39minitialize_graph()\n\u001b[0;32m--> 166\u001b[0m     llm_output \u001b[38;5;241m=\u001b[39m \u001b[43mMA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_multi_agent_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# running in single-agent mode\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODE\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Work/TenSurf/TenSurf_Brain/multi_agent/multi_agent.py:86\u001b[0m, in \u001b[0;36mMulti_Agent.generate_multi_agent_answer\u001b[0;34m(self, input_json, graph)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_multi_agent_answer\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_json, graph):\n\u001b[1;32m     73\u001b[0m     generated_messages \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m     74\u001b[0m         {\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m150\u001b[39m},\n\u001b[1;32m     84\u001b[0m     )\n\u001b[0;32m---> 86\u001b[0m     generated_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerated_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(generated_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generated_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][k]:\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/site-packages/langgraph/pregel/__init__.py:929\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    923\u001b[0m end_time \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    927\u001b[0m )\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m futures:\n\u001b[0;32m--> 929\u001b[0m     done, inflight \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_COMPLETED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m done:\n\u001b[1;32m    937\u001b[0m         task \u001b[38;5;241m=\u001b[39m futures\u001b[38;5;241m.\u001b[39mpop(fut)\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/concurrent/futures/_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    305\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_sr_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_sr_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    calculate_sr_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_sr_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_sr_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Stop Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sl_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?\",\n",
    "    \"What would be the stop loss of trading long positinos based on ES and swing method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and atr method and attribute coefficient of 1.3?\",\n",
    "    \"What would be the stop loss of trading long positinos based on YM and level method?\",\n",
    "    \"What would be the stop loss of trading long positinos based on NQ and DVWAP_band method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and WVWAP_band method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on GC and zigzag method?\",\n",
    "    \"What would be the stop loss of trading long positinos based on ES?\",\n",
    "    # Challenging prompts\n",
    "    \"How much would be the stop loss for trading?\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?    =>    {'response': 'FINAL ANSWER\\n\\nThe stop loss for trading short positions based on NQ using the minmax method and looking back up to 30 candles would be at 19018.5. The risk on this trade is 11.25 points. This stop loss is calculated based on the maximum high price of the previous 30 candles.', 'chart_info': {}}\n",
      "Inference Time: 26.93732476234436 seconds\n",
      "What would be the stop loss of trading long positinos based on ES and swing method?    =>    {'response': 'The stop loss for trading long positions based on ES using the swing method is determined to be at the following levels: 5351.25, 5341.0, and 5329.0. The associated risks for these trades are 2.25, 12.5, and 24.5 points, respectively. These stop loss levels were calculated based on low swings with a neighborhood parameter of 20 candles.', 'chart_info': {}}\n",
      "Inference Time: 26.80545997619629 seconds\n",
      "What would be the stop loss of trading short positinos based on NQ and atr method and attribute coefficient of 1.3?    =>    {'response': 'The stop loss for trading short positions based on the NQ and ATR method with an attribute coefficient of 1.3 is 19045.25. The risk on the trade is 15.5 points. This calculation is based on the ATR (Average True Range) with a length of 14, multiplied by the coefficient of 1.3.', 'chart_info': {}}\n",
      "Inference Time: 21.1414577960968 seconds\n",
      "What would be the stop loss of trading long positinos based on YM and level method?    =>    {'response': 'These stop loss levels are determined based on historical price data and indicate the price levels at which a trader should consider exiting a long position to limit potential losses. The associated risk values indicate the potential loss if the price moves against the trade. It is important to note that these levels are calculated based on different levels such as VWAP_Bottom_Band, prev_session_min, hourly SR levels, WVWAP, initial_balance_low, and 5min SR levels.', 'chart_info': {}}\n",
      "Inference Time: 46.951791524887085 seconds\n",
      "What would be the stop loss of trading long positinos based on NQ and DVWAP_band method?    =>    {'response': 'The stop loss for trading long positions on NQ based on the DVWAP_band method would be set at 18994.25. This stop loss is calculated based on the VWAP_Bottom_Band_3 as the bottom of the VWAP zone -3, with the current price being inside the VWAP zone -2. The risk on this trade is 35.5 points.', 'chart_info': {}}\n",
      "Inference Time: 19.487579822540283 seconds\n",
      "What would be the stop loss of trading short positinos based on NQ and WVWAP_band method?    =>    {'response': 'The stop loss for trading short positions on NQ based on the WVWAP_band method would be at 19165.5. The risk on this trade is 135.75 points. This stop loss is calculated based on WVWAP_Top_Band_3 as the ceiling of the WVWAP zone 3, with the current price being inside the WVWAP zone 2.', 'chart_info': {}}\n",
      "Inference Time: 178.77534079551697 seconds\n",
      "What would be the stop loss of trading short positinos based on GC and zigzag method?    =>    {'response': 'Based on the GC symbol and the zigzag method, the stop loss for short positions would be at 2315.86 and 2316.9. The risk associated with these stop loss levels is 4.66 and 5.7, respectively. These stop loss levels were calculated based on the last 5 zigzag legs of the same day of the week and the last session zigzag.', 'chart_info': {}}\n",
      "Inference Time: 117.76244521141052 seconds\n",
      "What would be the stop loss of trading long positinos based on ES?    =>    {'response': 'The stop loss for trading long positions based on ES would be 5347.5 and 5346.25. The risk on each trade would be 6.0 and 7.25 respectively. These values are calculated based on the last 5 zigzag legs of the same day of the week and the last session zigzag.', 'chart_info': {}}\n",
      "Inference Time: 36.70917105674744 seconds\n",
      "How much would be the stop loss for trading?    =>    {'response': 'Sure, I can help you calculate the stop loss for trading. Please provide me with the ticker symbol of the financial instrument you want to trade.', 'chart_info': None}\n",
      "Inference Time: 6.681099891662598 seconds\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_sl_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_sl_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    calculate_sl_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_sl_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_sl_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Take-Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_tp_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"How much would be the take-profit of trading based on NQ, long positions and stop loss of 100?\",\n",
    "    \"How much would be the take-profit of trading based on NQ and stop loss of 100?\",\n",
    "    \"How much would be the take-profit of trading based on NQ and long positions?\",\n",
    "    \"How much would be the take-profit of trading based on long positions and stop loss of 100?\",\n",
    "    \"How much would be the take-profit?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much would be the take-profit of trading based on NQ, long positions and stop loss of 100?    =>    {'response': 'I apologize, but it seems that there are no specific take-profit levels available for trading based on NQ, long positions, and a stop loss of 100. The calculation did not provide any results.', 'chart_info': {}}\n",
      "Inference Time: 35.621543407440186 seconds\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_tp_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_tp_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    calculate_tp_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_tp_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_tp_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "get_bias_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Tell me about the bias of ES on the market.\",\n",
    "    \"What is the current trading bias for ES?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about the bias of ES on the market.    =>    {'response': 'Based on the analysis of different methods, the bias of ES on the market is determined to be bullish. This conclusion is supported by multiple indicators, including the weekly VWAP, VAL/VAH of volume profile, short-term trend, mid-term trend, long-term trend, trend of the last hour, and counter ratio and power ratio. The combined bias is also bullish.', 'chart_info': {}}\n",
      "What is the current trading bias for ES?    =>    {'response': 'The current trading bias for ES is bullish. This is determined based on various methods including weekly VWAP, VAL/VAH of volume profile, short term trend, mid term trend, long term trend, trend of last hour, and counter ratio and power ratio. The combined bias is also bullish.', 'chart_info': {}}\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "get_bias_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in get_bias_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    get_bias_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/get_bias_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(get_bias_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "introduction_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Who are you?\",\n",
    "    \"What are you?\",\n",
    "    \"What can you do for me?\",\n",
    "    \"What are your functionalities?\",\n",
    "    \"How can you help me?\",\n",
    "    # Challenging prompts\n",
    "    \"Hi!\",\n",
    "    \"Good Morning!\",\n",
    "    \"What's up!?\",\n",
    "    \"How can I start?\",\n",
    "    \"Please help me!\",\n",
    "    \"What is TenSurf?\",\n",
    "    \"How could you help me?\",\n",
    "    # \"What about market today?\",\n",
    "    \"Could you guide me on how to use tensurf?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who are you?    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 2.6272988319396973 seconds\n",
      "What are you?    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 2.7197213172912598 seconds\n",
      "What can you do for me?    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 2.640967845916748 seconds\n",
      "What are your functionalities?    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 2.7283854484558105 seconds\n",
      "How can you help me?    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 2.658203125 seconds\n",
      "Hi!    =>    {'response': \"I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\"}\n",
      "Inference Time: 4.338561058044434 seconds\n",
      "Good Morning!    =>    {'response': \"I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\"}\n",
      "Inference Time: 3.7022972106933594 seconds\n",
      "What's up!?    =>    {'response': \"I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\"}\n",
      "Inference Time: 3.483160972595215 seconds\n",
      "How can I start?    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 2.641833543777466 seconds\n",
      "Please help me!    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 2.374638080596924 seconds\n",
      "What is TenSurf?    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 3.4386284351348877 seconds\n",
      "How could you help me?    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 2.378180503845215 seconds\n",
      "Could you guide me on how to use tensurf?    =>    {'response': 'I\\'m TenSurf Brain, your AI trading assistant within TenSurf Hub platform, designed to enhance your trading experience with advanced analytical and data-driven tools: 1. Trend Detection: I can analyze and report the trend of financial instruments over your specified period. For example, ask me, \"What is the trend of NQ stock from May-1-2024 12:00:00 until May-5-2024 12:00:00?\" 2. Support and Resistance Levels: I identify and score key price levels that may influence market behavior based on historical data. Try, \"Calculate Support and Resistance Levels based on YM by looking back up to the past 10 days and a timeframe of 1 hour.\" 3. Stop Loss Calculation: I determine optimal stop loss points to help you manage risk effectively. Query me like, \"How much would be the optimal stop loss for a short trade on NQ?\" 4. Take Profit Calculation: I calculate the ideal exit points for securing profits before a potential trend reversal. For example, \"How much would be the take-profit of a short position on Dow Jones with the stop loss of 10 points?\" 5. Trading Bias Identification: I analyze market conditions to detect the best trading biases and directions, whether for long or short positions. Ask me, \"What is the current trading bias for ES?\" Each tool is tailored to help you make smarter, faster, and more informed trading decisions. Enjoy!'}\n",
      "Inference Time: 2.3286209106445312 seconds\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "introduction_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in introduction_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    introduction_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/introduction_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(introduction_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yahoo finance agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "#prompts to test historicalprice tool\n",
    "yfinance_prompts = [\n",
    "    \"What is the price of apple from 2024-05-01 to 2024-05-15 with hourly timeframe?\",\n",
    "    \"What is the price of apple from 2024-05-11 to 2024-05-12?\",\n",
    "    \"What is the price of apple from 2024-05-10 to 2024-05-11?\",\n",
    "    \"What is the price of apple from 2024-05-10 to 2024-05-15?\",\n",
    "\n",
    "    \"What is the last price of Smartsheet Inc?\",\n",
    "    \"What is the last price of NVIDIA Corporation?\",\n",
    "    \"What is the last price of GameStop Corp?\",\n",
    "    \"What is the last price of apple?\",\n",
    "    \"What is the last price of microsoft?\",\n",
    "\n",
    "    \"What is the current price of AAPL?\",\n",
    "    \"What is the last price of AAPL?\",\n",
    "    \"What is the latest price of AAPL?\",\n",
    "    \n",
    "    \"What is the historical price of AAPL?\",\n",
    "    \"What is the current price of AAPL?\",\n",
    "    \"What is the historical price of AAPL at 2024-05-11 on daily timeframe?\",\n",
    "    \"What is the historical price of AAPL at 2024-05-08 on daily timeframe?\",\n",
    "    \"What is the historical price of AAPL at 2023-01-16 on daily timeframe?\",\n",
    "    \"What is the historical price of ABEV3.SA at 2023-01-16 on daily timeframe?\",\n",
    "    \"What is the historical price of AAPL from 2023-06-02 to 2023-11-02 for timeframe equal to 1mo?\",\n",
    "    \"What were the historical prices of AAPL from January 1, 2024, to December 31, 2024 on monthly timeframe?\",\n",
    "    \"Retrieve the historical prices for BTC-USD between January 1, 2024, and April 31, 2024.\",\n",
    "    \"Can you get the historical prices for the EURUSD=x forex pair for the past month ago on daily timeframe?\",\n",
    "    \"Can you get the historical prices for the EURUSD=x forex pair for two past month ago on daily timeframe?\",\n",
    "    \"Can you get the historical prices for the EURUSD=x forex pair from one month ago on daily timeframe?\",\n",
    "    \"Can you get the historical prices for the EURUSD=x forex pair from two month ago on daily timeframe?\",\n",
    "    \"Can you get the historical prices for the EURUSD=x forex pair from three month ago on daily timeframe?\",\n",
    "    \"Can you get the historical prices for the EURUSD=x forex pair for the past week on daily timeframe?\",\n",
    "    \"Can you get the historical prices for the EURUSD=x forex pair for one weeks ago on daily timeframe?\",\n",
    "    \n",
    "    \"What are the historical prices for ETH-USD from January 1, 2023 on weekly timeframe?\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "#prompts to test get stock info tool\n",
    "yfinance_prompts2 = [\n",
    "    \"can you give me the address of aapl?\",\n",
    "    \"can you give me the state of aapl?\",\n",
    "    \"can you give me information of apple in General Information category?\",\n",
    "    \"can you give me all information of AAPL?\",\n",
    "    \"can you give me Stock Price - Volume Information category of information of AAPL?\",\n",
    "    \"Can you give me general Information category of information for AAPL?\",\n",
    "    \"Can you give me Financial Information category of information of AAPL?\",\n",
    "    \"Can you give me Financial Information category of information of MSFT?\",\n",
    "    \"can you give me information of AAPL?\",\n",
    "    \"tell me about AAPL?\",\n",
    "    \"tell briefly about AAPL?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "#prompts to test earnign_report tool\n",
    "yfinance_prompts3 = [\n",
    "    \"what is the earning report of AAPL at 2024-02-28?\",\n",
    "    \"what is the earning report of AAPL at 2024-02-27?\",\n",
    "    \"what is the earning report of AAPL at 2024-08-01?\",\n",
    "    \"what is the earning report of AAPL at 2024-05-02?\",\n",
    "    \"what is the current earning report of AAPL?\",\n",
    "    \n",
    "    \"what is the latest earning report of AAPL?\",\n",
    "    \"what is the last earning report of AAPL?\",\n",
    "    \"what is the earning report of AAPL at 2023-11-03?\",\n",
    "    \"what is the earning report of AAPL at 2023-11-02?\",\n",
    "    \"what is the earning report of AAPL on 2023-11-02?\",\n",
    "    \n",
    "    \"Can you fetch the earnings reports for AAPL?\",\n",
    "    \"can you give me the earnings reports of MSFT from 2023-10-24 to 2024-04-25?\",\n",
    "    \"can you give me the earnings reports of AAPL from 2023-02-02 to 2024-02-28?\",\n",
    "    \"What is the earning report of AAPL?\",\n",
    "    \"What is the earning report of AAPL from three months ago?\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "#prompts to test get stock news tool\n",
    "yfinance_prompts4 = [\n",
    "    \"Can you give me the news of AAPL?\",\n",
    "    \"Can you give me the most two important news of AAPL? and tell me why these news are the most important?\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "#in order to test get_stock_info tool use yfinance_prompts2, for get_earning tool use yfinance_prompts3, for getstocknews use yfinance_prompts4 instead of yfinance_prompts\n",
    "yfinance_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in yfinance_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    yfinance_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/introduction_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(yfinance_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odd Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "odd_prompts = [\n",
    "\t\"Trend in the last month\" ,\n",
    "\t\"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\" ,\n",
    "\t\"What about market today?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "odd_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in odd_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    odd_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/odd_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(odd_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Chat Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_chat_scenario_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Hello\",\n",
    "    \"Who are you?\",\n",
    "    \"What can you do for me?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"For the past week\",\n",
    "    \"Can you also calculate the sr of it, too?\",\n",
    "    \"But how about the trend of it for the last month?\",\n",
    "    \"But how about the trend of it for the last year?\",\n",
    "    \"But how about the trend of it for the last day?\",\n",
    "    \"But how about the trend of it for the last hour?\",\n",
    "    \"Hi!\",\n",
    "    \"Can you calculate the sr of it?\",\n",
    "    \"What else can you do?\",\n",
    "    \"So how would be the stop loss for the short position?\",\n",
    "    \"How about long ones?\",\n",
    "    \"So what would be the take profit based on this stop loss?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "long_chat_scenario_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in long_chat_scenario_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    long_chat_scenario_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/long_chat_scenario_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(long_chat_scenario_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_function_calling_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the ternd and sr of NQ?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "parallel_function_calling_results = {}\n",
    "\n",
    "# # getting the answer of the prompts\n",
    "# try:\n",
    "for prompt in parallel_function_calling_prompts:\n",
    "    input_json = {\n",
    "        \"file_path\": None,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    parallel_function_calling_results[prompt]=output_json\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"test_results/parallel_function_calling_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(parallel_function_calling_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of file paths and prompts\n",
    "messages = []\n",
    "\n",
    "file_paths = [\"samplefiles/TjqcZqip.png\", 'samplefiles/applyjobs.xlsx', 'samplefiles/paper.docx',\n",
    "              'samplefiles/sample.pdf', 'samplefiles/transcription.txt', 'samplefiles/english.mp3', None]\n",
    "\n",
    "general_prompts = [\"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"What is the trend of NQ stock from 3/10/2023 15:45:30 until 3/11/2023 15:45:30?\"]\n",
    "\n",
    "# Iterate over file_paths and prompts and run the code\n",
    "for file_path, prompt in zip(file_paths, general_prompts):\n",
    "    input_json = {\n",
    "        \"file_path\": file_path,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the speed of light?    =>    I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\n",
      "tell me about english teaching    =>    I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\n"
     ]
    }
   ],
   "source": [
    "irrelevant_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the speed of light?\",\n",
    "    \"tell me about english teaching\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]\n",
    "\n",
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "irrelevant_results = {}\n",
    "\n",
    "# # getting the answer of the prompts\n",
    "# try:\n",
    "for prompt in irrelevant_prompts:\n",
    "    input_json = {\n",
    "        \"file_path\": file_path,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    irrelevant_results[prompt]=output_json\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"test_results/irrelevant_prompts_results.json\", \"w\") as outputfile: \n",
    "    json.dump(irrelevant_results, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech file detected. Processing speech...\n",
      "Speech processing complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The main idea of this file is to provide information about long-term trading in the stock market. It explains that long-term trading involves buying shares of a company and holding onto them for an extended period, with the goal of benefiting from the company's growth over time and earning dividends. Long-term traders are often categorized as investors or position traders.\",\n",
       " {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'samplefiles/tts_test.mp3'\n",
    "messages = []\n",
    "prompt = None\n",
    "\n",
    "input_json = {\n",
    "    \"file_path\": file_path,\n",
    "    \"prompt\": None,\n",
    "    \"messages\": messages,\n",
    "    \"front_json\": input_filter.front_end_json_sample\n",
    "}\n",
    "\n",
    "output_json = main.main(input_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The founders of Microsoft are Bill Gates and Paul Allen. They established the company on April 4, 1975, with the goal of developing and selling software for personal computers. Bill Gates is particularly known for his role in shaping the company's vision and strategy, while Paul Allen played a significant role in technical aspects and product development.\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurf.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '74b3de375b964f73a6b7668fe459e26f'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Corporation was founded by Bill Gates and Paul Allen. Bill Gates, currently one of the world's wealthiest individuals, served as Microsoft's Chairman and CEO for many years before transitioning to a role as a technology advisor. Paul Allen was a prominent philanthropist and entrepreneur who co-founded Microsoft with Bill Gates, but he passed away in 2018.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '80ddd1ad72504f2fa226755d49491a61'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\deepeval\\__init__.py:42: UserWarning: You are using deepeval version 0.21.43, however version 0.21.45 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from UnitTest import unit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_test.unit_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
