{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import merged\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing each function individualy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "detect_trend_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the trend of NQ stock from 20/4/2024 15:45:30 until 24/4/2024 15:45:30?\",\n",
    "    \"What is the trend of NQ stock for the past week?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"What is the trend?\",\n",
    "    \"Show me the trend of ES from 2024-03-25 11:12:17 to 2024-04-01 9:31:23.\",\n",
    "    \"Trend of GC, 2024-03-25 11:12:17 to 2024-04-01 9:31:23\",\n",
    "    \"Trend of GC, past 2 hours\",\n",
    "    # Challenging Prompts\n",
    "    \"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\",\n",
    "    \"What is the trend of NQ stock from 20/5/2024 15:45:30 until 24/4/2024 15:45:30?\",\n",
    "    \"What is the trend of NQ stock from 20/4/2024 15:45:30 until 24/3/2024 15:45:30?\",\n",
    "    \"What is the trend of NQ stock from 4/20/2024 15:45:30 until 4/24/2024 15:45:30?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"20/4/2024 15:45:30\",\\n  \"end_datetime\": \"24/4/2024 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\GradioFunctionCallingApp\\functions_python.ipynb:832: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  start_datetime = pd.to_datetime(start_datetime)\n",
      "c:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\GradioFunctionCallingApp\\functions_python.ipynb:834: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  end_datetime = pd.to_datetime(end_datetime)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x00000260443E5FC0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-20T22:45:30Z), stop: time(v: 2024-04-24T22:45:30Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ stock from 20/4/2024 15:45:30 until 24/4/2024 15:45:30?    =>    The trend of the NQ stock from 20/4/2024 15:45:30 until 24/4/2024 15:45:30 is without a significant trend.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"lookback\": \"1 week\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000026044404160>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-23T00:16:32Z), stop: time(v: 2024-04-30T00:16:32Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ stock for the past week?    =>    The trend of the NQ stock for the past week is without a significant trend.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x000002604441A470>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-20T00:16:38Z), stop: time(v: 2024-04-30T00:16:38Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ?    =>    To determine the trend of the NQ stock, please specify the time range or lookback period you would like to analyze. You can provide the start and end dates, or specify a lookback period in seconds, minutes, hours, days, weeks, months, or years.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000026044423400>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-20T00:16:44Z), stop: time(v: 2024-04-30T00:16:44Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend?    =>    To determine the trend of the NQ stock, please provide a specific time range or a lookback period. The trend analysis requires either the start and end dates or the number of seconds, minutes, hours, days, weeks, months, or years to look back.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"ES\",\\n  \"start_datetime\": \"2024-03-25 11:12:17\",\\n  \"end_datetime\": \"2024-04-01 9:31:23\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Show me the trend of ES from 2024-03-25 11:12:17 to 2024-04-01 9:31:23.    =>    Please enter dates in the following foramat: %d/%m/%Y %H:%M:%S or specify a period of time whether for the past seconds or minutes or hours or days or weeks or years.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"GC\",\\n  \"start_datetime\": \"2024-03-25 11:12:17\",\\n  \"end_datetime\": \"2024-04-01 9:31:23\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Trend of GC, 2024-03-25 11:12:17 to 2024-04-01 9:31:23    =>    Please enter dates in the following foramat: %d/%m/%Y %H:%M:%S or specify a period of time whether for the past seconds or minutes or hours or days or weeks or years.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"GC\",\\n  \"lookback\": \"2 hours\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x0000026044410910>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-29T22:16:51Z), stop: time(v: 2024-04-30T00:16:51Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"GC\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "Trend of GC, past 2 hours    =>    The trend of the GC stock for the past 2 hours is without a significant trend.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"3/4/2024/45 15:45:30\",\\n  \"end_datetime\": \"3/4/2024/67 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?    =>    Please enter dates in the following foramat: %d/%m/%Y %H:%M:%S or specify a period of time whether for the past seconds or minutes or hours or days or weeks or years.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"20/5/2024 15:45:30\",\\n  \"end_datetime\": \"24/4/2024 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "What is the trend of NQ stock from 20/5/2024 15:45:30 until 24/4/2024 15:45:30?    =>    Dates should not be in the future!\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"20/4/2024 15:45:30\",\\n  \"end_datetime\": \"24/3/2024 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "What is the trend of NQ stock from 20/4/2024 15:45:30 until 24/3/2024 15:45:30?    =>    End date time should be after start date time!\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"4/20/2024 15:45:30\",\\n  \"end_datetime\": \"4/24/2024 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "What is the trend of NQ stock from 4/20/2024 15:45:30 until 4/24/2024 15:45:30?    =>    Please enter dates in the following foramat: %d/%m/%Y %H:%M:%S or specify a period of time whether for the past seconds or minutes or hours or days or weeks or years.\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "llm = merged.FileProcessor()\n",
    "for prompt in detect_trend_prompts:\n",
    "    result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "    print(f\"{prompt}    =>    {result}\")\n",
    "    results[prompt]=result\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "#     # saving the answers\n",
    "#     with open(\"test_results/detect_trend_test_results.json\", \"w\") as outfile: \n",
    "#         json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Support and Resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sr_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 1 hour.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM by the timeframe of 1 hour.\",\n",
    "    \"How much is the sr of CL for the past week?\",\n",
    "    # Challenging prompts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "llm = merged.FileProcessor()\n",
    "for prompt in calculate_sr_prompts:\n",
    "    result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "    print(f\"{prompt}    =>    {result}\")\n",
    "    results[prompt]=result\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "#     # saving the answers\n",
    "#     with open(\"test_results/calculate_sr_test_results.json\", \"w\") as outfile: \n",
    "#         json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Stop Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sl_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"How much would be the stop loss for trading based on NQ and short positions with minmax method by looking back up to 30 candles and considering 50 candles neighboring the current time and also attribute coefficient of 1.3?\",\n",
    "    \"How much would be the stop loss for trading based on NQ and short positions with minmax method by looking back up to 30 candles and considering 50 candles neighboring the current time?\",\n",
    "    \"How much would be the stop loss for trading based on NQ and short positions with minmax method by looking back up to 30 candles?\",\n",
    "    \"How much would be the stop loss for trading based on NQ and short positions with minmax method?\",\n",
    "    \"How much would be the stop loss for trading based on NQ and short positions?\",\n",
    "    \"How much would be the stop loss for trading based on NQ?\",\n",
    "    \"How much would be the stop loss for trading?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"method\": \"minmax\",\\n  \"direction\": \"-1\",\\n  \"lookback\": 30,\\n  \"neighborhood\": 50,\\n  \"atr_coef\": 1.3\\n}', name='calculate_sl'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x000001F4F8EC1D80>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-27T01:22:06Z), stop: time(v: 2024-05-01T01:22:06Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "How much would be the stop loss for trading based on NQ and short positions with minmax method by looking back up to 30 candles and considering 50 candles neighboring the current time and also attribute coefficient of 1.3?    =>    The stop loss for trading based on NQ and short positions, using the minmax method with a lookback of 30 candles and considering 50 candles neighboring the current time, and an attribute coefficient of 1.3, is not available. Please make sure the parameters are correct and try again.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"method\": \"minmax\",\\n  \"direction\": \"-1\",\\n  \"lookback\": 30,\\n  \"neighborhood\": 50\\n}', name='calculate_sl'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x000001F4F8ECD960>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-27T01:22:12Z), stop: time(v: 2024-05-01T01:22:12Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "How much would be the stop loss for trading based on NQ and short positions with minmax method by looking back up to 30 candles and considering 50 candles neighboring the current time?    =>    The stop loss for trading based on NQ and short positions, using the minmax method with a lookback of 30 candles and considering 50 candles neighboring the current time, is currently not available. Please try again later or consider using a different method for calculating the stop loss.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"method\": \"minmax\",\\n  \"direction\": \"-1\",\\n  \"lookback\": 30\\n}', name='calculate_sl'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x000001F4F8ECDF30>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-27T01:22:18Z), stop: time(v: 2024-05-01T01:22:18Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "How much would be the stop loss for trading based on NQ and short positions with minmax method by looking back up to 30 candles?    =>    The stop loss for trading based on NQ and short positions, using the minmax method and looking back up to 30 candles, could not be calculated. Please make sure you have provided the correct parameters and try again.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"method\": \"minmax\",\\n  \"direction\": \"-1\"\\n}', name='calculate_sl'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x000001F4F8ECF0D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-27T01:22:23Z), stop: time(v: 2024-05-01T01:22:23Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "How much would be the stop loss for trading based on NQ and short positions with minmax method?    =>    The stop loss for trading based on NQ and short positions using the minmax method cannot be determined without specifying the lookback period. Please provide the number of candles to look back in order to calculate the stop loss.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"method\": \"minmax\",\\n  \"direction\": \"-1\"\\n}', name='calculate_sl'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x000001F4F8ED4A60>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-27T01:22:29Z), stop: time(v: 2024-05-01T01:22:29Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "How much would be the stop loss for trading based on NQ and short positions?    =>    The stop loss for trading based on NQ and short positions using the minmax method is currently not available. Please make sure you have provided the correct symbol and direction for the trade.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"method\": \"minmax\",\\n  \"direction\": \"-1\"\\n}', name='calculate_sl'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x000001F4F8ECE1A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-27T01:22:35Z), stop: time(v: 2024-05-01T01:22:35Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "How much would be the stop loss for trading based on NQ?    =>    The stop loss for trading based on NQ and short positions is currently being calculated. Please wait a moment while I retrieve the result for you.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"method\": \"minmax\",\\n  \"direction\": \"-1\"\\n}', name='calculate_sl'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x000001F4F8ECE9E0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-27T01:22:41Z), stop: time(v: 2024-05-01T01:22:41Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "How much would be the stop loss for trading?    =>    The stop loss for trading based on NQ and short positions using the minmax method is {}. Please note that the result of the function call is empty, so I am unable to provide a specific value for the stop loss.\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "llm = merged.FileProcessor()\n",
    "for prompt in calculate_sl_prompts:\n",
    "    result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "    print(f\"{prompt}    =>    {result}\")\n",
    "    results[prompt]=result\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "#     # saving the answers\n",
    "#     with open(\"test_results/calculate_sl_test_results.json\", \"w\") as outfile: \n",
    "#         json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Take-Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_tp_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"How much would be the take-profit of the NQ with the stop loss of 10 and direction of 1?\",\n",
    "    \"How much would be the take-profit of the NQ with the stop loss of 10?\",\n",
    "    \"How much would be the take-profit of the NQ with direction of 1?\",\n",
    "    \"How much would be the take-profit with the stop loss of 10 and direction of 1?\",\n",
    "    \"How much would be the take-profit?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "try:\n",
    "    llm = merged.FileProcessor()\n",
    "    for prompt in calculate_tp_prompts:\n",
    "        result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "        print(f\"{prompt}    =>    {result}\")\n",
    "        results[prompt]=result\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "finally:\n",
    "    # saving the answers\n",
    "    with open(\"test_results/calculate_tp_test_results.json\", \"w\") as outfile: \n",
    "        json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Chat Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_chat_scenario_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Hello\",\n",
    "    \"Who are you?\",\n",
    "    \"What can you do for me?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"For the past week\",\n",
    "    \"Can you also calculate the sr of it, too?\",\n",
    "    \"But how about the trend of it for the last month?\",\n",
    "    \"Can you calculate the sr of it?\",\n",
    "    \"What else can you do?\",\n",
    "    \"So how would be the stop loss for the short position?\",\n",
    "    \"How about long ones?\",\n",
    "    \"So what would be the take profit based on this stop loss?\"\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello    =>    Hi there! How can I assist you today?\n",
      "Who are you?    =>    I am an AI assistant designed to help with various tasks and provide information. I can assist with things like answering questions, providing recommendations, and performing calculations. How can I assist you today?\n",
      "What can you do for me?    =>    I can perform various tasks to assist you. Some of the things I can do include:\n",
      "\n",
      "1. Providing information: I can answer questions and provide information on a wide range of topics.\n",
      "\n",
      "2. Performing calculations: I can help with mathematical calculations, currency conversions, and other numerical tasks.\n",
      "\n",
      "3. Offering recommendations: If you need suggestions for books, movies, restaurants, or other things, I can provide recommendations based on your preferences.\n",
      "\n",
      "4. Assisting with productivity: I can help with tasks like setting reminders, creating to-do lists, and managing your schedule.\n",
      "\n",
      "5. Providing financial analysis: I can analyze financial data, detect trends in the market, calculate support and resistance levels, and determine stop-loss and take-profit levels.\n",
      "\n",
      "6. Language translation: I can translate text between different languages.\n",
      "\n",
      "These are just a few examples of what I can do. If you have a specific request or need assistance with something, feel free to let me know!\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x000001F4F7BABB50>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-04-21T00:24:48Z), stop: time(v: 2024-05-01T00:24:48Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ?    =>    To determine the trend of NQ, I need more information. Could you please specify the time range for which you would like to analyze the trend? You can provide either the start and end timestamps or the lookback period.\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m llm \u001b[38;5;241m=\u001b[39m merged\u001b[38;5;241m.\u001b[39mFileProcessor()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m long_chat_scenario_prompts:\n\u001b[1;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m    =>    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# results[prompt]=result\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     with open(\"test_results/long_chat_scenario_test_results.json\", \"w\") as outfile: \u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#         json.dump(results, outfile)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\GradioFunctionCallingApp\\merged.py:386\u001b[0m, in \u001b[0;36mFileProcessor.get_user_input\u001b[1;34m(self, file_path, prompt, messages)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompt:\n\u001b[0;32m    385\u001b[0m     content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_with_ai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\GradioFunctionCallingApp\\merged.py:178\u001b[0m, in \u001b[0;36mFileProcessor.chat_with_ai\u001b[1;34m(self, messages, content)\u001b[0m\n\u001b[0;32m    176\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content})\n\u001b[0;32m    177\u001b[0m response \u001b[38;5;241m=\u001b[39m get_response(messages, functions, config\u001b[38;5;241m.\u001b[39mazure_GPT_MODEL_3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 178\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\GradioFunctionCallingApp\\merged.py:65\u001b[0m, in \u001b[0;36mFileProcessor.chat_with_ai.<locals>.get_result\u001b[1;34m(messages, chat_response)\u001b[0m\n\u001b[0;32m     63\u001b[0m     results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m assistant_message\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m function_name \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mfunction_call\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m---> 65\u001b[0m function_arguments \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_call\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m FC \u001b[38;5;241m=\u001b[39m functions_python\u001b[38;5;241m.\u001b[39mFunctionCalls()\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mchat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "# results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "messages = []\n",
    "# try:\n",
    "llm = merged.FileProcessor()\n",
    "for prompt in long_chat_scenario_prompts:\n",
    "    result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "    print(f\"{prompt}    =>    {result}\")\n",
    "    # results[prompt]=result\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "#     # saving the answers\n",
    "#     with open(\"test_results/long_chat_scenario_test_results.json\", \"w\") as outfile: \n",
    "#         json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_function_calling_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the ternd and sr of NQ?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "try:\n",
    "    llm = merged.FileProcessor()\n",
    "    for prompt in calculate_tp_prompts:\n",
    "        result = llm.get_user_input(file_path=None, prompt=prompt, messages=messages)\n",
    "        print(f\"{prompt}    =>    {result}\")\n",
    "        results[prompt]=result\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "finally:\n",
    "    # saving the answers\n",
    "    with open(\"test_results/parallel_function_calling_test_results.json\", \"w\") as outfile: \n",
    "        json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image file detected. VisionGPT processing...\n",
      "An error occurred while processing the image: 401 Client Error: Unauthorized for url: https://api.openai.com/v1/chat/completions\n",
      "The main idea of this file is to provide functions for analyzing financial data and generating insights about trends, support and resistance levels, stop-loss and take-profit levels for trading purposes. These functions can be used to analyze specific financial instruments, such as stocks, and provide information about their trends and potential levels of support and resistance. Additionally, the functions can calculate stop-loss and take-profit levels based on different methods and parameters.\n",
      "Excel file detected. Extracting text...\n",
      "Extraction complete.\n",
      "I apologize, but I'm not sure what file you are referring to. Could you please provide more context or clarify your question?\n",
      "Word document detected. Extracting text...\n",
      "Extraction complete.\n",
      "The main idea of this file is to explain the Beez algorithm, which is an optimization algorithm that combines local search and global search to solve complex optimization problems. The algorithm is inspired by the behavior of bees in a hive, where scout bees search for initial solutions, which are then evaluated and rearranged based on their costs. The algorithm iteratively searches around these initial solutions, generating new solutions and replacing the elite and non-elite solutions with better ones. The process continues for a specified number of iterations until the optimal solution is reached. The file provides a detailed description of the algorithm and its steps.\n",
      "PDF file detected. Extracting text...\n",
      "Extraction complete.\n",
      "The main idea of this file is to provide information and educate investors about the different types of orders they can use to buy and sell stocks through a brokerage firm. The file explains the concepts of market orders and limit orders, highlighting their characteristics and potential risks. It also introduces special orders and trading instructions such as stop orders, stop-limit orders, day orders, good-til-cancelled orders, immediate-or-cancel orders, fill-or-kill orders, and all-or-none orders. The file emphasizes the importance of understanding these order types and instructions, as well as contacting brokerage firms to determine their specific policies and availability. Overall, the file aims to enhance investors' knowledge and awareness of the various options and considerations when trading stocks.\n",
      "Text file detected. Extracting text...\n",
      "Extraction complete.\n",
      "The main idea of this file is to describe a trained model that is optimized for transcribing audio files containing speech in English. The model has been trained on a large dataset of English audio and text. It is capable of transcribing audio files that contain speech in other languages as well, but the output of the model will be in English text. The file also mentions the option of using the whisper model via a short movie or via a short movie, with the readability of the transcribed text being the same. Additionally, the model is capable of handling mixed language audio input and providing the transcription in English. Overall, the file highlights the capabilities and focus of the trained model for transcribing audio files in English.\n",
      "Speech file detected. Processing speech...\n",
      "An error occurred while processing the speech file: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\n",
      "I apologize for the confusion. Based on the information provided, it seems that the main idea of this file is to describe a trained model that is optimized for transcribing audio files containing speech in English. The model has been trained on a large dataset of English audio and text, and it is capable of transcribing audio files in other languages as well. The output of the model is in English text. The file also mentions the option of using the whisper model via a short movie or via a short movie, with the readability of the transcribed text being the same. Additionally, the model can handle mixed language audio input and provide the transcription in English. The primary focus of the file is to explain the capabilities and usage of the trained model for transcribing audio files.\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"symbol\": \"NQ\",\\n  \"start_datetime\": \"3/10/2023 15:45:30\",\\n  \"end_datetime\": \"3/11/2023 15:45:30\"\\n}', name='detect_trend'), tool_calls=None)\n",
      "\n",
      "Error reading data from InfluxDB: <urllib3.connection.HTTPConnection object at 0x00000136C75F3940>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2023-03-10T23:45:30Z), stop: time(v: 2023-03-11T23:45:30Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "The trend of the NQ stock from 3/10/2023 15:45:30 until 3/11/2023 15:45:30 is without a significant trend.\n"
     ]
    }
   ],
   "source": [
    "# Define the list of file paths and prompts\n",
    "messages = merged.messages\n",
    "file_paths = [\"samplefiles/TjqcZqip.png\", 'samplefiles/applyjobs.xlsx', 'samplefiles/paper.docx',\n",
    "              'samplefiles/sample.pdf', 'samplefiles/transcription.txt', 'samplefiles/english.mp3', None]\n",
    "prompts = [\"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"What is the trend of NQ stock from 3/10/2023 15:45:30 until 3/11/2023 15:45:30?\"]\n",
    "\n",
    "# Iterate over file_paths and prompts and run the code\n",
    "for file_path, prompt in zip(file_paths, prompts):\n",
    "    try:\n",
    "        processor = merged.FileProcessor()\n",
    "        print(processor.get_user_input(file_path, prompt, messages))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The founders of Microsoft are Bill Gates and Paul Allen. They established the company on April 4, 1975, with the goal of developing and selling software for personal computers. Bill Gates is particularly known for his role in shaping the company's vision and strategy, while Paul Allen played a significant role in technical aspects and product development.\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurf.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '74b3de375b964f73a6b7668fe459e26f'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Corporation was founded by Bill Gates and Paul Allen. Bill Gates, currently one of the world's wealthiest individuals, served as Microsoft's Chairman and CEO for many years before transitioning to a role as a technology advisor. Paul Allen was a prominent philanthropist and entrepreneur who co-founded Microsoft with Bill Gates, but he passed away in 2018.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '80ddd1ad72504f2fa226755d49491a61'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
