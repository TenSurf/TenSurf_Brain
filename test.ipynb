{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from main import llm_surf\n",
    "import input_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing each function individualy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "detect_trend_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the trend of NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00?\",\n",
    "    \"What is the trend of NQ stock for the past week?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"What is the trend?\",\n",
    "    # \"Show me the trend of ES from May-1-2024 12:00:00 to May-5-2024 12:00:00.\",\n",
    "    # \"Trend of GC, May-1-2024 12:00:00 to May-5-2024 12:00:00\",\n",
    "    # \"Trend of GC, past 2 hours\",\n",
    "    # \"What is the trend of NQ from May-1-2024 12:00:00 until now?\",\n",
    "    # # Challenging Prompts\n",
    "    \"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\",\n",
    "    \"What is the trend of NQ stock from May-20-2024 15:45:30 until Apr-24-2024 15:45:30?\",\n",
    "    # \"What is the trend of NQ stock from 20/4/2024 15:45:30 until 24/3/2024 15:45:30?\",\n",
    "    # \"What is the trend of NQ stock from 4/20/2024 15:45:30 until 4/24/2024 15:45:30?\",\n",
    "    \"Trend of Gold in the last month?\",\n",
    "    \"Trend in the last month\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the trend of NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00?    =>    {'response': 'Based on the analysis of the NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00, the trend is without a significant trend.', 'chart_info': {}}\n",
      "What is the trend of NQ stock for the past week?    =>    {'response': 'Based on the analysis of the NQ stock for the past week, there is no significant trend detected.', 'chart_info': {}}\n",
      "What is the trend of NQ?    =>    {'response': 'The trend of NQ is currently neutral, indicating that there is no significant upward or downward movement in the price.', 'chart_info': {}}\n",
      "What is the trend?    =>    {'response': 'Sure, I can help you determine the trend of a financial instrument. Please provide me with the following information:\\n\\n1. Symbol of the financial instrument.\\n2. Time range or lookback period you want to analyze.\\n\\nOnce I have this information, I will be able to calculate the trend for you.', 'chart_info': None}\n",
      "Error reading data from InfluxDB: (400)\n",
      "Reason: Bad Request\n",
      "HTTP response headers: HTTPHeaderDict({'Content-Type': 'application/json; charset=utf-8', 'Vary': 'Accept-Encoding', 'X-Influxdb-Build': 'OSS', 'X-Influxdb-Version': 'v2.7.3', 'X-Platform-Error-Code': 'invalid', 'Date': 'Mon, 27 May 2024 16:15:28 GMT', 'Transfer-Encoding': 'chunked'})\n",
      "HTTP response body: b'{\"code\":\"invalid\",\"message\":\"error in building plan while starting program: cannot query an empty range\"}'\n",
      "\n",
      " Query is from(bucket:\"bronze\") \n",
      "                |> range(start: time(v:2024-03-04T20:15:30Z), stop: time(v: 2024-03-04T20:15:30Z))\n",
      "                |> filter(fn: (r) => r[\"_measurement\"] == \"NQ\" and                    r[\"timeframe\"] == \"1min\" and                    r[\"liq_threshold\"] == \"-1\")\n",
      "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
      "                \n",
      "There is no data for this period of time...\n",
      "What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?    =>    {'response': 'The trend of the NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30 is neutral, indicating no significant trend.', 'chart_info': {}}\n",
      "What is the trend of NQ stock from May-20-2024 15:45:30 until Apr-24-2024 15:45:30?    =>    {'response': 'No problem! If you provide me with a valid time range, I can help you determine the trend of the NQ stock.', 'chart_info': {}}\n",
      "Trend of Gold in the last month?    =>    {'response': 'Based on the trend analysis, the trend of Gold in the last month is a mild bullish (upward) trend.', 'chart_info': {}}\n",
      "Trend in the last month    =>    {'response': 'Of course! Please provide me with the ticker symbol of the financial instrument you would like to analyze.', 'chart_info': None}\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "detect_trend_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in detect_trend_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    detect_trend_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/detect_trend_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(detect_trend_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Support and Resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sr_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 10 minutes.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM by the timeframe of 1 hour.\",\n",
    "    \"How much is the sr of CL for the past week?\",\n",
    "    # Challenging prompts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 10 minutes.    =>    {'response': 'The support and resistance levels for YM (E-mini Dow Jones Industrial Average) based on a lookback period of 10 days and a timeframe of 10 minutes are as follows:\\n\\n- Support Levels: 40213.0, 40034.0, 40033.0, 40017.0, 40009.0, 39979.0, 39690.0, 39715.0, 39774.0, 39882.0, 39451.0, 39546.0, 39315.0, 39095.0, 39096.0, 39100.0, 39105.0\\n\\n- Resistance Levels: 4.7, 6.0, 3.9, 7.8, 3.3, 7.0, 3.5, 5.8, 4.8, 2.9, 2.8, 3.6, 3.1, 12.5, 9.0, 6.6, 2.8\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.', 'chart_info': {'levels_prices': [40213.0, 40034.0, 40033.0, 40017.0, 40009.0, 39979.0, 39690.0, 39715.0, 39774.0, 39882.0, 39451.0, 39546.0, 39315.0, 39095.0, 39096.0, 39100.0, 39105.0], 'levels_start_timestamps': [Timestamp('2024-05-20 08:30:00'), Timestamp('2024-05-21 12:30:00'), Timestamp('2024-05-21 19:00:00'), Timestamp('2024-05-21 22:50:00'), Timestamp('2024-05-22 07:30:00'), Timestamp('2024-05-22 10:10:00'), Timestamp('2024-05-22 12:50:00'), Timestamp('2024-05-22 18:00:00'), Timestamp('2024-05-23 02:00:00'), Timestamp('2024-05-23 05:10:00'), Timestamp('2024-05-23 08:20:00'), Timestamp('2024-05-23 08:50:00'), Timestamp('2024-05-24 08:10:00'), Timestamp('2024-05-26 18:20:00'), Timestamp('2024-05-26 19:30:00'), Timestamp('2024-05-27 02:40:00'), Timestamp('2024-05-27 06:50:00')], 'levels_detect_timestamps': [Timestamp('2024-05-20 09:20:00'), Timestamp('2024-05-21 13:20:00'), Timestamp('2024-05-21 19:50:00'), Timestamp('2024-05-21 23:40:00'), Timestamp('2024-05-22 08:20:00'), Timestamp('2024-05-22 11:00:00'), Timestamp('2024-05-22 13:40:00'), Timestamp('2024-05-22 18:50:00'), Timestamp('2024-05-23 02:50:00'), Timestamp('2024-05-23 06:00:00'), Timestamp('2024-05-23 09:10:00'), Timestamp('2024-05-23 09:40:00'), Timestamp('2024-05-24 09:00:00'), Timestamp('2024-05-26 19:10:00'), Timestamp('2024-05-26 20:20:00'), Timestamp('2024-05-27 03:30:00'), Timestamp('2024-05-27 07:40:00')], 'levels_end_timestamps': [Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00'), Timestamp('2024-05-27 09:15:00')], 'levels_scores': [4.7, 6.0, 3.9, 7.8, 3.3, 7.0, 3.5, 5.8, 4.8, 2.9, 2.8, 3.6, 3.1, 12.5, 9.0, 6.6, 2.8], 'function_name': 'calculate_sr', 'symbol': 'YM'}}\n",
      "Calculate Support and Resistance Levels based on YM by looking back up to past 10 days.    =>    {'response': 'These support and resistance levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.\\n\\nSupport Levels: 40034.0, 40033.0, 40017.0, 40009.0, 39668.0, 39715.0, 39864.0, 39774.0, 39882.0, 39315.0, 39095.0, 39100.0, 39105.0\\n\\nResistance Levels: These levels are determined based on historical price data and indicate areas where the price is likely to encounter resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.\\n\\nPlease note that the timestamps provided indicate the start, detection, and end times for each level.', 'chart_info': {'levels_prices': [40034.0, 40033.0, 40017.0, 40009.0, 39668.0, 39715.0, 39864.0, 39774.0, 39882.0, 39315.0, 39095.0, 39100.0, 39105.0], 'levels_start_timestamps': [Timestamp('2024-05-21 12:00:00'), Timestamp('2024-05-21 19:00:00'), Timestamp('2024-05-21 22:00:00'), Timestamp('2024-05-22 07:00:00'), Timestamp('2024-05-22 11:00:00'), Timestamp('2024-05-22 18:00:00'), Timestamp('2024-05-22 21:00:00'), Timestamp('2024-05-23 02:00:00'), Timestamp('2024-05-23 05:00:00'), Timestamp('2024-05-24 08:00:00'), Timestamp('2024-05-26 18:00:00'), Timestamp('2024-05-27 02:00:00'), Timestamp('2024-05-27 06:00:00')], 'levels_detect_timestamps': [Timestamp('2024-05-21 15:00:00'), Timestamp('2024-05-21 21:00:00'), Timestamp('2024-05-22 00:00:00'), Timestamp('2024-05-22 09:00:00'), Timestamp('2024-05-22 13:00:00'), Timestamp('2024-05-22 20:00:00'), Timestamp('2024-05-22 23:00:00'), Timestamp('2024-05-23 04:00:00'), Timestamp('2024-05-23 07:00:00'), Timestamp('2024-05-24 10:00:00'), Timestamp('2024-05-26 20:00:00'), Timestamp('2024-05-27 04:00:00'), Timestamp('2024-05-27 08:00:00')], 'levels_end_timestamps': [Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00')], 'levels_scores': [3.8, 4.1, 6.1, 3.9, 3.3, 2.7, 1.8, 3.3, 7.3, 2.9, 5.7, 4.9, 3.3], 'function_name': 'calculate_sr', 'symbol': 'YM'}}\n",
      "Calculate Support and Resistance Levels based on YM by the timeframe of 1 hour.    =>    {'response': 'The support and resistance levels for YM based on a 1-hour timeframe are as follows:\\n\\n- Support Levels: 40034.0, 40033.0, 40017.0, 40009.0, 39668.0, 39715.0, 39864.0, 39774.0, 39882.0, 39315.0, 39095.0, 39100.0, 39105.0\\n\\n- Resistance Levels: 40034.0, 40033.0, 40017.0, 40009.0, 39668.0, 39715.0, 39864.0, 39774.0, 39882.0, 39315.0, 39095.0, 39100.0, 39105.0\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.', 'chart_info': {'levels_prices': [40034.0, 40033.0, 40017.0, 40009.0, 39668.0, 39715.0, 39864.0, 39774.0, 39882.0, 39315.0, 39095.0, 39100.0, 39105.0], 'levels_start_timestamps': [Timestamp('2024-05-21 12:00:00'), Timestamp('2024-05-21 19:00:00'), Timestamp('2024-05-21 22:00:00'), Timestamp('2024-05-22 07:00:00'), Timestamp('2024-05-22 11:00:00'), Timestamp('2024-05-22 18:00:00'), Timestamp('2024-05-22 21:00:00'), Timestamp('2024-05-23 02:00:00'), Timestamp('2024-05-23 05:00:00'), Timestamp('2024-05-24 08:00:00'), Timestamp('2024-05-26 18:00:00'), Timestamp('2024-05-27 02:00:00'), Timestamp('2024-05-27 06:00:00')], 'levels_detect_timestamps': [Timestamp('2024-05-21 15:00:00'), Timestamp('2024-05-21 21:00:00'), Timestamp('2024-05-22 00:00:00'), Timestamp('2024-05-22 09:00:00'), Timestamp('2024-05-22 13:00:00'), Timestamp('2024-05-22 20:00:00'), Timestamp('2024-05-22 23:00:00'), Timestamp('2024-05-23 04:00:00'), Timestamp('2024-05-23 07:00:00'), Timestamp('2024-05-24 10:00:00'), Timestamp('2024-05-26 20:00:00'), Timestamp('2024-05-27 04:00:00'), Timestamp('2024-05-27 08:00:00')], 'levels_end_timestamps': [Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00'), Timestamp('2024-05-27 09:16:00')], 'levels_scores': [3.8, 4.1, 6.1, 3.9, 3.3, 2.7, 1.8, 3.3, 7.3, 2.9, 5.7, 4.9, 3.3], 'function_name': 'calculate_sr', 'symbol': 'YM'}}\n",
      "How much is the sr of CL for the past week?    =>    {'response': 'I apologize for the inconvenience. It seems that there is no available data to calculate the support and resistance levels for CL (Crude Oil) for the past week. If you have any other questions or need assistance with anything else, please let me know.', 'chart_info': {'levels_prices': [], 'levels_start_timestamps': [], 'levels_detect_timestamps': [], 'levels_end_timestamps': [], 'levels_scores': [], 'function_name': 'calculate_sr', 'symbol': 'CL'}}\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_sr_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_sr_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    calculate_sr_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_sr_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_sr_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Stop Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sl_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?\",\n",
    "    \"What would be the stop loss of trading long positinos based on ES and swing method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and atr method and attribute coefficient of 1.3?\",\n",
    "    \"What would be the stop loss of trading long positinos based on YM and level method?\",\n",
    "    \"What would be the stop loss of trading long positinos based on NQ and DVWAP_band method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and WVWAP_band method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on GC and zigzag method?\",\n",
    "    \"What would be the stop loss of trading long positinos based on ES?\",\n",
    "    # Challenging prompts\n",
    "    \"How much would be the stop loss for trading?\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?    =>    {'response': 'Based on the NQ symbol and using the minmax method with a lookback of 30 candles, the stop loss for short positions would be at 18934.75. The risk on this trade is 9.75 points. This stop loss is calculated based on the maximum high price of the previous 30 candles.', 'chart_info': {}}\n",
      "What would be the stop loss of trading long positinos based on ES and swing method?    =>    {'response': 'The stop loss for trading long positions based on ES and the swing method is as follows:\\n\\n- SL 1: 5320.5\\n- SL 2: 5319.5\\n- SL 3: 5318.5\\n- SL 4: 5318.25\\n- SL 5: 5317.25\\n- SL 6: 5317.0\\n- SL 7: 5317.0\\n- SL 8: 5315.5\\n- SL 9: 5314.75\\n- SL 10: 5314.5\\n- SL 11: 5312.5\\n- SL 12: 5309.25\\n\\nThe corresponding risk values for each stop loss are:\\n\\n- Risk 1: 11.25\\n- Risk 2: 12.25\\n- Risk 3: 13.25\\n- Risk 4: 13.5\\n- Risk 5: 14.5\\n- Risk 6: 14.75\\n- Risk 7: 14.75\\n- Risk 8: 16.25\\n- Risk 9: 17.0\\n- Risk 10: 17.25\\n- Risk 11: 19.25\\n- Risk 12: 22.5\\n\\nThese stop loss levels were calculated based on the low swing with a neighborhood parameter of 20 candles.', 'chart_info': {}}\n",
      "What would be the stop loss of trading short positinos based on NQ and atr method and attribute coefficient of 1.3?    =>    {'response': 'FINAL ANSWER\\n\\nThe stop loss for trading short positions based on the NQ and ATR method with an attribute coefficient of 1.3 would be at 18,954.0. The risk on the trade would be 6.75 points. This stop loss is calculated based on the Average True Range (ATR) with a length of 14, multiplied by the coefficient of 1.3.', 'chart_info': {}}\n",
      "What would be the stop loss of trading long positinos based on YM and level method?    =>    {'response': 'The stop loss for trading long positions based on YM using the level method is determined by various levels such as VWAP_Top_Band, WVWAP_Top_Band, Overnight_high, 5min_SR, VP_POC, initial_balance_high, VWAP_Top_Band, WVWAP_Top_Band, and more. The stop loss levels and their corresponding risk values are as follows:\\n\\n- Stop Loss 1: 39172.0 (Risk: 6.0)\\n- Stop Loss 2: 39169.0 (Risk: 9.0)\\n- Stop Loss 3: 39162.0 (Risk: 16.0)\\n- Stop Loss 4: 39154.0 (Risk: 24.0)\\n- Stop Loss 5: 39152.0 (Risk: 26.0)\\n- Stop Loss 6: 39150.0 (Risk: 28.0)\\n- Stop Loss 7: 39143.0 (Risk: 35.0)\\n- Stop Loss 8: 39133.0 (Risk: 45.0)\\n- Stop Loss 9: 39132.0 (Risk: 46.0)\\n- Stop Loss 10: 39128.0 (Risk: 50.0)\\n- Stop Loss 11: 39123.0 (Risk: 55.0)\\n- Stop Loss 12: 39114.0 (Risk: 64.0)\\n- Stop Loss 13: 39113.0 (Risk: 65.0)\\n- Stop Loss 14: 39105.0 (Risk: 73.0)\\n- Stop Loss 15: 39103.0 (Risk: 75.0)\\n- Stop Loss 16: 39100.0 (Risk: 78.0)\\n- Stop Loss 17: 39095.0 (Risk: 83.0)\\n- Stop Loss 18: 39093.0 (Risk: 85.0)\\n\\nThese stop loss levels are calculated based on historical price data and indicate areas where the price is likely to encounter resistance. The associated risk values represent the potential loss if the price moves against the trade.', 'chart_info': {}}\n",
      "What would be the stop loss of trading long positinos based on NQ and DVWAP_band method?    =>    {'response': 'Based on the DVWAP_band method, the stop loss for trading long positions on NQ would be 18927.75. The risk on the trade is 19.75 points. This stop loss is calculated based on VWAP_Top_Band_3 as the bottom of the VWAP zone 4, with the current price being inside VWAP zone 5.', 'chart_info': {}}\n",
      "What would be the stop loss of trading short positinos based on NQ and WVWAP_band method?    =>    {'response': 'Based on the WVWAP_band method, the stop loss for trading short positions on NQ would be at 18968.25. The risk on this trade is 20.75 points. This stop loss is calculated based on WVWAP_Top_Band_6 as the ceiling of the wvwap zone 6, with the current price being inside wvwap zone 5.', 'chart_info': {}}\n",
      "What would be the stop loss of trading short positinos based on GC and zigzag method?    =>    {'response': 'Based on the GC and zigzag method, the stop loss for trading short positions would be 2357.38 and 2358.45. The risk on these trades would be 2.38 and 3.45 respectively. The stop loss values are calculated based on the last session zigzag and the last 5 zigzag legs of the same day of the week.', 'chart_info': {}}\n",
      "What would be the stop loss of trading long positinos based on ES?    =>    {'response': 'Based on the ES (E-mini S&P 500) symbol, there are multiple methods to calculate the stop loss for long positions. Here are some of the methods and their corresponding stop loss values:\\n\\n1. ATR Method: The stop loss is calculated based on the Average True Range (ATR) indicator with a length of 14 and a coefficient of 1. The stop loss values range from 5331.0 to 5273.5.\\n\\n2. VWAP Method: The stop loss is calculated based on the VWAP_Top_Band_4 level, which represents the bottom of the VWAP zone 5. The stop loss value is 5329.75.\\n\\n3. WVWAP Method: The stop loss is calculated based on the WVWAP_Top_Band_4 level, which represents the bottom of the WVWAP zone 5. The stop loss value is 5329.75.\\n\\n4. Level Method: The stop loss is calculated based on the VP_VAH level. The stop loss value is 5329.75.\\n\\nPlease note that these are just a few examples of the stop loss values for long positions based on different methods. The actual stop loss value may vary depending on the chosen method and other factors.', 'chart_info': {}}\n",
      "How much would be the stop loss for trading?    =>    {'response': 'To calculate the stop loss for your trading, I need the following information:\\n\\n1. Ticker symbol of the financial instrument you want to trade.\\n2. Direction of the trade (long or short).\\n3. Method you want to use for calculating the stop loss (e.g., minmax, swing, atr, etc.).\\n\\nPlease provide these details so that I can assist you further.', 'chart_info': None}\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_sl_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_sl_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    calculate_sl_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_sl_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_sl_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Take-Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_tp_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"How much would be the take-profit of the NQ with the stop loss of 10 and direction of 1?\",\n",
    "    \"How much would be the take-profit of the NQ with the stop loss of 10?\",\n",
    "    \"How much would be the take-profit of the NQ with direction of 1?\",\n",
    "    \"How much would be the take-profit with the stop loss of 10 and direction of 1?\",\n",
    "    \"How much would be the take-profit?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much would be the take-profit of the NQ with the stop loss of 10 and direction of 1?    =>    {'response': 'I apologize, but it seems that I am unable to calculate the take-profit (TP) for the NQ with the given parameters. The calculate_tp function did not provide any results for the TP and info parameters. Is there anything else I can assist you with?', 'chart_info': {}}\n",
      "How much would be the take-profit of the NQ with the stop loss of 10?    =>    {'response': 'I apologize, but it seems that I am unable to calculate the take-profit (TP) for the NQ with a stop loss of 10 at the moment. The calculate_tp function did not provide any information regarding the TP. Is there anything else I can assist you with?', 'chart_info': {}}\n",
      "How much would be the take-profit of the NQ with direction of 1?    =>    {'response': \"I apologize, but I don't have the information to calculate the take-profit for the NQ with a direction of 1 at the moment. Is there anything else I can assist you with?\", 'chart_info': {}}\n",
      "How much would be the take-profit with the stop loss of 10 and direction of 1?    =>    {'response': 'Apologies for the confusion. To calculate the take-profit value, we need additional information such as the symbol of the financial instrument and the method or levels to base the calculation on. Please provide the necessary details so that we can assist you further.', 'chart_info': {}}\n",
      "How much would be the take-profit?    =>    {'response': 'To calculate the take-profit (TP), I need the following information:\\n1. Symbol of the financial instrument.\\n2. Direction of the trade (long or short).\\n3. If you have a specific stop-loss (SL) value, please provide it.\\n\\nPlease provide the above information so that I can calculate the take-profit for you.', 'chart_info': None}\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_tp_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_tp_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    calculate_tp_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_tp_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_tp_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "get_bias_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Tell me about the bias of ES on the market.\",\n",
    "    \"What is the current trading bias for ES?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about the bias of ES on the market.    =>    {'response': 'Based on the analysis of different methods, the bias of ES on the market is determined to be bullish. This conclusion is supported by multiple indicators, including the weekly VWAP, VAL/VAH of volume profile, short-term trend, mid-term trend, long-term trend, trend of the last hour, and counter ratio and power ratio. The combined bias is also bullish.', 'chart_info': {}}\n",
      "What is the current trading bias for ES?    =>    {'response': 'The current trading bias for ES is bullish. This is determined based on various methods including weekly VWAP, VAL/VAH of volume profile, short term trend, mid term trend, long term trend, trend of last hour, and counter ratio and power ratio. The combined bias is also bullish.', 'chart_info': {}}\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "get_bias_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in get_bias_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    get_bias_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/get_bias_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(get_bias_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "introduction_prompts = [\n",
    "    # # Normal Prompts\n",
    "    # \"Who are you?\",\n",
    "    # \"What are you?\",\n",
    "    # \"What can you do for me?\",\n",
    "    # \"What are your functionalities?\",\n",
    "    # \"How can you help me?\",\n",
    "    # # Challenging prompts\n",
    "    # \"Hi!\",\n",
    "    # \"Good Morning!\",\n",
    "    # \"What's up!?\",\n",
    "    # \"How can I start?\",\n",
    "    # \"Please help me!\",\n",
    "    # \"What is TenSurf?\",\n",
    "    # \"How could you help me?\",\n",
    "    \"What about market today?\",\n",
    "    \"Could you guide me on how to use tensurf?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "introduction_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in introduction_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    introduction_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/introduction_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(introduction_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odd Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "odd_prompts = [\n",
    "\t\"Trend in the last month\" ,\n",
    "\t\"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\" ,\n",
    "\t\"What about market today?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'function_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m odd_prompts:\n\u001b[0;32m      8\u001b[0m     input_json \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_message\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     }\n\u001b[1;32m---> 19\u001b[0m     output_json \u001b[38;5;241m=\u001b[39m \u001b[43mllm_surf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m    =>    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     odd_results[prompt]\u001b[38;5;241m=\u001b[39moutput_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\TenSurf_Brain\\main.py:118\u001b[0m, in \u001b[0;36mllm_surf\u001b[1;34m(llm_input)\u001b[0m\n\u001b[0;32m    114\u001b[0m     MA \u001b[38;5;241m=\u001b[39m Multi_Agent(\n\u001b[0;32m    115\u001b[0m         ChatWithOpenai\u001b[38;5;241m=\u001b[39mChatWithOpenai, client\u001b[38;5;241m=\u001b[39mazure_connector_surf\u001b[38;5;241m.\u001b[39mclient\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m     graph \u001b[38;5;241m=\u001b[39m MA\u001b[38;5;241m.\u001b[39minitialize_graph()\n\u001b[1;32m--> 118\u001b[0m     llm_output \u001b[38;5;241m=\u001b[39m \u001b[43mMA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_multi_agent_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# running in single-agent mode\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODE\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\TenSurf_Brain\\multi_agent\\multi_agent.py:86\u001b[0m, in \u001b[0;36mMulti_Agent.generate_multi_agent_answer\u001b[1;34m(self, input_json, graph)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_multi_agent_answer\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_json, graph):\n\u001b[0;32m     73\u001b[0m     generated_messages \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m     74\u001b[0m         {\n\u001b[0;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m150\u001b[39m},\n\u001b[0;32m     84\u001b[0m     )\n\u001b[1;32m---> 86\u001b[0m     generated_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerated_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(generated_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generated_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][k]:\n",
      "File \u001b[1;32mc:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\langgraph\\pregel\\__init__.py:834\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m    827\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mwait(\n\u001b[0;32m    828\u001b[0m     futures,\n\u001b[0;32m    829\u001b[0m     return_when\u001b[38;5;241m=\u001b[39mconcurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFIRST_EXCEPTION,\n\u001b[0;32m    830\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m    831\u001b[0m )\n\u001b[0;32m    833\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 834\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# combine pending writes from all tasks\u001b[39;00m\n\u001b[0;32m    837\u001b[0m pending_writes \u001b[38;5;241m=\u001b[39m deque[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]()\n",
      "File \u001b[1;32mc:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1334\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(done, inflight, step)\u001b[0m\n\u001b[0;32m   1332\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m   1333\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m-> 1334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m   1337\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m   1339\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\langgraph\\pregel\\retry.py:66\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     64\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\langchain_core\\runnables\\base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\langgraph\\utils.py:89\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m     83\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, config)\n\u001b[0;32m     84\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     85\u001b[0m         {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: config}\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m     88\u001b[0m     )\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Sepehr\\Science\\AI\\3.LearningAlgorithms\\DeepLearning\\TenSurf\\FunctionCalling\\TenSurf_Brain\\multi_agent\\utils.py:151\u001b[0m, in \u001b[0;36mUtils.tool_node\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    148\u001b[0m messages \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    149\u001b[0m last_message \u001b[38;5;241m=\u001b[39m messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    150\u001b[0m tool_input \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\n\u001b[1;32m--> 151\u001b[0m     \u001b[43mlast_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    152\u001b[0m )\n\u001b[0;32m    153\u001b[0m output_json \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tool_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__arg1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tool_input:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'function_call'"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "odd_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in odd_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    odd_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/odd_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(odd_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Chat Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_chat_scenario_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Hello\",\n",
    "    \"Who are you?\",\n",
    "    \"What can you do for me?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"For the past week\",\n",
    "    \"Can you also calculate the sr of it, too?\",\n",
    "    \"But how about the trend of it for the last month?\",\n",
    "    \"But how about the trend of it for the last year?\",\n",
    "    \"But how about the trend of it for the last day?\",\n",
    "    \"But how about the trend of it for the last hour?\",\n",
    "    \"Hi!\",\n",
    "    \"Can you calculate the sr of it?\",\n",
    "    \"What else can you do?\",\n",
    "    \"So how would be the stop loss for the short position?\",\n",
    "    \"How about long ones?\",\n",
    "    \"So what would be the take profit based on this stop loss?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "long_chat_scenario_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in long_chat_scenario_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    long_chat_scenario_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/long_chat_scenario_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(long_chat_scenario_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_function_calling_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the ternd and sr of NQ?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "parallel_function_calling_results = {}\n",
    "\n",
    "# # getting the answer of the prompts\n",
    "# try:\n",
    "for prompt in parallel_function_calling_prompts:\n",
    "    input_json = {\n",
    "        \"file_path\": None,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    parallel_function_calling_results[prompt]=output_json\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"test_results/parallel_function_calling_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(parallel_function_calling_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of file paths and prompts\n",
    "messages = []\n",
    "\n",
    "file_paths = [\"samplefiles/TjqcZqip.png\", 'samplefiles/applyjobs.xlsx', 'samplefiles/paper.docx',\n",
    "              'samplefiles/sample.pdf', 'samplefiles/transcription.txt', 'samplefiles/english.mp3', None]\n",
    "\n",
    "general_prompts = [\"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"What is the trend of NQ stock from 3/10/2023 15:45:30 until 3/11/2023 15:45:30?\"]\n",
    "\n",
    "# Iterate over file_paths and prompts and run the code\n",
    "for file_path, prompt in zip(file_paths, general_prompts):\n",
    "    input_json = {\n",
    "        \"file_path\": file_path,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the speed of light?    =>    I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\n",
      "tell me about english teaching    =>    I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\n"
     ]
    }
   ],
   "source": [
    "irrelevant_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the speed of light?\",\n",
    "    \"tell me about english teaching\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]\n",
    "\n",
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "irrelevant_results = {}\n",
    "\n",
    "# # getting the answer of the prompts\n",
    "# try:\n",
    "for prompt in irrelevant_prompts:\n",
    "    input_json = {\n",
    "        \"file_path\": file_path,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    irrelevant_results[prompt]=output_json\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"test_results/irrelevant_prompts_results.json\", \"w\") as outputfile: \n",
    "    json.dump(irrelevant_results, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech file detected. Processing speech...\n",
      "Speech processing complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The main idea of this file is to provide information about long-term trading in the stock market. It explains that long-term trading involves buying shares of a company and holding onto them for an extended period, with the goal of benefiting from the company's growth over time and earning dividends. Long-term traders are often categorized as investors or position traders.\",\n",
       " {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'samplefiles/tts_test.mp3'\n",
    "messages = []\n",
    "prompt = None\n",
    "\n",
    "input_json = {\n",
    "    \"file_path\": file_path,\n",
    "    \"prompt\": None,\n",
    "    \"messages\": messages,\n",
    "    \"front_json\": input_filter.front_end_json_sample\n",
    "}\n",
    "\n",
    "output_json = main.main(input_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The founders of Microsoft are Bill Gates and Paul Allen. They established the company on April 4, 1975, with the goal of developing and selling software for personal computers. Bill Gates is particularly known for his role in shaping the company's vision and strategy, while Paul Allen played a significant role in technical aspects and product development.\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurf.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '74b3de375b964f73a6b7668fe459e26f'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Corporation was founded by Bill Gates and Paul Allen. Bill Gates, currently one of the world's wealthiest individuals, served as Microsoft's Chairman and CEO for many years before transitioning to a role as a technology advisor. Paul Allen was a prominent philanthropist and entrepreneur who co-founded Microsoft with Bill Gates, but he passed away in 2018.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '80ddd1ad72504f2fa226755d49491a61'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\deepeval\\__init__.py:42: UserWarning: You are using deepeval version 0.21.43, however version 0.21.45 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from UnitTest import unit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_test.unit_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
