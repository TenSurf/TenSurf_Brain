{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e0fa0c-f0de-45be-8f1c-cc2f038f5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71718ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pytz\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "import bisect\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from datetime import datetime , timedelta\n",
    "import math\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from datetime import timedelta, datetime\n",
    "from time import sleep\n",
    "import time\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS, ASYNCHRONOUS\n",
    "from influxdb_client import InfluxDBClient, Point, WriteOptions, WritePrecision\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd8de2",
   "metadata": {},
   "source": [
    "# Common functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aabcaa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon_data(ticker: str, start_datetime: pd.Timestamp = None, end_datetime: pd.Timestamp = None, timeframe: str = 'minute', api_key: str = None, data_type: str = \"realtime\") -> pd.DataFrame:\n",
    "    start_timestamp_ms = int(start_datetime.timestamp()) * 1000\n",
    "    end_timestamp_ms = int(end_datetime.timestamp()) * 1000\n",
    "    url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/{timeframe}/{start_timestamp_ms}/{end_timestamp_ms}?apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    function_response = response.json()\n",
    "    prices = [{'DateTime': datetime.fromtimestamp(result['t'] / 1000), 'open': result['o'], 'close': result['c'], 'high': result['h'], 'low': result['l'], 'volume': result['v']} for result in function_response['results']]\n",
    "    return pd.DataFrame(prices)\n",
    "\n",
    "def convert_datetime(dt):\n",
    "    if type(dt) == type(\"\"):\n",
    "        dt = datetime(dt)\n",
    "    us_timezone = pytz.timezone('US/Pacific')\n",
    "    local_time = dt.replace(tzinfo=us_timezone)\n",
    "    utc_time = local_time.astimezone(pytz.utc)\n",
    "    return utc_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "class InfluxClient:\n",
    "    def __init__(self, token, org, url, bucket):\n",
    "        self.token = token\n",
    "        self.org = org\n",
    "        self.url = url\n",
    "        self.bucket = bucket\n",
    "        self.client = InfluxDBClient(url=self.url, token=self.token, org=self.org, timeout=None)\n",
    "        self.receiver_email = 'tensurfllc@gmail.com'\n",
    "        self.last_error_time = 0\n",
    "        self.column_convertor = {'Candle_ClosePrice': 'close', 'Candle_HighPrice': 'high', 'BarPeriod': 'end_time',\n",
    "                                 'Candle_OpenPrice': 'open', 'Candle_LowPrice': 'low', 'VP': 'volume_profile',\n",
    "                                 'Candle_AskNumberOfTrades': 'ask_number', 'Candle_AskVolumeOfTrades': 'ask_volume',\n",
    "                                 'Candle_BidNumberOfTrades': 'bid_number', 'Candle_BidVolumeOfTrades': 'bid_volume',\n",
    "                                 'Candle_LastTradePrice': 'lastprice', 'Candle_NumberOfTrades': 'numtrades',\n",
    "                                 'Candle_VolumeofTrades': 'volume', 'VAP_AskVolumes': 'vap_askvolumes',\n",
    "                                 'VAP_BidVolumes': 'vap_bidvolumes', 'VAP_NumberOfTrades': 'vap_numberoftrades',\n",
    "                                 'VAP_TotalVolume': 'vap_totalvolume', 'VAP_Volumes': 'vap_volumes',\n",
    "                                 'VAP_Prices': 'vap_prices', \"LOB_SumBid\": 'sum_lob_bid', \"LOB_SumAsk\": 'sum_lob_ask',\n",
    "                                 \"LOB_SumBidTick\": 'sum_lob_bid_tick', \"LOB_SumAskTick\": 'sum_lob_ask_tick',\n",
    "                                 \"LOB_BidPrices\": 'lob_bid_price', \"LOB_BidVolumes\": 'lob_bid_volume',\n",
    "                                 \"LOB_AskPrices\": 'lob_ask_price', \"LOB_AskVolumes\": 'lob_ask_volume'}\n",
    "\n",
    "         #self.get_last_records = memory.cache(self.get_last_records)\n",
    "\n",
    "    def retrieve_db_df_between(self, symbol, start_date, end_date):\n",
    "        start_date = convert_datetime(start_date)\n",
    "        end_date = convert_datetime(end_date)\n",
    "\n",
    "        query = f'''from(bucket:\"{self.bucket}\") \n",
    "                |> range(start: time(v:{start_date}), stop: time(v: {end_date}))\n",
    "                |> filter(fn: (r) => r[\"_measurement\"] == \"{symbol}\" and\\\n",
    "                    r[\"timeframe\"] == \"1min\" and\\\n",
    "                    r[\"liq_threshold\"] == \"-1\")\n",
    "                |> pivot(rowKey:[\"_time\"], columnKey:[\"_field\"], valueColumn:\"_value\")\n",
    "                '''\n",
    "        return self.read_data(query)\n",
    "\n",
    "    def read_data(self, query):\n",
    "        try:\n",
    "            result_ = self.client.query_api().query(query=query)\n",
    "            records = []\n",
    "            for table in result_:\n",
    "                for record in table.records:\n",
    "                    records.append(record.values)\n",
    "\n",
    "            result = pd.DataFrame(records)\n",
    "            if isinstance(result, pd.DataFrame) and all(col in result.columns for col in\n",
    "                                                        ['_time', 'result', 'table', '_start', '_stop', '_measurement',\n",
    "                                                         'liq_threshold', 'timeframe']):\n",
    "                df = result.drop(columns={'_time', 'result', 'table', '_start', '_stop', '_measurement', 'liq_threshold',\n",
    "                             'timeframe'})\n",
    "                df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "                if 'BarPeriod' in df.columns:\n",
    "                    df['BarPeriod'] = pd.to_datetime(df['BarPeriod'])\n",
    "                self.client.close()\n",
    "                df = df.rename(columns={k: v for k, v in self.column_convertor.items() if k in df.columns})\n",
    "                return df\n",
    "            else:\n",
    "                print(query)\n",
    "                print('[Error] result output is not DataFrame')\n",
    "        except Exception as e:\n",
    "                #self.send_error_email(f'InfluxDB - Error reading data from InfluxDB', e)\n",
    "            print(f\"Error reading data from InfluxDB: {e}\\n Query is {query}\")\n",
    "\n",
    "def true_range(h,l,c):\n",
    "    high_low = h - l\n",
    "    high_close = np.abs(h-c)\n",
    "    low_close = np.abs(l-c)\n",
    "    return np.max([high_low, high_close, low_close])\n",
    "\n",
    "def get_session(date):\n",
    "    if date.hour >= 15 or date.hour < 6 or date.hour == 6 and date.minute < 30:\n",
    "        return 'overnight'\n",
    "    return 'RTH'\n",
    "\n",
    "def is_hammer(open, high, low, close, atr):\n",
    "    body_size = abs(close - open)\n",
    "    candle_size = high - low\n",
    "    upper_shadow = high - max(open, close)\n",
    "    lower_shadow = min(open, close) - low\n",
    "    if lower_shadow > atr and lower_shadow > 2 * body_size and (upper_shadow + body_size) < 0.33 * candle_size:\n",
    "        return 1\n",
    "    if upper_shadow > atr and upper_shadow > 2 * body_size and (lower_shadow + body_size) < 0.33 * candle_size:\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1934c1",
   "metadata": {},
   "source": [
    "# Zigzag class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ddacfc-df91-46ec-89af-09f658c86b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class zigzagClass:\n",
    "    def __init__(self, mode='mode1', reversal=.02, reversal_amount=10 ):\n",
    "        self.all_days = []\n",
    "        self.reversal = reversal\n",
    "        self.reversal_amount = reversal_amount\n",
    "        self.mode = mode\n",
    "        self.first_low = 0\n",
    "        self.first_high = 0\n",
    "        self.last_high, self.last_low = 0, 0\n",
    "        self.prev_low = 0\n",
    "        self.prev_high = 0\n",
    "        self.day7_index = 0\n",
    "        self.pivot_index = 0\n",
    "        self.bar_count_since_last_pivot = 0\n",
    "        self.pivot_points = []\n",
    "        self.recent_swing_info = {'price': 0, 'time': None, 'type': '', 'note': ''}\n",
    "        self.trend = ''\n",
    "        self.minimum_candles = 3\n",
    "\n",
    "    def update_pivots(self, data_dict, data_index, current_index):\n",
    "        new_leg = False\n",
    "        cur_high = data_dict['high'][current_index]\n",
    "        cur_low = data_dict['low'][current_index]\n",
    "        day = data_index[current_index].date()\n",
    "        if day not in self.all_days:\n",
    "            self.all_days.append(day)\n",
    "        self.bar_count_since_last_pivot += 1\n",
    "        if self.first_high == 0:\n",
    "            self.first_low = cur_low\n",
    "            self.first_high = cur_high\n",
    "            self.last_high, self.last_low = self.first_high, self.first_low\n",
    "            return\n",
    "        if self.trend == '':\n",
    "            if cur_low > self.first_high:\n",
    "                self.pivot_points = [{'session':get_session(data_index[current_index]), 'date':data_index[current_index], 'index':current_index, 'value': self.last_high, 'trend': 'down'}]\n",
    "                self.trend = 'up'\n",
    "                self.last_high = cur_high\n",
    "                self.pivot_index = current_index\n",
    "                self.bar_count_since_last_pivot = 0\n",
    "                self.low_of_current_up_trend = cur_low\n",
    "                return\n",
    "            elif cur_high < self.first_low:\n",
    "                self.pivot_points = [{'session':get_session(data_index[current_index]), 'date':data_index[current_index], 'index':current_index, 'value': self.last_low, 'trend': 'up'}]\n",
    "                self.trend = 'down'\n",
    "                self.last_low = cur_low\n",
    "                self.pivot_index = current_index\n",
    "                self.bar_count_since_last_pivot = 0\n",
    "                self.high_of_current_down_trend = cur_high\n",
    "                return\n",
    "        if self.trend == 'up':\n",
    "            reversal_price = self.last_high - (self.last_high * self.reversal / 100) if self.mode == 'mode1' else self.last_high - self.reversal_amount\n",
    "            if self.mode == 'mode2':\n",
    "                if cur_high >= self.last_high:\n",
    "                    self.last_high = cur_high\n",
    "                    self.pivot_index = current_index\n",
    "                elif cur_high < self.last_high:\n",
    "                    if self.last_high - cur_low > self.reversal_amount and self.bar_count_since_last_pivot >= 2:\n",
    "                        self.pivot_points.append({'session':get_session(data_index[self.pivot_index]), 'date':data_index[self.pivot_index],'index':self.pivot_index, 'value': self.last_high, 'trend': self.trend})\n",
    "                        new_leg = True\n",
    "                        self.trend = 'down'\n",
    "                        self.last_low = cur_low\n",
    "                        self.pivot_index = current_index\n",
    "                        self.bar_count_since_last_pivot = 0\n",
    "                        self.high_of_current_down_trend = cur_high\n",
    "                elif cur_low < self.low_of_current_up_trend:\n",
    "                    self.pivot_points.append({'session':get_session(data_index[self.pivot_index]), 'date':data_index[self.pivot_index],'index':self.pivot_index, 'value': self.last_high, 'trend': self.trend})\n",
    "                    new_leg = True\n",
    "                    self.trend = 'down'\n",
    "                    self.last_low = cur_low\n",
    "                    self.pivot_index = current_index\n",
    "                    self.bar_count_since_last_pivot = 0\n",
    "                    self.high_of_current_down_trend = cur_high\n",
    "                self.low_of_current_up_trend = min(self.low_of_current_up_trend, cur_low)\n",
    "            else:\n",
    "                if cur_high >= self.last_high:\n",
    "                    self.last_high = cur_high\n",
    "                    self.pivot_index = current_index\n",
    "                    self.bar_count_since_last_pivot = 0\n",
    "                ############################################################################################ Find Peak\n",
    "                if cur_low < reversal_price and self.bar_count_since_last_pivot >= self.minimum_candles:\n",
    "                    self.pivot_points.append({'session':get_session(data_index[self.pivot_index]), 'date':data_index[self.pivot_index],'index':self.pivot_index, 'value': self.last_high, 'trend': self.trend})\n",
    "                    new_leg = True\n",
    "                    self.trend = 'down'\n",
    "                    ind = self.minimum_candles - 1 - np.argmin(\n",
    "                        data_dict['low'][current_index - self.minimum_candles + 1: current_index + 1][::-1])\n",
    "                    self.pivot_index = current_index - self.minimum_candles + 1 + ind\n",
    "                    self.last_low = data_dict['low'][self.pivot_index]\n",
    "                    self.bar_count_since_last_pivot = 0\n",
    "        elif self.trend == 'down':\n",
    "            reversal_price = self.last_low + (self.last_low * self.reversal / 100) if self.mode == 'mode1' else self.last_low + self.reversal_amount\n",
    "            if self.mode == 'mode2':\n",
    "                if cur_low <= self.last_low:\n",
    "                    self.last_low = cur_low\n",
    "                    self.pivot_index = current_index\n",
    "                elif cur_low > self.last_low:\n",
    "                    if cur_high - self.last_low > self.reversal_amount and self.bar_count_since_last_pivot >= 2:\n",
    "                        self.pivot_points.append({'session':get_session(data_index[self.pivot_index]), 'date':data_index[self.pivot_index],'index':self.pivot_index, 'value': self.last_low, 'trend': self.trend})\n",
    "                        new_leg = True\n",
    "                        self.trend = 'up'\n",
    "                        self.last_high = cur_high\n",
    "                        self.pivot_index = current_index\n",
    "                        self.bar_count_since_last_pivot = 0\n",
    "                        self.low_of_current_up_trend = cur_low\n",
    "                elif cur_high > self.high_of_current_down_trend:\n",
    "                    self.pivot_points.append({'session':get_session(data_index[self.pivot_index]), 'date':data_index[self.pivot_index],'index':self.pivot_index, 'value': self.last_low, 'trend': self.trend})\n",
    "                    new_leg = True\n",
    "                    self.trend = 'up'\n",
    "                    self.last_high = cur_high\n",
    "                    self.pivot_index = current_index\n",
    "                    self.bar_count_since_last_pivot = 0\n",
    "                    self.low_of_current_up_trend = cur_low\n",
    "                self.high_of_current_down_trend = max(self.high_of_current_down_trend, cur_high)\n",
    "            else:\n",
    "                if cur_low <= self.last_low:\n",
    "                    self.last_low = cur_low\n",
    "                    self.pivot_index = current_index\n",
    "                    self.bar_count_since_last_pivot = 0\n",
    "                ############################################################################################ Find Valley\n",
    "                if cur_high > reversal_price and self.bar_count_since_last_pivot >= self.minimum_candles:\n",
    "                    self.pivot_points.append({'session':get_session(data_index[self.pivot_index]), 'date':data_index[self.pivot_index],'index':self.pivot_index, 'value': self.last_low, 'trend': self.trend})\n",
    "                    new_leg = True\n",
    "                    self.trend = 'up'\n",
    "                    ind = self.minimum_candles - 1 - np.argmax(\n",
    "                        data_dict['high'][current_index - self.minimum_candles + 1: current_index + 1][::-1])\n",
    "                    self.pivot_index = current_index - self.minimum_candles + 1 + ind\n",
    "                    self.last_high = data_dict['high'][self.pivot_index]\n",
    "                    self.bar_count_since_last_pivot = 0\n",
    "        if new_leg:\n",
    "            swing_type = ''\n",
    "            p_value = self.pivot_points[-1]['value']\n",
    "            if len(self.pivot_points) >= 3:\n",
    "                if self.pivot_points[-1]['trend'] == 'up':\n",
    "                    if p_value >= self.pivot_points[-3]['value']:\n",
    "                        swing_type = 'HH'\n",
    "                    else:\n",
    "                        swing_type = 'LH'\n",
    "                elif p_value >= self.pivot_points[-3]['value']:\n",
    "                    swing_type = 'HL'\n",
    "                else:\n",
    "                    swing_type = 'LL'\n",
    "            self.recent_swing_info = {'price': p_value,\n",
    "                                          'time': self.pivot_points[-1]['date'], 'type': swing_type, 'note': ''}\n",
    "        return new_leg\n",
    "\n",
    "    def get_mean_leg(self, current_date):\n",
    "        if len(self.pivot_points) == 0:\n",
    "            return 0\n",
    "        while self.pivot_points[-1]['date'] - self.pivot_points[self.day7_index]['date'] > timedelta(days=7):\n",
    "            self.day7_index += 1\n",
    "        current_session = get_session(current_date)\n",
    "        legs = [abs(self.pivot_points[i]['value'] - self.pivot_points[i + 1]['value']) for i in range(self.day7_index, len(self.pivot_points) - 1) if self.pivot_points[i+1]['session'] == current_session]\n",
    "        mean_leg = np.mean(legs)\n",
    "        # print(self.pivot_dates, mean_leg, '-----------------------')\n",
    "        return mean_leg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2fd715-355d-4db7-9df5-b26b799c7c2d",
   "metadata": {},
   "source": [
    "# Supprt/Resistance detection functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe735de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRDetector:\n",
    "    def __init__(self, pre_data, timeframe, params_, detection_method_):\n",
    "        # Note: pre_data is time indexed dataframe\n",
    "        self.detection_method = detection_method_\n",
    "        self.timeframe = timeframe\n",
    "        self.params = params_\n",
    "        self.timeframe2 = re.sub(r'\\d+', '1', timeframe)\n",
    "        self.merge_percent = self.params[self.detection_method]['merge_percent'][self.timeframe2]\n",
    "        self.closeness = self.params[self.detection_method]['merge_percent'][self.timeframe2]\n",
    "        self.score_method = self.params[self.detection_method]['score']\n",
    "        self.window_size_score = self.params[self.detection_method]['window_size'][self.timeframe2]\n",
    "        self.last_date = None\n",
    "        self.recent_candle = {'time': None, 'open': 0, 'high': 0, 'low': 0, 'close': 0}\n",
    "        self.potential_support_levels = []\n",
    "        self.potential_resistance_levels = []\n",
    "        self.new_potential_level = False\n",
    "        self.remove_level = False\n",
    "        self.recent_zones = []\n",
    "        self.lines = {}\n",
    "        self.all_levels = []\n",
    "        self.last_support_index = 0\n",
    "        self.last_resistance_index = 0\n",
    "        self.distance_max_threshold = 5\n",
    "        self.current_round_date = None\n",
    "        self.current_date = None\n",
    "        self.resample(pre_data, self.timeframe)\n",
    "\n",
    "    def resample(self, data: pd.DataFrame, timeframe):\n",
    "        if timeframe is None:\n",
    "            return data\n",
    "        tmp = data.resample(timeframe).agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last'})\n",
    "        tmp = tmp.dropna(subset=['open'])\n",
    "        tmp['tr'] = np.maximum.reduce([tmp['high'] - tmp['low'], np.abs(tmp['high'] - tmp['close']), np.abs(tmp['low'] - tmp['close'])])\n",
    "        tmp['atr'] = tmp['tr'].rolling(14).mean()\n",
    "        tmp = tmp.iloc[14:]\n",
    "        self.data = tmp.to_dict(orient='list')\n",
    "        self.data['time'] = tmp.index.tolist()\n",
    "\n",
    "    def get_levels(self):\n",
    "        for i in range(len(self.data['time'])):\n",
    "            self.current_date = self.data['time'][i]\n",
    "            self.atr = self.data['atr'][i]\n",
    "            self.check_cross_line(i)\n",
    "            self.update_potential_levels(i)\n",
    "            self.score_lines(i)\n",
    "\n",
    "    def get_distance(self):\n",
    "        return self.merge_percent * self.atr\n",
    "\n",
    "    def check_cross_line(self, index):\n",
    "        close = self.data['close'][index]\n",
    "        high = self.data['high'][index]\n",
    "        low = self.data['low'][index]\n",
    "\n",
    "        endtime = self.data['time'][index]\n",
    "        max_cross = self.params[self.detection_method]['max_cross']\n",
    "        removed_levels = []\n",
    "        self.remove_level = False\n",
    "        for level in self.lines.keys():\n",
    "            if high >= level and not self.lines[level]['isSupport']:\n",
    "                self.lines[level]['cross'] += 1\n",
    "                self.lines[level]['isSupport'] = True\n",
    "                if self.lines[level]['cross'] >= max_cross:\n",
    "                    self.lines[level][\"endTime\"] = endtime\n",
    "                    removed_levels.append(level)\n",
    "                    if level in self.all_levels:\n",
    "                        self.all_levels.remove(level)\n",
    "            if low <= level and self.lines[level]['isSupport']:\n",
    "                self.lines[level]['cross'] += 1\n",
    "                self.lines[level]['isSupport'] = False\n",
    "                if self.lines[level]['cross'] >= max_cross:\n",
    "                    self.lines[level][\"endTime\"] = endtime\n",
    "                    if level in self.all_levels:\n",
    "                        self.all_levels.remove(level)\n",
    "        if len(removed_levels) > 0: self.remove_level = True\n",
    "        self.lines = {key: value for key, value in self.lines.items() if key not in removed_levels}\n",
    "\n",
    "    def update_potential_levels(self, current_index):\n",
    "        self.new_potential_level = False\n",
    "        timeframe = self.timeframe\n",
    "\n",
    "\n",
    "        window_size = self.params[self.detection_method]['window_size'][self.timeframe2]\n",
    "        if current_index < 2 * window_size + 1:\n",
    "            return\n",
    "        high_data = np.array(self.data['high'][self.last_resistance_index:current_index+1])\n",
    "        low_data = np.array(self.data['low'][self.last_support_index:current_index+1])\n",
    "        high_datalen = len(high_data)\n",
    "        low_datalen = len(low_data)\n",
    "        local_maxima = argrelextrema(high_data, lambda x, y: x >= y, order=window_size)[0]\n",
    "        while len(local_maxima) > 0 and local_maxima[0] < window_size: local_maxima = local_maxima[1:]\n",
    "        while len(local_maxima) > 0 and local_maxima[-1] >= high_datalen - window_size: local_maxima = local_maxima[:-1]\n",
    "        local_minima = argrelextrema(low_data, lambda x, y: x <= y, order=window_size)[0]\n",
    "        while len(local_minima) > 0 and local_minima[0] < window_size: local_minima = local_minima[1:]\n",
    "        while len(local_minima) > 0 and local_minima[-1] >= low_datalen - window_size: local_minima = local_minima[:-1]\n",
    "        potential_resistance_levels = []\n",
    "        potential_support_levels = []\n",
    "        last_index = self.last_resistance_index\n",
    "        if len(local_maxima) > 0:\n",
    "            potential_resistance_levels = list(high_data[local_maxima])\n",
    "            self.last_resistance_index = max(local_maxima + last_index)\n",
    "            for i, index in enumerate(local_maxima + last_index):\n",
    "                level = potential_resistance_levels[i]\n",
    "                self.new_potential_level = True\n",
    "                if level in self.lines.keys():\n",
    "                    self.lines[level]['cross'] = 0\n",
    "                else:\n",
    "                    bisect.insort(self.all_levels, level)\n",
    "                    self.lines[level] = {}\n",
    "                    self.lines[level]['time'] = self.data['time'][index]\n",
    "                    self.lines[level]['detect_time'] = self.current_date\n",
    "                    self.lines[level]['price'] = level\n",
    "                    self.lines[level]['isSupport'] = False\n",
    "                    self.lines[level]['endTime'] = None\n",
    "                    self.lines[level]['cross'] = 0\n",
    "                    self.lines[level]['importance'] = 1\n",
    "        last_index = self.last_support_index\n",
    "        if len(local_minima) > 0:\n",
    "            potential_support_levels = list(low_data[local_minima])\n",
    "            self.last_support_index = max(local_minima + last_index)\n",
    "            for i, index in enumerate(local_minima + last_index):\n",
    "                self.new_potential_level = True\n",
    "                level = potential_support_levels[i]\n",
    "                if level in self.lines.keys():\n",
    "                    self.lines[level]['importance'] += 2\n",
    "                else:\n",
    "                    bisect.insort(self.all_levels, level)\n",
    "                    self.lines[level] = {}\n",
    "                    self.lines[level]['time'] = self.data['time'][index]\n",
    "                    self.lines[level]['detect_time'] = self.current_date\n",
    "                    self.lines[level]['price'] = level\n",
    "                    self.lines[level]['isSupport'] = True\n",
    "                    self.lines[level]['endTime'] = None\n",
    "                    self.lines[level]['cross'] = 0\n",
    "                    self.lines[level]['importance'] = 1\n",
    "        self.potential_support_levels += potential_support_levels\n",
    "        self.potential_resistance_levels += potential_resistance_levels\n",
    "\n",
    "    def get_zones(self):\n",
    "        potential_level_prices = np.array(list(self.lines.keys()))\n",
    "        if self.new_potential_level:\n",
    "            levels = self.aggregate_prices_to_levels(potential_level_prices, self.get_distance())\n",
    "            self.recent_zones = levels\n",
    "            self.concat_score()\n",
    "\n",
    "    def concat_score(self):\n",
    "        \"\"\"score each zone using max level importance and update importance by max importance in zone\"\"\"\n",
    "        zones = self.recent_zones\n",
    "        if zones is not None:\n",
    "            for i, level in enumerate(zones):\n",
    "                levels = [x for x in self.lines.keys() if level['minprice'] <= x <= level['maxprice']]\n",
    "                importances = [self.lines[x]['importance'] for x in levels]\n",
    "                times = [self.lines[x]['time'] for x in levels]\n",
    "                zone_score = np.sum(importances)\n",
    "                zones[i]['importance'] = zone_score\n",
    "                zones[i]['time'] = np.min(times)\n",
    "\n",
    "    def score_lines(self, current_index):\n",
    "        open_, high_, low_, close_ = [self.data[col][current_index] for col in ['open', 'high', 'low', 'close']]\n",
    "        if self.score_method == 'candle':\n",
    "            self.score_line_candle(open_, high_, low_, close_)\n",
    "        elif self.score_method == 'swing':\n",
    "            self.score_line_swing(current_index, self.window_size_score)  # 5 is good\n",
    "        elif self.score_method == 'power':\n",
    "            self.score_line_power(current_index, self.window_size_score)  # better be same as window_size\n",
    "\n",
    "    def score_line_power(self, current_index, window_size):\n",
    "        if not self.new_potential_level:\n",
    "            return\n",
    "        if self.last_resistance_index == current_index - window_size:\n",
    "            high = self.data['high'][self.last_resistance_index]\n",
    "            window_low = min(self.data['low'][self.last_resistance_index:current_index+1])\n",
    "            distance = round((high - window_low) / self.atr, 1)\n",
    "            high_minprice = high - (self.atr * self.closeness)\n",
    "            high_maxprice = high + (self.atr * self.closeness)\n",
    "            low_index = bisect.bisect_left(self.all_levels, high_minprice)\n",
    "            high_index = bisect.bisect_right(self.all_levels, high_maxprice)\n",
    "            for level in self.all_levels[low_index:high_index]:\n",
    "                self.lines[level]['importance'] += distance\n",
    "                self.lines[level]['importance'] = round(self.lines[level]['importance'], 1)\n",
    "\n",
    "        if self.last_support_index == current_index - window_size:\n",
    "            low = self.data['low'][self.last_support_index]\n",
    "            window_high = max(self.data['high'][self.last_support_index:current_index+1])\n",
    "            distance = round((window_high - low) / self.atr, 1)\n",
    "            low_minprice = low - (self.atr * self.closeness)\n",
    "            low_maxprice = low + (self.atr * self.closeness)\n",
    "            low_index = bisect.bisect_left(self.all_levels, low_minprice)\n",
    "            high_index = bisect.bisect_right(self.all_levels, low_maxprice)\n",
    "            for level in self.all_levels[low_index:high_index]:\n",
    "                self.lines[level]['importance'] += distance\n",
    "                self.lines[level]['importance'] = round(self.lines[level]['importance'], 1)\n",
    "\n",
    "    def score_line_candle(self, open, high, low, close):\n",
    "        high_minprice = high - (self.atr * self.closeness)\n",
    "        high_maxprice = high + (self.atr * self.closeness)\n",
    "        low_minprice = low - (self.atr * self.closeness)\n",
    "        low_maxprice = low + (self.atr * self.closeness)\n",
    "        for level in self.lines.keys():\n",
    "            if (level >= close and (high_minprice <= level <= high_maxprice) or\n",
    "                    level <= close and (low_minprice <= level <= low_maxprice)):\n",
    "                self.lines[level][\"importance\"] += 1\n",
    "\n",
    "    def score_line_swing(self, current_index, window_size):\n",
    "        if not self.new_potential_level:\n",
    "            return\n",
    "        if self.last_resistance_index == current_index - window_size:\n",
    "            high = self.data['high'][self.last_resistance_index]\n",
    "            high_minprice = high - (self.atr * self.closeness)\n",
    "            high_maxprice = high + (self.atr * self.closeness)\n",
    "            low_index = bisect.bisect_left(self.all_levels, high_minprice)\n",
    "            high_index = bisect.bisect_right(self.all_levels, high_maxprice)\n",
    "            for level in self.all_levels[low_index:high_index]:\n",
    "                self.lines[level]['importance'] += 1\n",
    "\n",
    "        if self.last_support_index == current_index - window_size:\n",
    "            low = self.data['low'][self.last_support_index]\n",
    "            low_minprice = low - (self.atr * self.closeness)\n",
    "            low_maxprice = low + (self.atr * self.closeness)\n",
    "            low_index = bisect.bisect_left(self.all_levels, low_minprice)\n",
    "            high_index = bisect.bisect_right(self.all_levels, low_maxprice)\n",
    "            for level in self.all_levels[low_index:high_index]:\n",
    "                self.lines[level]['importance'] += 1\n",
    "\n",
    "    def aggregate_prices_to_levels(self, prices, distance):\n",
    "        clustering = AgglomerativeClustering(distance_threshold=distance, n_clusters=None)\n",
    "        try:\n",
    "            clustering.fit(prices.reshape(-1, 1))\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(data=prices, columns=('price',))\n",
    "        df['cluster'] = clustering.labels_\n",
    "        df['peak_count'] = 1\n",
    "\n",
    "        grouped = df.groupby('cluster').agg(\n",
    "            {\n",
    "                'price': \"min\",\n",
    "                'peak_count': 'sum'\n",
    "            }\n",
    "        ).reset_index()\n",
    "\n",
    "        grouped2 = df.groupby('cluster').agg(\n",
    "            {\n",
    "                'price': \"max\",\n",
    "                'peak_count': 'sum'\n",
    "            }\n",
    "        ).reset_index()\n",
    "        grouped3 = df.groupby('cluster').agg(\n",
    "            {\n",
    "                'price': \"mean\",\n",
    "                'peak_count': 'sum'\n",
    "            }\n",
    "        ).reset_index()\n",
    "\n",
    "        grouped['meanprice'] = grouped3[\"price\"]\n",
    "        grouped['maxprice'] = grouped2[\"price\"]\n",
    "        grouped = grouped.rename(columns={\"price\": 'minprice'})\n",
    "        return grouped.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f63c9f",
   "metadata": {},
   "source": [
    "# Trend detection functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f7a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivots(data_dict, data_index):\n",
    "    zigzag = zigzagClass(mode='mode1', reversal=.02)\n",
    "    for current_index in range(len(data_dict['close'])):\n",
    "        zigzag.update_pivots(data_dict, data_index,current_index)\n",
    "    return [zigzag.pivot_points[x]['index'] for x in range(len(zigzag.pivot_points))], [zigzag.pivot_points[x]['value'] for x in range(len(zigzag.pivot_points))]\n",
    "\n",
    "def make_new_pivots(first_pivot, interval, pivot_values, pivot_indices):\n",
    "    current_pivot = first_pivot\n",
    "    new_pivot_values = [pivot_values[0]]\n",
    "    new_pivot_indices = [pivot_indices[0]]\n",
    "    i = 0\n",
    "    while i < len(pivot_indices) - 1:\n",
    "        if current_pivot == 1:\n",
    "            if i + 3 >= len(pivot_indices):\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            elif pivot_values[i + 1] < pivot_values[i + 3]:\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            elif (pivot_values[i + 2] - pivot_values[i + 1]) > (pivot_values[i] - pivot_values[i + 1]):\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            else:\n",
    "                if pivot_values[i + 2] > pivot_values[i]:\n",
    "                    new_pivot_values[-1] = pivot_values[i + 2]\n",
    "                    # new_pivot_indices[-1] = pivot_indices[i + 2]\n",
    "                new_pivot_values.append(pivot_values[i + 3])\n",
    "                new_pivot_indices.append(pivot_indices[i + 3])\n",
    "                i += 3\n",
    "        else:\n",
    "            if i + 3 >= len(pivot_indices):\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            elif pivot_values[i + 1] > pivot_values[i + 3]:\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            elif (pivot_values[i + 1] - pivot_values[i + 2]) > interval * .3 and \\\n",
    "                    pivot_values[i + 1] - pivot_values[i + 2] > (pivot_values[i + 1] - pivot_values[i]) * .7:\n",
    "                new_pivot_values.append(pivot_values[i + 1])\n",
    "                new_pivot_indices.append(pivot_indices[i + 1])\n",
    "                i += 1\n",
    "            else:\n",
    "                if pivot_values[i + 2] < pivot_values[i]:\n",
    "                    new_pivot_values[-1] = pivot_values[i + 2]\n",
    "                    # new_pivot_indices[-1] = pivot_indices[i + 2]\n",
    "                new_pivot_values.append(pivot_values[i + 3])\n",
    "                new_pivot_indices.append(pivot_indices[i + 3])\n",
    "                i += 3\n",
    "        current_pivot = -current_pivot\n",
    "    return new_pivot_indices, new_pivot_values\n",
    "\n",
    "def find_trend(data_dict, data_index, start_index, end_index):\n",
    "    data = {x: data_dict[x][start_index:end_index] for x in ['open', 'high', 'low', 'close', 'zigzag', 'zigzag_text']}\n",
    "    data['DateTime'] = data_index[start_index:end_index]\n",
    "    data_len = len(data['close'])\n",
    "    close_data = data['close']\n",
    "    datetimes = data['DateTime']\n",
    "    window_size = 5\n",
    "    # datetimes = datetimes[window_size -1:]\n",
    "    pivot_indices, pivot_values = get_pivots(data, datetimes)\n",
    "    if len(pivot_indices) < 2:\n",
    "        return 0\n",
    "    sum_red_bars, sum_green_bars = 0, 0\n",
    "    weighted_sum_red_bars, weighted_sum_green_bars = 0, 0\n",
    "    sum_up_pct, sum_down_pct = 0, 0\n",
    "    sum_up, sum_down = 0, 0\n",
    "    highs = 0\n",
    "    lows = 0\n",
    "    higher_highs = 0\n",
    "    lower_lows = 0\n",
    "    last_high = 0\n",
    "    last_low = 0\n",
    "    if pivot_values[1] > pivot_values[0]:\n",
    "        last_low = pivot_values[0]\n",
    "    else:\n",
    "        last_high = pivot_values[0]\n",
    "    first_pivot = 0\n",
    "    if len(pivot_indices) > 2:\n",
    "        if pivot_values[1] > pivot_values[2]:\n",
    "            first_pivot = -1\n",
    "        else:\n",
    "            first_pivot = 1\n",
    "    elif len(pivot_indices) == 2:\n",
    "        if pivot_values[1] > pivot_values[0]:\n",
    "            first_pivot = -1\n",
    "        else:\n",
    "            first_pivot = 1\n",
    "    if first_pivot == 1 and close_data[0] > pivot_values[0]:\n",
    "        pivot_values[0] = close_data[0]\n",
    "        pivot_indices[0] = 0\n",
    "    if first_pivot == -1 and close_data[0] < pivot_values[0]:\n",
    "        pivot_values[0] = close_data[0]\n",
    "        pivot_indices[0] = 0\n",
    "    min_price = np.min(close_data)\n",
    "    max_price = np.max(close_data)\n",
    "    interval = max_price - min_price\n",
    "    while True:\n",
    "        new_pivot_indices, new_pivot_values = make_new_pivots(first_pivot, interval, pivot_values, pivot_indices)\n",
    "        if len(new_pivot_values) == len(pivot_values):\n",
    "            break\n",
    "        pivot_indices, pivot_values = new_pivot_indices, new_pivot_values\n",
    "    high_pct = 0\n",
    "    low_pct = 0\n",
    "    first_price = data['open'][0]\n",
    "    last_price = close_data[-1]\n",
    "    overall_change = ((last_price - first_price) / first_price) * 100\n",
    "    num_of_legs = len(pivot_values) - 1\n",
    "    num_of_pairs = num_of_legs // 2\n",
    "    if num_of_pairs <= 0:\n",
    "        if overall_change > 0:\n",
    "            return 3\n",
    "        else:\n",
    "            return -3\n",
    "    high_count = 0\n",
    "    high_sum = 0\n",
    "    low_count = 0\n",
    "    low_sum = 0\n",
    "    high_len = 0\n",
    "    low_len = 0\n",
    "    low_legs = []\n",
    "    high_legs = []\n",
    "    for i in range(1, len(pivot_indices)):\n",
    "        change = pivot_values[i] - pivot_values[i - 1]\n",
    "        if change > 0:\n",
    "            high_count += 1\n",
    "            high_sum += change\n",
    "            high_legs.append(change)\n",
    "            high_len += pivot_indices[i] - pivot_indices[i - 1]\n",
    "        else:\n",
    "            low_count += 1\n",
    "            low_sum += abs(change)\n",
    "            low_legs.append(abs(change))\n",
    "            low_len += pivot_indices[i] - pivot_indices[i - 1]\n",
    "        pct_change = change / pivot_values[i - 1] * 100\n",
    "        if pct_change > 0:\n",
    "            if last_high == 0:\n",
    "                last_high = pivot_values[i]\n",
    "            else:\n",
    "                if pivot_values[i] > last_high:\n",
    "                    highs += 1\n",
    "                    higher_highs += 1\n",
    "                    high_pct += abs(pivot_values[i] - last_high) / last_high * 100\n",
    "                else:\n",
    "                    lows += 1\n",
    "                    low_pct += abs(pivot_values[i] - last_high) / last_high * 100\n",
    "                last_high = pivot_values[i]\n",
    "            sum_green_bars += pivot_indices[i] - pivot_indices[i - 1]\n",
    "            weighted_sum_green_bars += (pivot_indices[i] - pivot_indices[i - 1]) * pct_change\n",
    "            sum_up_pct += pct_change\n",
    "            sum_up += 1\n",
    "        elif pct_change < 0:\n",
    "            if last_low == 0:\n",
    "                last_low = pivot_values[i]\n",
    "            else:\n",
    "                if pivot_values[i] > last_low:\n",
    "                    highs += 1\n",
    "                    high_pct += abs(pivot_values[i] - last_low) / last_low * 100\n",
    "                else:\n",
    "                    lows += 1\n",
    "                    lower_lows += 1\n",
    "                    low_pct += abs(pivot_values[i] - last_low) / last_low * 100\n",
    "                last_low = pivot_values[i]\n",
    "            sum_red_bars += pivot_indices[i] - pivot_indices[i - 1]\n",
    "            weighted_sum_red_bars += (pivot_indices[i] - pivot_indices[i - 1]) * pct_change\n",
    "            sum_down_pct += pct_change\n",
    "            sum_down += 1\n",
    "    diff_sum_pct = sum_up_pct + sum_down_pct\n",
    "    # Calculating the percent changes\n",
    "    if high_sum >= 4 * low_sum:\n",
    "        return 3\n",
    "    if low_sum >= 4 * high_sum:\n",
    "        return -3\n",
    "    max_increase = ((max_price - first_price) / first_price) * 100\n",
    "    min_decrease = ((first_price - min_price) / first_price) * 100\n",
    "    bullish_retracement = ((max_price - last_price) / max_price) * 100\n",
    "    bearish_retracement = ((last_price - min_price) / min_price) * 100\n",
    "    mean_price = np.mean(close_data)\n",
    "    up_mean = mean_price > (np.max(close_data) + np.min(close_data)) / 2\n",
    "    down_mean = mean_price < (np.max(close_data) + np.min(close_data)) / 2\n",
    "    pivot_dist = [(pivot_values[i] - pivot_values[i - 1]) for i in range(1, len(pivot_values))]\n",
    "    max_leg = np.max(pivot_dist)\n",
    "    min_leg = np.min(pivot_dist)\n",
    "    if overall_change > 0 and last_price > (\n",
    "            first_price + max_price) * .4995 and first_price - min_price < last_price - first_price:\n",
    "        if last_price > (first_price + max_price) * .5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "        if max_leg * .5 < abs(min_leg):\n",
    "            result = -1\n",
    "        if max_leg * .75 < abs(min_leg):\n",
    "            return 0\n",
    "        # if up_mean:\n",
    "        if high_pct > low_pct:\n",
    "            if highs >= 1.2 * lows or high_pct > 1.2 * low_pct:\n",
    "                return (result + 2)\n",
    "            else:\n",
    "                return (result + 1)\n",
    "        elif highs > lows:\n",
    "            return (result + 1)\n",
    "        if bullish_retracement < .5 * max_increase:\n",
    "            return result\n",
    "        return 0\n",
    "    elif overall_change < 0 and last_price <= (\n",
    "            first_price + min_price) * .5005 and max_price - first_price < first_price - last_price:\n",
    "        result = -1\n",
    "        if last_price <= (first_price + min_price) * .5:\n",
    "            result = -1\n",
    "        else:\n",
    "            result = 0\n",
    "        if abs(min_leg) * .5 < max_leg:\n",
    "            result = 1\n",
    "        if abs(min_leg) * .75 < max_leg:\n",
    "            return 0\n",
    "        # if down_mean:\n",
    "        if high_pct < low_pct:\n",
    "            if lows >= 1.2 * highs or 1.2 * high_pct < low_pct:\n",
    "                return result - 2\n",
    "            else:\n",
    "                return result - 1\n",
    "        elif highs < lows:\n",
    "            return result - 1\n",
    "        if bearish_retracement < .5 * min_decrease:\n",
    "            return result\n",
    "        return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f661559d",
   "metadata": {},
   "source": [
    "# Function call class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73af8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "\t\"ES\": {\n",
    "        \"point_value\": 50,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"NQ\": {\n",
    "        \"point_value\": 20,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"RT\": {\n",
    "        \"point_value\": 50,\n",
    "        \"tick_size\": 0.1\n",
    "    },\n",
    "    \"YM\": {\n",
    "        \"point_value\": 5,\n",
    "        \"tick_size\": 1\n",
    "    },\n",
    "\t\"MES\": {\n",
    "        \"point_value\": 5,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"MNQ\": {\n",
    "        \"point_value\": 2,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"CL\": {\n",
    "        \"point_value\": 1000,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"MCL\": {\n",
    "        \"point_value\": 100,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"GC\": {\n",
    "        \"point_value\": 1000,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"MGC\": {\n",
    "        \"point_value\": 10,\n",
    "        \"tick_size\": 0.1\n",
    "    },\n",
    "    \"NG\": {\n",
    "        \"point_value\": 10000,\n",
    "        \"tick_size\": 0.001\n",
    "    },\n",
    "    \"M2K\": {\n",
    "        \"point_value\": 5,\n",
    "        \"tick_size\": 0.1\n",
    "    },\n",
    "    \"ZB\": {\n",
    "        \"point_value\": 31.25,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"ZC\": {\n",
    "        \"point_value\": 25,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"ZM\": {\n",
    "        \"point_value\": 100,\n",
    "        \"tick_size\": 0.1\n",
    "    },\n",
    "    \"ZL\": {\n",
    "        \"point_value\": 600,\n",
    "        \"tick_size\": 0.01\n",
    "    },\n",
    "    \"ZS\": {\n",
    "        \"point_value\": 50,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"ZW\": {\n",
    "        \"point_value\": 50,\n",
    "        \"tick_size\": 0.25\n",
    "    },\n",
    "    \"HG\": {\n",
    "        \"point_value\": 25000,\n",
    "        \"tick_size\": 0.005\n",
    "    },\n",
    "    \"MHG\": {\n",
    "        \"point_value\": 2500,\n",
    "        \"tick_size\": 0.005\n",
    "    },\n",
    "    \"HE\": {\n",
    "        \"point_value\": 400,\n",
    "        \"tick_size\": 0.025\n",
    "    },\n",
    "    \"LE\": {\n",
    "        \"point_value\": 400,\n",
    "        \"tick_size\": 0.025\n",
    "    },\n",
    "    \"SI\": {\n",
    "        \"point_value\": 5000,\n",
    "        \"tick_size\": 0.005\n",
    "    },\n",
    "    \"SIL\": {\n",
    "        \"point_value\": 1000,\n",
    "        \"tick_size\": 0.005\n",
    "    },\n",
    "    \"MYM\": {\n",
    "        \"point_value\": 0.5,\n",
    "        \"tick_size\": 1\n",
    "    },\n",
    "    \"6A\": {\n",
    "        \"point_value\": 125000,\n",
    "        \"tick_size\": 5e-05\n",
    "    },\n",
    "    \"6B\": {\n",
    "        \"point_value\": 62500,\n",
    "        \"tick_size\": 0.0001\n",
    "    },\n",
    "    \"6C\": {\n",
    "        \"point_value\": 100000,\n",
    "        \"tick_size\": 5e-05\n",
    "    },\n",
    "    \"6E\": {\n",
    "        \"point_value\": 125000,\n",
    "        \"tick_size\": 5e-05\n",
    "    },\n",
    "    \"6J\": {\n",
    "        \"point_value\": 125000,\n",
    "        \"tick_size\": 5e-05\n",
    "    }\n",
    "}\n",
    "class FunctionCalls:\n",
    "    def __init__(self):\n",
    "        url = 'http://localhost:8086'\n",
    "        token = 'WrSMwFo5b-ngd_gMqp1ZjGijae9QtQRKlNXd9U_8ExvcY0oVjQjZ7-dtmruJX_joU_pMzH72YUibcOX7XrvbBw=='\n",
    "        org = 'TenSurf'\n",
    "        self.bronze_client = InfluxClient(token, org, url, 'bronze')\n",
    "        self.url = url\n",
    "        self.token = token\n",
    "        self.org = org\n",
    "\n",
    "    def get_data(self, symbol, start_datetime, end_datetime):\n",
    "        if symbol in ['ES', 'NQ', 'GC', 'CL', 'YM', 'RTY']:\n",
    "            df = self.bronze_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        else:\n",
    "            polygon_api_key = \"6lpCMsrDOzmm6PPpSkci73RfUvEeU9y_\"\n",
    "            df = get_polygon_data(ticker='AAPL', start_datetime=start_datetime, end_datetime=end_datetime, timeframe='minute',\n",
    "                                                     data_type='historical', api_key=polygon_api_key)\n",
    "        return df\n",
    "    \n",
    "    def detect_trend(self, parameters):\n",
    "        # trends range are in [-3,3]\n",
    "        # -3 represents a strong downtrend, -2: moderate downtrend, -1: weak downtrend, 0: neutral,\n",
    "        # 1: weak uptrend, 2: moderate uptrend, and 3: strong uptrend.\n",
    "        symbol = parameters[\"symbol\"]\n",
    "        start_datetime = parameters[\"start_datetime\"]\n",
    "        end_datetime = parameters[\"end_datetime\"]\n",
    "        if end_datetime is None:\n",
    "            end_datetime = datetime.now()\n",
    "        if start_datetime is None:\n",
    "            start_datetime = end_datetime - timedelta(days=7)\n",
    "        if isinstance(start_datetime, str):\n",
    "            start_datetime = pd.to_datetime(start_datetime)\n",
    "        if isinstance(end_datetime, str):\n",
    "            end_datetime = pd.to_datetime(end_datetime)\n",
    "        df = self.get_data(symbol, start_datetime, end_datetime)\n",
    "        if df is None or len(df) == 0:\n",
    "            print('There is no data for this period of time...')\n",
    "            return 0\n",
    "        else:\n",
    "            data_dict = df.to_dict(orient='list')\n",
    "            data_index = data_dict['DateTime']\n",
    "            return find_trend(data_dict, data_index, 0, len(data_index) - 1)\n",
    "\n",
    "    def calculate_sr(self, parameters):\n",
    "        symbol = parameters[\"symbol\"]\n",
    "        timeframe = parameters[\"timeframe\"]\n",
    "        lookback_days = int(parameters[\"lookback_days\"].split(\" \")[0])\n",
    "        end_datetime = datetime.now()\n",
    "        start_datetime = end_datetime - timedelta(days=lookback_days)\n",
    "        df = self.get_data(symbol, start_datetime, end_datetime)\n",
    "        if df is None or len(df) == 0:\n",
    "            print('There is no data for this period of time...')\n",
    "            return 0\n",
    "        df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "        df = df.set_index('DateTime')\n",
    "        params = {'agglomerative': {'window_size': {'1h': 2, '1d': 2, '1w': 2, '1min': 5}, 'use_maxima': True,\n",
    "                                    'merge_percent': {'1h': .5, '1d': .5, '1w': .25, '1min': .75}, 'max_cross': 2,\n",
    "                                    'score': 'power', 'closeness': {'1h': .25, '1d': .25, '1w': .25, '1min': .25}}}\n",
    "        detector = SRDetector(df, timeframe, params, 'agglomerative')\n",
    "        detector.get_levels()\n",
    "        levels = list(detector.lines.keys())\n",
    "        start_times = [detector.lines[x]['time'] for x in levels]\n",
    "        detect_times = [detector.lines[x]['detect_time'] for x in levels]\n",
    "        end_datetimes = [df.index[-1]] * len(levels)\n",
    "        scores = [detector.lines[x]['importance'] for x in levels]\n",
    "        return [levels, start_times, detect_times, end_datetimes, scores]\n",
    "\n",
    "    def round(self, x):\n",
    "        coef = 1 / self.ticksize\n",
    "        return round(x * coef) / coef\n",
    "    \n",
    "    def calculate_sl(self, parameters):\n",
    "        def get_vwap_stop(vwap_level_names, vwap_values, fill_price, direction):\n",
    "            delta_vwap = vwap_values[1] - vwap_values[0]\n",
    "            if direction == 1:\n",
    "                for i in range(1, 8):\n",
    "                    if vwap_values[i] <= fill_price <= vwap_values[i + 1]:\n",
    "                        return vwap_values[i - 1], vwap_level_names[i - 1]\n",
    "                if fill_price > vwap_values[-1]:\n",
    "                    dist = np.floor((fill_price - vwap_values[-1]) / delta_vwap)\n",
    "                    name = f'{vwap_level_names[-1][:-1]}{int(4 + dist - 1)}'\n",
    "                    return vwap_values[-1] + (dist - 1) * delta_vwap, name\n",
    "                if fill_price > vwap_values[0]:\n",
    "                    return vwap_values[0] - delta_vwap, f'{vwap_level_names[0][:-1]}5'\n",
    "                dist = np.ceil((vwap_values[0] - fill_price) / delta_vwap)\n",
    "                name = f'{vwap_level_names[0][:-1]}{int(4 + dist + 1)}'\n",
    "                return vwap_values[0] - (dist + 1) * delta_vwap, name\n",
    "            else:  # direction == -1\n",
    "                for i in range(1, 8):\n",
    "                    if vwap_values[i - 1] <= fill_price <= vwap_values[i]:\n",
    "                        return vwap_values[i + 1], vwap_level_names[i + 1]\n",
    "                if fill_price < vwap_values[0]:\n",
    "                    dist = np.floor((vwap_values[0] - fill_price) / delta_vwap)\n",
    "                    name = f'{vwap_level_names[0][:-1]}{int(4 + dist - 1)}'\n",
    "                    return vwap_values[0] - (dist - 1) * delta_vwap, name\n",
    "                if fill_price < vwap_values[-1]:\n",
    "                    return vwap_values[-1] + delta_vwap, f'{vwap_level_names[-1][:-1]}5'\n",
    "                dist = np.ceil((fill_price - vwap_values[-1]) / delta_vwap)\n",
    "                name = f'{vwap_level_names[-1][:-1]}{int(4 + dist + 1)}'\n",
    "                return vwap_values[-1] + (dist + 1) * delta_vwap, name\n",
    "\n",
    "        symbol = parameters[\"symbol\"]\n",
    "        ticksize = config[symbol]['tick_size']\n",
    "        self.ticksize = ticksize\n",
    "        direction = parameters[\"direction\"]\n",
    "        method = parameters[\"method\"] if 'method' in parameters else 'all'\n",
    "        if method is None or method == '':\n",
    "            method = 'all'\n",
    "        neighborhood = parameters[\"neighborhood\"] if 'neighborhood' in parameters else 20\n",
    "        atr_coef = parameters[\"atr_coef\"] if 'atr_coef' in parameters else 1.5\n",
    "        lookback = parameters[\"lookback\"] if 'lookback' in parameters else 100\n",
    "        min_sl_ticks = parameters[\"min_sl_ticks\"] if 'min_sl_ticks' in parameters else 4\n",
    "        minimum_risk = min_sl_ticks * ticksize\n",
    "        end_datetime = datetime.now()\n",
    "        start_datetime = end_datetime - timedelta(days=4)\n",
    "        df = self.bronze_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        if df is None or len(df) == 0:\n",
    "            print('There is no data for this period of time...')\n",
    "            return {}\n",
    "        siver_client = InfluxClient(self.token, self.org, self.url, 'silver')\n",
    "        df = df.iloc[-23 * 60:]  # Approximately last one day\n",
    "        data_dict = df.to_dict(orient='list')\n",
    "        data_index = data_dict['DateTime']\n",
    "        atr = data_dict['ATR'][-1]\n",
    "        current_index = len(data_dict['close']) - 1\n",
    "        fill_price = data_dict['close'][current_index]\n",
    "        answer = {'sl': [], 'risk': [], 'info': []}\n",
    "        sl_dict = {}\n",
    "        if method in ['swing', 'all']:\n",
    "            if direction == 1:\n",
    "                data = np.array(data_dict['low'])\n",
    "                swing_indices = argrelextrema(data, lambda x, y: x < y, order=neighborhood, mode='clip')[0]\n",
    "                if len(swing_indices) and swing_indices[0] < neighborhood:\n",
    "                    swing_indices = swing_indices[1:]\n",
    "                if len(swing_indices) and swing_indices[-1] > len(data) - neighborhood // 2:\n",
    "                    swing_indices = swing_indices[:-1]\n",
    "                for x in swing_indices[::-1]:\n",
    "                    if data[x] < fill_price - minimum_risk:\n",
    "                        sl_dict['swing'] = data[x]\n",
    "                        answer['sl'].append(self.round(data[x]))\n",
    "                        answer['risk'].append(self.round(abs(fill_price - data[x])))\n",
    "                        answer['info'].append(\n",
    "                            f'calculated based on low swing with neighborhood parameter of {neighborhood} candles')\n",
    "            else:\n",
    "                data = np.array(data_dict['high'])\n",
    "                swing_indices = argrelextrema(data, lambda x, y: x > y, order=neighborhood, mode='clip')[0]\n",
    "                if len(swing_indices) and swing_indices[0] < neighborhood:\n",
    "                    swing_indices = swing_indices[1:]\n",
    "                if len(swing_indices) and swing_indices[-1] > len(data) - neighborhood // 2:\n",
    "                    swing_indices = swing_indices[:-1]\n",
    "                for x in swing_indices[::-1]:\n",
    "                    if data[x] > fill_price + minimum_risk:\n",
    "                        sl_dict['swing'] = data[x]\n",
    "                        answer['sl'].append(self.round(data[x]))\n",
    "                        answer['risk'].append(self.round(abs(fill_price - data[x])))\n",
    "                        answer['info'].append(\n",
    "                            f'calculated based on high swing with neighborhood parameter of {neighborhood} candles')\n",
    "        if method in ['minmax', 'all']:\n",
    "            if direction == 1:\n",
    "                mm_stop = min(data_dict['low'][- lookback:])\n",
    "                sl_dict['minmax'] = mm_stop\n",
    "                answer['sl'].append(self.round(mm_stop))\n",
    "                answer['risk'].append(self.round(abs(fill_price - mm_stop)))\n",
    "                answer['info'].append(f'calculated based on minimum low price of previous {lookback} candles')\n",
    "\n",
    "            else:\n",
    "                mm_stop = min(data_dict['high'][- lookback:])\n",
    "                sl_dict['minmax'] = mm_stop\n",
    "                answer['sl'].append(self.round(mm_stop))\n",
    "                answer['risk'].append(self.round(abs(fill_price - mm_stop)))\n",
    "                answer['info'].append(f'calculated based on maximum high price of previous {lookback} candles')\n",
    "\n",
    "        if method in ['atr', 'all']:\n",
    "            if direction == 1:\n",
    "                atr_stop = fill_price - atr_coef * atr\n",
    "            else:\n",
    "                atr_stop = fill_price + atr_coef * atr\n",
    "            sl_dict['atr'] = atr_stop\n",
    "            answer['sl'].append(self.round(atr_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - atr_stop)))\n",
    "            answer['info'].append(f'calculated based on ATR with length 14 multiplied by the coefficient {atr_coef}')\n",
    "        if method in ['DVWAP_band', 'all']:\n",
    "            vwap_level_names = [f'VWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['VWAP'] + [f'VWAP_Top_Band_{i}'\n",
    "                                                                                                    for\n",
    "                                                                                                    i in\n",
    "                                                                                                    range(1, 5)]\n",
    "            vwap_values = [data_dict[x][-1] for x in vwap_level_names]\n",
    "            vwap_stop, level_name = get_vwap_stop(vwap_level_names, vwap_values, fill_price, direction)\n",
    "            answer['sl'].append(self.round(vwap_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - vwap_stop)))\n",
    "            if level_name == 'VWAP':\n",
    "                level_number = 0\n",
    "            elif 'Top' in level_name:\n",
    "                level_number = int(level_name.split('_')[-1])\n",
    "            else:\n",
    "                level_number = -1 * int(level_name.split('_')[-1])\n",
    "            if direction == 1:\n",
    "                if level_number >= 0:\n",
    "                    cur_level = level_number + 2\n",
    "                    bottop = level_number + 1\n",
    "                else:\n",
    "                    cur_level = level_number + 1\n",
    "                    bottop = level_number\n",
    "                    if level_number == -1: cur_level += 1\n",
    "            else:\n",
    "                if level_number <= 0:\n",
    "                    cur_level = level_number - 2\n",
    "                    bottop = level_number - 1\n",
    "                else:\n",
    "                    cur_level = level_number - 1\n",
    "                    bottop = level_number\n",
    "                    if level_number == 1: cur_level -= 1\n",
    "\n",
    "            if direction == 1:\n",
    "                answer['info'].append(\n",
    "                    f'calculated based on {level_name} as the bottom of vwap zone {bottop} (current price is inside vwap zone {cur_level})')\n",
    "            else:\n",
    "                answer['info'].append(\n",
    "                    f'calculated based on {level_name} as the ceiling of vwap zone {bottop} (current price is inside vwap zone {cur_level})')\n",
    "        if method in ['WVWAP_band', 'all']:\n",
    "            vwap_level_names = [f'WVWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['WVWAP'] + [\n",
    "                f'WVWAP_Top_Band_{i}'\n",
    "                for i in\n",
    "                range(1, 5)]\n",
    "            vwap_values = [data_dict[x][-1] for x in vwap_level_names]\n",
    "            vwap_stop, level_name = get_vwap_stop(vwap_level_names, vwap_values, fill_price, direction)\n",
    "            answer['sl'].append(self.round(vwap_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - vwap_stop)))\n",
    "            if level_name == 'WVWAP':\n",
    "                level_number = 0\n",
    "            elif 'Top' in level_name:\n",
    "                level_number = int(level_name.split('_')[-1])\n",
    "            else:\n",
    "                level_number = -1 * int(level_name.split('_')[-1])\n",
    "            if direction == 1:\n",
    "                if level_number >= 0:\n",
    "                    cur_level = level_number + 2\n",
    "                    bottop = level_number + 1\n",
    "                else:\n",
    "                    cur_level = level_number + 1\n",
    "                    bottop = level_number\n",
    "                    if level_number == -1: cur_level += 1\n",
    "            else:\n",
    "                if level_number <= 0:\n",
    "                    cur_level = level_number - 2\n",
    "                    bottop = level_number - 1\n",
    "                else:\n",
    "                    cur_level = level_number - 1\n",
    "                    bottop = level_number\n",
    "                    if level_number == 1: cur_level -= 1\n",
    "\n",
    "            if direction == 1:\n",
    "                answer['info'].append(\n",
    "                    f'calculated based on {level_name} as the bottom of wvwap zone {bottop} (current price is inside wvwap zone {cur_level})')\n",
    "            else:\n",
    "                answer['info'].append(\n",
    "                    f'calculated based on {level_name} as the ceiling of wvwap zone {bottop} (current price is inside wvwap zone {cur_level})')\n",
    "        if method in ['zigzag', 'level', 'all']:\n",
    "            # Read Silver data\n",
    "            sdf = siver_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "            sdf = sdf.iloc[-1]\n",
    "        if method in ['zigzag', 'all']:\n",
    "            if direction == 1:\n",
    "                zz_stop = fill_price  - sdf['ZZ_rth_last5']\n",
    "            else:\n",
    "                zz_stop = fill_price + sdf['ZZ_rth_last5']\n",
    "            answer['sl'].append(self.round(zz_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - zz_stop)))\n",
    "            answer['info'].append(f'Calculated based on the last 5 zigzag legs of the same day of the week')\n",
    "            if direction == 1:\n",
    "                zz_stop = fill_price  - sdf['ZZ_rth_daily']\n",
    "            else:\n",
    "                zz_stop = fill_price + sdf['ZZ_rth_daily']\n",
    "            answer['sl'].append(self.round(zz_stop))\n",
    "            answer['risk'].append(self.round(abs(fill_price - zz_stop)))\n",
    "            answer['info'].append(f'Calculated based on the last session zigzag')\n",
    "\n",
    "        if method in ['level', 'all']:\n",
    "            vwap_level_names = [f'VWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['VWAP'] + [f'VWAP_Top_Band_{i}' for\n",
    "                                                                                                i in\n",
    "                                                                                                range(1, 5)]\n",
    "            vwap_level_names += [f'WVWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['WVWAP'] + [f'WVWAP_Top_Band_{i}'\n",
    "                                                                                                   for i in\n",
    "                                                                                                   range(1, 5)]\n",
    "            vwap_values = [data_dict[x][-1] for x in vwap_level_names]\n",
    "            initial_level_names = ['VP_POC', 'VP_VAL', 'VP_VAH', 'Overnight_high', 'Overnight_low', 'Overnight_mid',\n",
    "                                   'initial_balance_high',\n",
    "                                   'initial_balance_low', 'initial_balance_mid', 'prev_session_max', 'prev_session_min',\n",
    "                                   'prev_session_mid']\n",
    "            level_names = []\n",
    "            level_values = []\n",
    "            for i in range(len(initial_level_names)):\n",
    "                level = initial_level_names[i]\n",
    "                if direction == 1 and sdf[level] < fill_price - minimum_risk or direction == -1 and sdf[\n",
    "                    level] > fill_price + minimum_risk:\n",
    "                    level_values.append(sdf[level])\n",
    "                    level_names.append(level)\n",
    "            for i in range(len(vwap_level_names)):\n",
    "                level = vwap_level_names[i]\n",
    "                if direction == 1 and vwap_values[i] < fill_price - minimum_risk or direction == -1 and vwap_values[\n",
    "                    i] > fill_price + minimum_risk:\n",
    "                    level_values.append(vwap_values[i])\n",
    "                    level_names.append(level)\n",
    "            for x, y in zip(level_names, level_values):\n",
    "                answer['sl'].append(self.round(y))\n",
    "                answer['risk'].append(self.round(abs(fill_price - y)))\n",
    "                answer['info'].append(f'calculated based on the level {x}')\n",
    "\n",
    "            best_level = {}\n",
    "            for col in [ 'weekly_SR', 'daily_SR', 'hourly_SR','5min_SR']:\n",
    "                if col not in sdf:\n",
    "                    continue\n",
    "                sr_levels = eval(sdf[col])\n",
    "                for i, val in enumerate(sr_levels['values']):\n",
    "                    if direction == 1 and val < fill_price - minimum_risk:\n",
    "                        if col not in best_level or val > best_level[col]['sl']:\n",
    "                            best_level[col] = {'sl': val, 'info':f'calculate based on {\" \".join(col.split(\"_\"))} level starting from {sr_levels[\"start_time\"][i]}'}\n",
    "                    if direction == -1 and val > fill_price + minimum_risk:\n",
    "                        if col not in best_level or val < best_level[col]['sl']:\n",
    "                            best_level[col] = {'sl': val, 'info':f'calculate based on {\" \".join(col.split(\"_\"))} level starting from {sr_levels[\"start_time\"][i]}'}\n",
    "            for col in best_level:\n",
    "                answer['sl'].append(self.round(best_level[col]['sl']))\n",
    "                answer['risk'].append(self.round(abs(fill_price - best_level[col]['sl'])))\n",
    "                answer['info'].append(best_level[col]['info'])\n",
    "        if direction == 1:\n",
    "            sorted_items = sorted(zip(answer['sl'], answer['risk'], answer['info']), key=lambda x: x[0], reverse=True)\n",
    "        else:\n",
    "            sorted_items = sorted(zip(answer['sl'], answer['risk'], answer['info']), key=lambda x: x[0])\n",
    "        return {'sl': [item[0] for item in sorted_items],\n",
    "                'risk': [item[1] for item in sorted_items],\n",
    "                'info': [item[2] for item in sorted_items]}\n",
    "\n",
    "    def calculate_tp(self, parameters):\n",
    "        symbol = parameters[\"symbol\"]\n",
    "        ticksize = config[symbol]['tick_size']\n",
    "        self.ticksize = ticksize\n",
    "        direction = parameters[\"direction\"]\n",
    "        sl = parameters[\"stoploss\"]\n",
    "        method = parameters[\"method\"] if 'method' in parameters else 'all'\n",
    "        end_datetime = datetime.now()\n",
    "        start_datetime = end_datetime - timedelta(days=4)\n",
    "        df = self.bronze_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        if df is None or len(df) == 0:\n",
    "            print('There is no data for this period of time...')\n",
    "            return {}\n",
    "        siver_client = InfluxClient(self.token, self.org, self.url, 'silver')\n",
    "        df = df.iloc[-23 * 60:]  # Approximately last one day\n",
    "        data_dict = df.to_dict(orient='list')\n",
    "        data_index = data_dict['DateTime']\n",
    "        atr = data_dict['ATR'][-1]\n",
    "        current_index = len(data_dict['close']) - 1\n",
    "        fill_price = data_dict['close'][current_index]\n",
    "        risk = abs(fill_price - sl)\n",
    "        answer = {'tp': [], 'info': []}\n",
    "        sdf = siver_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        sdf = sdf.iloc[-1]\n",
    "        answer = {'tp': [], 'info': []}\n",
    "        vwap_level_names = [f'VWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['VWAP'] + [f'VWAP_Top_Band_{i}' for\n",
    "                                                                                            i in\n",
    "                                                                                            range(1, 5)]\n",
    "        vwap_level_names += [f'WVWAP_Bottom_Band_{i}' for i in range(4, 0, -1)] + ['WVWAP'] + [f'WVWAP_Top_Band_{i}'\n",
    "                                                                                               for i in\n",
    "                                                                                               range(1, 5)]\n",
    "        vwap_values = [data_dict[x][-1] for x in vwap_level_names]\n",
    "        initial_level_names = ['VP_POC', 'VP_VAL', 'VP_VAH', 'Overnight_high', 'Overnight_low', 'Overnight_mid',\n",
    "                               'initial_balance_high',\n",
    "                               'initial_balance_low', 'initial_balance_mid', 'prev_session_max', 'prev_session_min',\n",
    "                               'prev_session_mid']\n",
    "        level_names = []\n",
    "        level_values = []\n",
    "        for i in range(len(initial_level_names)):\n",
    "            level = initial_level_names[i]\n",
    "            if direction == 1 and sdf[level] > fill_price + risk or direction == -1 and sdf[\n",
    "                level] < fill_price - risk:\n",
    "                level_values.append(sdf[level])\n",
    "                level_names.append(level)\n",
    "        for i in range(len(vwap_level_names)):\n",
    "            level = vwap_level_names[i]\n",
    "            if direction == 1 and  vwap_values[i] > fill_price + risk or direction == -1 and vwap_values[i] < fill_price - risk:\n",
    "                level_values.append(vwap_values[i])\n",
    "                level_names.append(level)\n",
    "        for x, y in zip(level_names, level_values):\n",
    "            answer['tp'].append(self.round(y))\n",
    "            answer['info'].append(f'calculated based on the level {x}')\n",
    "\n",
    "        best_level = {}\n",
    "        for col in [ 'weekly_SR', 'daily_SR', 'hourly_SR','5min_SR']:\n",
    "            if col not in sdf:\n",
    "                continue\n",
    "            sr_levels = eval(sdf[col])\n",
    "            for i, val in enumerate(sr_levels['values']):\n",
    "                if direction == 1 and val > fill_price + risk:\n",
    "                    if col not in best_level or val < best_level[col]['tp']:\n",
    "                        best_level[col] = {'tp': val, 'info':f'calculate based on {\" \".join(col.split(\"_\"))} level starting from {str(sr_levels[\"start_time\"][i])[:19]}'}\n",
    "                if direction == -1 and val > fill_price + risk:\n",
    "                    if col not in best_level or val < best_level[col]['tp']:\n",
    "                        best_level[col] = {'tp': val, 'info':f'calculate based on {\" \".join(col.split(\"_\"))} level starting from {str(sr_levels[\"start_time\"][i])[:19]}'}\n",
    "        for col in best_level:\n",
    "            answer['tp'].append(self.round(best_level[col]['tp']))\n",
    "            answer['info'].append(best_level[col]['info'])\n",
    "        if direction == -1:\n",
    "            sorted_items = sorted(zip(answer['tp'], answer['info']), key=lambda x: x[0], reverse=True)\n",
    "        else:\n",
    "            sorted_items = sorted(zip(answer['tp'], answer['info']), key=lambda x: x[0])\n",
    "        return {'tp': [item[0] for item in sorted_items],\n",
    "                'info': [item[1] for item in sorted_items]}\n",
    "\n",
    "    def get_bias(self, parameters):\n",
    "        def convert_trend(x):\n",
    "            if abs(x) < .2:\n",
    "                return 0\n",
    "            return int( np.sign(x))\n",
    "#             if abs(x)  .4:\n",
    "#                 return 1 * np.sign(x)\n",
    "#             if abs(x) < .6:\n",
    "#                 return 2 * np.sign(x)\n",
    "#             return 3 * np.sign(x)\n",
    "\n",
    "        symbol = parameters[\"symbol\"]\n",
    "        ticksize = config[symbol]['tick_size']\n",
    "        self.ticksize = ticksize\n",
    "        method = parameters[\"method\"] if 'method' in parameters else 'all'\n",
    "        end_datetime = datetime.now()\n",
    "        start_datetime = end_datetime - timedelta(days=4)\n",
    "        df = self.bronze_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        if df is None or len(df) == 0:\n",
    "            print('There is no data for this period of time...')\n",
    "            return {}\n",
    "        siver_client = InfluxClient(self.token, self.org, self.url, 'silver')\n",
    "        df = df.iloc[-46 * 60:]  # Approximately last one day\n",
    "        data_dict = df.to_dict(orient='list')\n",
    "        data_index = data_dict['DateTime']\n",
    "        atr = data_dict['ATR'][-1]\n",
    "        current_index = len(data_dict['close']) - 1\n",
    "        cur_close = data_dict['close'][current_index]\n",
    "        answer = {'bias': [], 'info': []}\n",
    "        sdf = siver_client.retrieve_db_df_between(symbol, start_datetime, end_datetime)\n",
    "        if method in ['weekly VWAP', 'all']:\n",
    "            bias = 0\n",
    "            if cur_close > data_dict['VWAP_Top_Band_2'][current_index]:\n",
    "                bias = 1\n",
    "            elif cur_close < data_dict['VWAP_Bottom_Band_2'][current_index]:\n",
    "                bias = -1\n",
    "            else:\n",
    "                for current_index in range(len(data_dict['close']) - 1, -1, -1):\n",
    "                    cur_high = data_dict['high'][current_index]\n",
    "                    cur_low = data_dict['low'][current_index]\n",
    "                    if cur_high >= data_dict['VWAP_Top_Band_2'][current_index]:\n",
    "                        bias = -1\n",
    "                        break\n",
    "                    if cur_low <= data_dict['VWAP_Bottom_Band_2'][current_index]:\n",
    "                        bias = 1\n",
    "                        break\n",
    "            info = 'Calculated based on weekly VWAP'\n",
    "            answer['bias'].append(bias)\n",
    "            answer['info'].append(info)\n",
    "        if method in ['volume profile', 'all']:\n",
    "            poc = sdf['VP_POC'].iloc[current_index]\n",
    "            val = sdf['VP_VAL'].iloc[current_index]\n",
    "            vah = sdf['VP_VAH'].iloc[current_index]\n",
    "            bias = 0\n",
    "            if cur_close > vah:\n",
    "                bias = 1\n",
    "            elif cur_close < val:\n",
    "                bias = -1\n",
    "            else:\n",
    "                for current_index in range(len(data_dict['close']) - 1, -1, -1):\n",
    "                    cur_high = data_dict['high'][current_index]\n",
    "                    cur_low = data_dict['low'][current_index]\n",
    "                    if cur_high >= vah:\n",
    "                        bias = -1\n",
    "                        break\n",
    "                    if cur_low <= val:\n",
    "                        bias = 1\n",
    "                        break\n",
    "            info = 'Calculated based on VAL/VAH of volume profile'\n",
    "            answer['bias'].append(bias)\n",
    "            answer['info'].append(info)\n",
    "        if method in ['trend', 'all']:\n",
    "            short_trend = convert_trend(sdf.iloc[-1]['short_term_trend_prob'])\n",
    "            mid_trend = convert_trend(sdf.iloc[-1]['mid_term_trend_prob'])\n",
    "            long_trend = convert_trend(sdf.iloc[-1]['long_term_trend_prob'])\n",
    "            answer['bias'] += [short_trend, mid_trend, long_trend]\n",
    "            answer['info'] += [f'Calculated based on {x} trend' for x in ['short term', 'mid term', 'long term']]\n",
    "        if method in ['zigzag', 'all']:\n",
    "            columns = ['trend_last_hour']\n",
    "            for col in columns:\n",
    "                trend = sdf.iloc[-1][col]\n",
    "                answer['bias'].append(1 if trend > .2 else -1 if trend < -.2 else 0)\n",
    "                answer['info'].append(f'Calculated based on trend of {\" \".join(x for x in col[6:].split(\"_\"))}')\n",
    "        if method in ['counter', 'all']:\n",
    "            bid_number = np.sum(df['bid_number'].iloc[-20:])\n",
    "            ask_number = np.sum(df['ask_number'].iloc[-20:])\n",
    "            bid_volume = np.sum(df['bid_volume'].iloc[-20:])\n",
    "            ask_volume = np.sum(df['ask_volume'].iloc[-20:])\n",
    "            # main calculations\n",
    "            bid_ratio = bid_volume / bid_number\n",
    "            ask_ratio = ask_volume / ask_number\n",
    "            power_ratio = bid_ratio / ask_ratio if bid_ratio > ask_ratio else -ask_ratio / bid_ratio\n",
    "            counter_ratio = bid_volume / ask_volume if bid_volume > ask_volume else - ask_volume / bid_volume\n",
    "            trend = 0\n",
    "            if power_ratio > 1.02 and counter_ratio > 1.02:\n",
    "                trend = 1\n",
    "            if power_ratio < -1.02 and counter_ratio < -1.02:\n",
    "                trend = -1\n",
    "            answer['bias'].append(trend)\n",
    "            answer['info'].append(f'Calculated based on counter ratio and power ratio')\n",
    "        if method in ['micro-composite', 'all']:\n",
    "            pass\n",
    "            # microcomposite = MicroComposite(self.config)\n",
    "        answer['combined_bias'] = 1 if np.sum(answer['bias']) > 0 else -1 if np.sum(answer['bias']) < 0 else 0\n",
    "        return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffacbe58",
   "metadata": {},
   "source": [
    "### Make object of FunctionCalls class and call a method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bddd2e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend type: <<Strong upward>>\n",
      "----------------------------------------\n",
      "sr_values = [181.32, 181.45, 182.03, 182.11, 182.13, 183.2, 182.5, 183.91, 185.4, 188.3]\n",
      "sr_start_dates = [Timestamp('2024-05-07 09:00:00'), Timestamp('2024-05-08 07:00:00'), Timestamp('2024-05-08 13:00:00'), Timestamp('2024-05-09 06:00:00'), Timestamp('2024-05-10 10:00:00'), Timestamp('2024-05-10 12:00:00'), Timestamp('2024-05-10 16:00:00'), Timestamp('2024-05-13 05:00:00'), Timestamp('2024-05-14 05:00:00'), Timestamp('2024-05-14 06:00:00')]\n",
      "sr_detection_dates = [Timestamp('2024-05-07 11:00:00'), Timestamp('2024-05-08 09:00:00'), Timestamp('2024-05-08 15:00:00'), Timestamp('2024-05-09 08:00:00'), Timestamp('2024-05-10 12:00:00'), Timestamp('2024-05-10 14:00:00'), Timestamp('2024-05-13 02:00:00'), Timestamp('2024-05-13 07:00:00'), Timestamp('2024-05-14 07:00:00'), Timestamp('2024-05-14 08:00:00')]\n",
      "sr_end_dates = [Timestamp('2024-05-14 09:35:00'), Timestamp('2024-05-14 09:35:00'), Timestamp('2024-05-14 09:35:00'), Timestamp('2024-05-14 09:35:00'), Timestamp('2024-05-14 09:35:00'), Timestamp('2024-05-14 09:35:00'), Timestamp('2024-05-14 09:35:00'), Timestamp('2024-05-14 09:35:00'), Timestamp('2024-05-14 09:35:00'), Timestamp('2024-05-14 09:35:00')]\n",
      "sr_importances = [4.5, 2.9, 8.4, 6.1, 2.8, 2.1, 4.7, 4.4, 5.2, 4.2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#You should create an instance of the FunctionCalls class whenever you want to call a function of it.\n",
    "\n",
    "#Example: To find trend of last 10 days\n",
    "now = datetime.now()\n",
    "fc = FunctionCalls()\n",
    "parameters = {\n",
    "    \"symbol\": \"ES\",\n",
    "    \"start_datetime\": f\"{now - timedelta(days=10)}\",\n",
    "    \"end_datetime\": f\"{now}\"\n",
    "}\n",
    "trend = fc.detect_trend(parameters)\n",
    "trend_name = {-3:'Strong downward',-2:'Downward',-1:'Weak downward', 0:'No trend', 3:'Strong upward', 2:'Upward', 1:'Weak upward'}\n",
    "print(f'Trend type: <<{trend_name[trend]}>>')\n",
    "print('-'*40)\n",
    "#Example: To find S/R of last 10 days on 1h timeframe data\n",
    "fc = FunctionCalls()\n",
    "parameters = {\n",
    "    \"symbol\": \"AAPL\",\n",
    "    \"timeframe\": \"1h\",\n",
    "    \"lookback_days\": \"10 days\"\n",
    "}\n",
    "sr_value, sr_start_date, sr_detect_date, sr_end_date, sr_importance = fc.calculate_sr(parameters)\n",
    "print(f'sr_values = {sr_value}\\nsr_start_dates = {sr_start_date}\\nsr_detection_dates = {sr_detect_date}\\nsr_end_dates = {sr_end_date}\\nsr_importances = {sr_importance}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd13f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sl': [18305.75, 18305.75, 18308.75, 18309.5, 18320.25, 18326.0, 18326.75, 18327.75, 18331.5, 18332.75, 18333.25, 18367.25, 18370.75], 'risk': [1.75, 1.75, 4.75, 5.5, 16.25, 22.0, 22.75, 23.75, 27.5, 28.75, 29.25, 63.25, 66.75], 'info': ['calculated based on high swing with neighborhood parameter of 20 candles', 'calculated based on maximum high price of previous 100 candles', 'calculated based on high swing with neighborhood parameter of 20 candles', 'calculated based on high swing with neighborhood parameter of 20 candles', 'calculated based on WVWAP_Top_Band_2 as the ceiling of wvwap zone 2 (current price is inside wvwap zone 1)', 'Calculated based on the last 5 zigzag legs of the same day of the week', 'calculated based on high swing with neighborhood parameter of 20 candles', 'calculated based on ATR with length 14 multiplied by the coefficient 1.5', 'calculated based on high swing with neighborhood parameter of 20 candles', 'calculated based on VWAP_Top_Band_2 as the ceiling of vwap zone 2 (current price is inside vwap zone 1)', 'Calculated based on the last session zigzag', 'calculated based on high swing with neighborhood parameter of 20 candles', 'calculated based on high swing with neighborhood parameter of 20 candles']}\n"
     ]
    }
   ],
   "source": [
    "#'method' key in the parameters can be one of the following methods:\n",
    "# swing , minmax , atr , zigzag , DVWAP_band , WVWAP_band , level , all\n",
    "# if method not set, the result is based on all methods\n",
    "fc = FunctionCalls()\n",
    "# parameters = {\"symbol\": \"ES\",\"direction\": 1, 'method':'level'}\n",
    "parameters = {\"symbol\": \"NQ\", \"direction\": \"-1\"}\n",
    "stoploss = fc.calculate_sl(parameters)\n",
    "print(stoploss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdaa93b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m fc \u001b[38;5;241m=\u001b[39m FunctionCalls()\n\u001b[0;32m      5\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mES\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m----> 7\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[43mfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(bias)\n",
      "Cell \u001b[1;32mIn[7], line 580\u001b[0m, in \u001b[0;36mFunctionCalls.get_bias\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    578\u001b[0m     answer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(info)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume profile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m--> 580\u001b[0m     poc \u001b[38;5;241m=\u001b[39m \u001b[43msdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVP_POC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    581\u001b[0m     val \u001b[38;5;241m=\u001b[39m sdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVP_VAL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[current_index]\n\u001b[0;32m    582\u001b[0m     vah \u001b[38;5;241m=\u001b[39m sdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVP_VAH\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[current_index]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "#'method' key in the parameters can be one of the following methods:\n",
    "# swing , minmax , atr , zigzag , DVWAP_band , WVWAP_band , level , all\n",
    "# if method not set, the result is based on all methods\n",
    "fc = FunctionCalls()\n",
    "parameters = {\"symbol\": \"ES\", \"method\":\"all\"}\n",
    "\n",
    "bias = fc.get_bias(parameters)\n",
    "print(bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02c321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
