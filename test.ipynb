{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to update token costs. Using static costs.\n",
      "/home/sepehr/anaconda3/envs/sepehr/lib/python3.10/site-packages/tokencost/constants.py:61: RuntimeWarning: coroutine 'update_token_costs' was never awaited\n",
      "  TOKEN_COSTS = TOKEN_COSTS_STATIC\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from main import llm_surf\n",
    "import input_filter\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing each function individualy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "detect_trend_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the trend of NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00?\",\n",
    "    \"What is the trend of NQ stock for the past week?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"What is the trend?\",\n",
    "    # \"Show me the trend of ES from May-1-2024 12:00:00 to May-5-2024 12:00:00.\",\n",
    "    # \"Trend of GC, May-1-2024 12:00:00 to May-5-2024 12:00:00\",\n",
    "    # \"Trend of GC, past 2 hours\",\n",
    "    # \"What is the trend of NQ from May-1-2024 12:00:00 until now?\",\n",
    "    # # Challenging Prompts\n",
    "    # \"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\",\n",
    "    \"What is the trend of NQ stock from May-20-2024 15:45:30 until Apr-24-2024 15:45:30?\",\n",
    "    # \"What is the trend of NQ stock from 20/4/2024 15:45:30 until 24/3/2024 15:45:30?\",\n",
    "    # \"What is the trend of NQ stock from 4/20/2024 15:45:30 until 4/24/2024 15:45:30?\",\n",
    "    \"Trend of Gold in the last month?\",\n",
    "    # \"Trend in the last month\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the trend of NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00?    =>    {'response': 'Based on the analysis of the NQ stock from May-21-2024 12:00:00 until May-25-2024 12:00:00, the trend is without significant trend.', 'chart_info': {}}\n",
      "Inference Time: 28.964582681655884 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the trend of NQ stock for the past week?    =>    {'response': 'Based on the historical data of the NQ stock for the past week, there is no significant trend detected. The trend intensity and direction are neutral.', 'chart_info': {}}\n",
      "Inference Time: 25.172155141830444 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the trend of NQ?    =>    {'response': 'To determine the trend of NQ, I can analyze the historical price data over a specific time range or lookback period. Please provide either the start and end dates or the number of days to look back for the analysis.', 'chart_info': None}\n",
      "Inference Time: 6.547298192977905 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the trend?    =>    {'response': 'To determine the trend of a financial instrument, I need the symbol of the instrument and the time range or lookback period you are interested in. Could you please provide me with the symbol and the desired time range or lookback period?', 'chart_info': None}\n",
      "Inference Time: 6.243314027786255 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the trend of NQ stock from May-20-2024 15:45:30 until Apr-24-2024 15:45:30?    =>    {'response': 'To determine the trend of the NQ stock, I need a valid time range for the analysis. The end date time should be after the start date time. Please provide a valid time range for the analysis.', 'chart_info': {}}\n",
      "Inference Time: 12.90014386177063 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend of Gold in the last month?    =>    {'response': 'To determine the trend of Gold in the last month, I need to analyze the historical price data. Could you please provide me with the start and end dates of the one-month period you are interested in?', 'chart_info': {}}\n",
      "Inference Time: 15.520745754241943 seconds\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "detect_trend_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in detect_trend_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    detect_trend_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/detect_trend_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(detect_trend_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Support and Resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sr_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 10 minutes.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM by looking back up to past 10 days.\",\n",
    "    \"Calculate Support and Resistance Levels based on YM with the timeframe of 1 hour.\",\n",
    "    \"How much is the sr of CL for the past week?\",\n",
    "    # Challenging prompts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "response: ([38306.0, 38322.0, 38448.0, 38749.0, 38770.0, 38778.0, 38901.0, 39259.0, 39094.0, 39117.0, 39168.0, 39118.0, 39476.0, 39481.0, 39687.0, 39502.0, 39527.0, 39613.0, 39619.0, 39558.0], [Timestamp('2024-06-14 04:00:00'), Timestamp('2024-06-14 07:10:00'), Timestamp('2024-06-17 06:30:00'), Timestamp('2024-06-18 08:00:00'), Timestamp('2024-06-19 15:00:00'), Timestamp('2024-06-20 06:30:00'), Timestamp('2024-06-20 08:00:00'), Timestamp('2024-06-20 11:30:00'), Timestamp('2024-06-20 12:50:00'), Timestamp('2024-06-20 18:00:00'), Timestamp('2024-06-20 22:30:00'), Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-21 05:20:00'), Timestamp('2024-06-21 06:40:00'), Timestamp('2024-06-21 07:20:00'), Timestamp('2024-06-21 08:40:00'), Timestamp('2024-06-21 10:30:00'), Timestamp('2024-06-21 11:20:00'), Timestamp('2024-06-21 12:50:00'), Timestamp('2024-06-21 13:00:00')], [Timestamp('2024-06-14 04:50:00'), Timestamp('2024-06-14 08:00:00'), Timestamp('2024-06-17 07:20:00'), Timestamp('2024-06-18 08:50:00'), Timestamp('2024-06-19 15:50:00'), Timestamp('2024-06-20 07:20:00'), Timestamp('2024-06-20 08:50:00'), Timestamp('2024-06-20 12:20:00'), Timestamp('2024-06-20 13:40:00'), Timestamp('2024-06-20 20:00:00'), Timestamp('2024-06-20 23:30:00'), Timestamp('2024-06-21 01:40:00'), Timestamp('2024-06-21 06:10:00'), Timestamp('2024-06-21 07:30:00'), Timestamp('2024-06-21 08:10:00'), Timestamp('2024-06-21 09:30:00'), Timestamp('2024-06-21 11:20:00'), Timestamp('2024-06-21 12:10:00'), Timestamp('2024-06-21 13:40:00'), Timestamp('2024-06-21 13:50:00')], [Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00')], [7.2, 3.7, 4.1, 13.8, 9.5, 6.1, 2.1, 3.5, 3.0, 53.6, 8.0, 41.4, 10.7, 6.6, 3.0, 2.7, 3.9, 3.2, 3.3, 2.6], 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 10min are as follows:\\n\\n- Levels: [38306.0, 38322.0, 38448.0, 38749.0, 38770.0, 38778.0, 38901.0, 39259.0, 39094.0, 39117.0, 39168.0, 39118.0, 39476.0, 39481.0, 39687.0, 39502.0, 39527.0, 39613.0, 39619.0, 39558.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.')\n",
      "\n",
      "Calculate Support and Resistance Levels based on YM by looking back up to past 10 days and timeframe of 10 minutes.    =>    {'response': 'Great! If you have any more questions or need further assistance, feel free to ask. Happy trading!\\nSure! I can help you with that. Let me calculate the support and resistance levels for YM based on a lookback period of 10 days and a timeframe of 10 minutes.', 'chart_info': {'levels_prices': [38306.0, 38322.0, 38448.0, 38749.0, 38770.0, 38778.0, 38901.0, 39259.0, 39094.0, 39117.0, 39168.0, 39118.0, 39476.0, 39481.0, 39687.0, 39502.0, 39527.0, 39613.0, 39619.0, 39558.0], 'levels_start_timestamps': [Timestamp('2024-06-14 04:00:00'), Timestamp('2024-06-14 07:10:00'), Timestamp('2024-06-17 06:30:00'), Timestamp('2024-06-18 08:00:00'), Timestamp('2024-06-19 15:00:00'), Timestamp('2024-06-20 06:30:00'), Timestamp('2024-06-20 08:00:00'), Timestamp('2024-06-20 11:30:00'), Timestamp('2024-06-20 12:50:00'), Timestamp('2024-06-20 18:00:00'), Timestamp('2024-06-20 22:30:00'), Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-21 05:20:00'), Timestamp('2024-06-21 06:40:00'), Timestamp('2024-06-21 07:20:00'), Timestamp('2024-06-21 08:40:00'), Timestamp('2024-06-21 10:30:00'), Timestamp('2024-06-21 11:20:00'), Timestamp('2024-06-21 12:50:00'), Timestamp('2024-06-21 13:00:00')], 'levels_detect_timestamps': [Timestamp('2024-06-14 04:50:00'), Timestamp('2024-06-14 08:00:00'), Timestamp('2024-06-17 07:20:00'), Timestamp('2024-06-18 08:50:00'), Timestamp('2024-06-19 15:50:00'), Timestamp('2024-06-20 07:20:00'), Timestamp('2024-06-20 08:50:00'), Timestamp('2024-06-20 12:20:00'), Timestamp('2024-06-20 13:40:00'), Timestamp('2024-06-20 20:00:00'), Timestamp('2024-06-20 23:30:00'), Timestamp('2024-06-21 01:40:00'), Timestamp('2024-06-21 06:10:00'), Timestamp('2024-06-21 07:30:00'), Timestamp('2024-06-21 08:10:00'), Timestamp('2024-06-21 09:30:00'), Timestamp('2024-06-21 11:20:00'), Timestamp('2024-06-21 12:10:00'), Timestamp('2024-06-21 13:40:00'), Timestamp('2024-06-21 13:50:00')], 'levels_end_timestamps': [Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00')], 'levels_scores': [7.2, 3.7, 4.1, 13.8, 9.5, 6.1, 2.1, 3.5, 3.0, 53.6, 8.0, 41.4, 10.7, 6.6, 3.0, 2.7, 3.9, 3.2, 3.3, 2.6], 'function_name': 'calculate_sr', 'symbol': 'YM', 'timeframe': '10min', 'response': 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 10min are as follows:\\n\\n- Levels: [38306.0, 38322.0, 38448.0, 38749.0, 38770.0, 38778.0, 38901.0, 39259.0, 39094.0, 39117.0, 39168.0, 39118.0, 39476.0, 39481.0, 39687.0, 39502.0, 39527.0, 39613.0, 39619.0, 39558.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.'}}\n",
      "Inference Time: 26.802929401397705 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "response: ([38306.0, 38322.0, 38448.0, 38749.0, 38770.0, 38778.0, 38901.0, 39259.0, 39094.0, 39117.0, 39168.0, 39118.0, 39476.0, 39481.0, 39687.0, 39502.0, 39527.0, 39613.0, 39619.0, 39558.0], [Timestamp('2024-06-14 04:00:00'), Timestamp('2024-06-14 07:10:00'), Timestamp('2024-06-17 06:30:00'), Timestamp('2024-06-18 08:00:00'), Timestamp('2024-06-19 15:00:00'), Timestamp('2024-06-20 06:30:00'), Timestamp('2024-06-20 08:00:00'), Timestamp('2024-06-20 11:30:00'), Timestamp('2024-06-20 12:50:00'), Timestamp('2024-06-20 18:00:00'), Timestamp('2024-06-20 22:30:00'), Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-21 05:20:00'), Timestamp('2024-06-21 06:40:00'), Timestamp('2024-06-21 07:20:00'), Timestamp('2024-06-21 08:40:00'), Timestamp('2024-06-21 10:30:00'), Timestamp('2024-06-21 11:20:00'), Timestamp('2024-06-21 12:50:00'), Timestamp('2024-06-21 13:00:00')], [Timestamp('2024-06-14 04:50:00'), Timestamp('2024-06-14 08:00:00'), Timestamp('2024-06-17 07:20:00'), Timestamp('2024-06-18 08:50:00'), Timestamp('2024-06-19 15:50:00'), Timestamp('2024-06-20 07:20:00'), Timestamp('2024-06-20 08:50:00'), Timestamp('2024-06-20 12:20:00'), Timestamp('2024-06-20 13:40:00'), Timestamp('2024-06-20 20:00:00'), Timestamp('2024-06-20 23:30:00'), Timestamp('2024-06-21 01:40:00'), Timestamp('2024-06-21 06:10:00'), Timestamp('2024-06-21 07:30:00'), Timestamp('2024-06-21 08:10:00'), Timestamp('2024-06-21 09:30:00'), Timestamp('2024-06-21 11:20:00'), Timestamp('2024-06-21 12:10:00'), Timestamp('2024-06-21 13:40:00'), Timestamp('2024-06-21 13:50:00')], [Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00')], [7.2, 3.7, 4.1, 13.8, 9.5, 6.1, 2.1, 3.5, 3.0, 53.6, 8.0, 41.4, 10.7, 6.6, 3.0, 2.7, 3.9, 3.2, 3.3, 2.6], 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 10min are as follows:\\n\\n- Levels: [38306.0, 38322.0, 38448.0, 38749.0, 38770.0, 38778.0, 38901.0, 39259.0, 39094.0, 39117.0, 39168.0, 39118.0, 39476.0, 39481.0, 39687.0, 39502.0, 39527.0, 39613.0, 39619.0, 39558.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.')\n",
      "\n",
      "Calculate Support and Resistance Levels based on YM by looking back up to past 10 days.    =>    {'response': 'Great! If you have any more questions or need further assistance, feel free to ask. Happy trading!\\nSure! I can help you with that. Let me calculate the support and resistance levels for YM based on historical price data with a lookback period of 10 days.', 'chart_info': {'levels_prices': [38306.0, 38322.0, 38448.0, 38749.0, 38770.0, 38778.0, 38901.0, 39259.0, 39094.0, 39117.0, 39168.0, 39118.0, 39476.0, 39481.0, 39687.0, 39502.0, 39527.0, 39613.0, 39619.0, 39558.0], 'levels_start_timestamps': [Timestamp('2024-06-14 04:00:00'), Timestamp('2024-06-14 07:10:00'), Timestamp('2024-06-17 06:30:00'), Timestamp('2024-06-18 08:00:00'), Timestamp('2024-06-19 15:00:00'), Timestamp('2024-06-20 06:30:00'), Timestamp('2024-06-20 08:00:00'), Timestamp('2024-06-20 11:30:00'), Timestamp('2024-06-20 12:50:00'), Timestamp('2024-06-20 18:00:00'), Timestamp('2024-06-20 22:30:00'), Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-21 05:20:00'), Timestamp('2024-06-21 06:40:00'), Timestamp('2024-06-21 07:20:00'), Timestamp('2024-06-21 08:40:00'), Timestamp('2024-06-21 10:30:00'), Timestamp('2024-06-21 11:20:00'), Timestamp('2024-06-21 12:50:00'), Timestamp('2024-06-21 13:00:00')], 'levels_detect_timestamps': [Timestamp('2024-06-14 04:50:00'), Timestamp('2024-06-14 08:00:00'), Timestamp('2024-06-17 07:20:00'), Timestamp('2024-06-18 08:50:00'), Timestamp('2024-06-19 15:50:00'), Timestamp('2024-06-20 07:20:00'), Timestamp('2024-06-20 08:50:00'), Timestamp('2024-06-20 12:20:00'), Timestamp('2024-06-20 13:40:00'), Timestamp('2024-06-20 20:00:00'), Timestamp('2024-06-20 23:30:00'), Timestamp('2024-06-21 01:40:00'), Timestamp('2024-06-21 06:10:00'), Timestamp('2024-06-21 07:30:00'), Timestamp('2024-06-21 08:10:00'), Timestamp('2024-06-21 09:30:00'), Timestamp('2024-06-21 11:20:00'), Timestamp('2024-06-21 12:10:00'), Timestamp('2024-06-21 13:40:00'), Timestamp('2024-06-21 13:50:00')], 'levels_end_timestamps': [Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00')], 'levels_scores': [7.2, 3.7, 4.1, 13.8, 9.5, 6.1, 2.1, 3.5, 3.0, 53.6, 8.0, 41.4, 10.7, 6.6, 3.0, 2.7, 3.9, 3.2, 3.3, 2.6], 'function_name': 'calculate_sr', 'symbol': 'YM', 'timeframe': '10min', 'response': 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 10min are as follows:\\n\\n- Levels: [38306.0, 38322.0, 38448.0, 38749.0, 38770.0, 38778.0, 38901.0, 39259.0, 39094.0, 39117.0, 39168.0, 39118.0, 39476.0, 39481.0, 39687.0, 39502.0, 39527.0, 39613.0, 39619.0, 39558.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.'}}\n",
      "Inference Time: 21.335211277008057 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "response: ([38448.0, 38749.0, 38770.0, 38778.0, 39259.0, 39117.0, 39168.0, 39118.0, 39476.0, 39687.0], [Timestamp('2024-06-17 06:00:00'), Timestamp('2024-06-18 08:00:00'), Timestamp('2024-06-19 15:00:00'), Timestamp('2024-06-20 06:00:00'), Timestamp('2024-06-20 11:00:00'), Timestamp('2024-06-20 18:00:00'), Timestamp('2024-06-20 22:00:00'), Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-21 05:00:00'), Timestamp('2024-06-21 07:00:00')], [Timestamp('2024-06-17 08:00:00'), Timestamp('2024-06-18 10:00:00'), Timestamp('2024-06-19 17:00:00'), Timestamp('2024-06-20 08:00:00'), Timestamp('2024-06-20 13:00:00'), Timestamp('2024-06-20 20:00:00'), Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-21 02:00:00'), Timestamp('2024-06-21 07:00:00'), Timestamp('2024-06-21 09:00:00')], [Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00')], [5.1, 3.9, 7.3, 5.6, 2.8, 16.0, 2.1, 15.5, 5.8, 4.3], 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 1h are as follows:\\n\\n- Levels: [38448.0, 38749.0, 38770.0, 38778.0, 39259.0, 39117.0, 39168.0, 39118.0, 39476.0, 39687.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.')\n",
      "\n",
      "Calculate Support and Resistance Levels based on YM with the timeframe of 1 hour.    =>    {'response': 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 1 hour are as follows:\\n\\n- Levels: [38448.0, 38749.0, 38770.0, 38778.0, 39259.0, 39117.0, 39168.0, 39118.0, 39476.0, 39687.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.', 'chart_info': {'levels_prices': [38448.0, 38749.0, 38770.0, 38778.0, 39259.0, 39117.0, 39168.0, 39118.0, 39476.0, 39687.0], 'levels_start_timestamps': [Timestamp('2024-06-17 06:00:00'), Timestamp('2024-06-18 08:00:00'), Timestamp('2024-06-19 15:00:00'), Timestamp('2024-06-20 06:00:00'), Timestamp('2024-06-20 11:00:00'), Timestamp('2024-06-20 18:00:00'), Timestamp('2024-06-20 22:00:00'), Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-21 05:00:00'), Timestamp('2024-06-21 07:00:00')], 'levels_detect_timestamps': [Timestamp('2024-06-17 08:00:00'), Timestamp('2024-06-18 10:00:00'), Timestamp('2024-06-19 17:00:00'), Timestamp('2024-06-20 08:00:00'), Timestamp('2024-06-20 13:00:00'), Timestamp('2024-06-20 20:00:00'), Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-21 02:00:00'), Timestamp('2024-06-21 07:00:00'), Timestamp('2024-06-21 09:00:00')], 'levels_end_timestamps': [Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00'), Timestamp('2024-06-21 13:58:00')], 'levels_scores': [5.1, 3.9, 7.3, 5.6, 2.8, 16.0, 2.1, 15.5, 5.8, 4.3], 'function_name': 'calculate_sr', 'symbol': 'YM', 'timeframe': '1h', 'response': 'The support and resistance levels for YM based on historical price data with a lookback period of 10 days and a timeframe of 1h are as follows:\\n\\n- Levels: [38448.0, 38749.0, 38770.0, 38778.0, 39259.0, 39117.0, 39168.0, 39118.0, 39476.0, 39687.0]\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.'}}\n",
      "Inference Time: 25.787004232406616 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "response: ([], [], [], [], [], 'The support and resistance levels for CL based on historical price data with a lookback period of 7 days and a timeframe of 1d are as follows:\\n\\n- Levels: []\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.')\n",
      "\n",
      "How much is the sr of CL for the past week?    =>    {'response': 'Based on historical price data for the past week, no specific support and resistance levels have been identified for CL. This means that there are no specific price areas where the price is likely to encounter support or resistance.', 'chart_info': {'levels_prices': [], 'levels_start_timestamps': [], 'levels_detect_timestamps': [], 'levels_end_timestamps': [], 'levels_scores': [], 'function_name': 'calculate_sr', 'symbol': 'CL', 'timeframe': '1d', 'response': 'The support and resistance levels for CL based on historical price data with a lookback period of 7 days and a timeframe of 1d are as follows:\\n\\n- Levels: []\\n\\nThese levels are determined based on historical price data and indicate areas where the price is likely to encounter support or resistance. The associated scores indicate the strength or significance of each level, with higher scores indicating stronger levels.'}}\n",
      "Inference Time: 20.31899857521057 seconds\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_sr_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_sr_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    calculate_sr_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_sr_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_sr_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Stop Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_sl_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?\",\n",
    "    \"What would be the stop loss of trading long positinos based on ES and swing method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and atr method and attribute coefficient of 1.3?\",\n",
    "    \"What would be the stop loss of trading long positinos based on YM and level method?\",\n",
    "    \"What would be the stop loss of trading long positinos based on NQ and DVWAP_band method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on NQ and WVWAP_band method?\",\n",
    "    \"What would be the stop loss of trading short positinos based on GC and zigzag method?\",\n",
    "    \"What would be the stop loss of trading long positinos based on ES?\",\n",
    "    # Challenging prompts\n",
    "    \"How much would be the stop loss for trading?\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be the stop loss of trading short positinos based on NQ and minmax method by looking back up to 30 candles?    =>    {'response': 'Based on the NQ symbol and using the minmax method with a lookback of 30 candles, the stop loss for short positions would be at 20006.75. This stop loss level is calculated based on the maximum high price of the previous 30 candles. The risk on this trade is 0.5.', 'chart_info': {'stop_loss': {'sl': [20006.75], 'risk': [0.5], 'info': ['calculated based on maximum high price of previous 30 candles']}, 'symbol': 'NQ', 'timeframe': '1d'}}\n",
      "Inference Time: 20.448111295700073 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be the stop loss of trading long positinos based on ES and swing method?    =>    {'response': 'These stop loss levels are determined based on the swing method using the ES symbol. The stop loss levels are as follows:\\n\\n- Stop Loss 1: 5531.25 (Risk: 4.75)\\n- Stop Loss 2: 5529.5 (Risk: 6.5)\\n- Stop Loss 3: 5528.75 (Risk: 7.25)\\n- Stop Loss 4: 5528.5 (Risk: 7.5)\\n- Stop Loss 5: 5526.5 (Risk: 9.5)\\n- Stop Loss 6: 5526.25 (Risk: 9.75)\\n- Stop Loss 7: 5524.25 (Risk: 11.75)\\n- Stop Loss 8: 5519.0 (Risk: 17.0)\\n\\nThese stop loss levels are calculated based on the low swing with a neighborhood parameter of 20 candles. The risk value represents the potential loss on each trade.', 'chart_info': {'stop_loss': {'sl': [5531.25, 5529.5, 5528.75, 5528.5, 5526.5, 5526.25, 5524.25, 5519.0], 'risk': [4.75, 6.5, 7.25, 7.5, 9.5, 9.75, 11.75, 17.0], 'info': ['calculated based on low swing with neighborhood parameter of 20 candles', 'calculated based on low swing with neighborhood parameter of 20 candles', 'calculated based on low swing with neighborhood parameter of 20 candles', 'calculated based on low swing with neighborhood parameter of 20 candles', 'calculated based on low swing with neighborhood parameter of 20 candles', 'calculated based on low swing with neighborhood parameter of 20 candles', 'calculated based on low swing with neighborhood parameter of 20 candles', 'calculated based on low swing with neighborhood parameter of 20 candles']}, 'symbol': 'ES', 'timeframe': '1d'}}\n",
      "Inference Time: 19.579089164733887 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be the stop loss of trading short positinos based on NQ and atr method and attribute coefficient of 1.3?    =>    {'response': 'The stop loss for trading short positions on NQ, based on the ATR method with an attribute coefficient of 1.3, would be 20019.5. The risk on this trade would be 12.25 points. This calculation is based on the ATR (Average True Range) with a length of 14, multiplied by the coefficient of 1.3.', 'chart_info': {'stop_loss': {'sl': [20019.5], 'risk': [12.25], 'info': ['calculated based on ATR with length 14 multiplied by the coefficient 1']}, 'symbol': 'NQ', 'timeframe': '1d'}}\n",
      "Inference Time: 21.002443075180054 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be the stop loss of trading long positinos based on YM and level method?    =>    {'response': 'These stop loss levels are determined based on the level method, and the associated risk values indicate the potential loss on each trade.', 'chart_info': {'stop_loss': {'sl': [39573.0, 39554.0, 39550.0, 39535.0, 39516.0, 39502.0, 39496.0, 39481.0, 39476.0, 39446.0, 39362.0, 39342.0, 39259.0, 39259.0, 39238.0, 39139.0, 39134.0, 39117.0, 39030.0, 39018.0, 38954.0, 38926.0, 38778.0], 'risk': [9.0, 28.0, 32.0, 47.0, 66.0, 80.0, 86.0, 101.0, 106.0, 136.0, 220.0, 240.0, 323.0, 323.0, 344.0, 443.0, 448.0, 465.0, 552.0, 564.0, 628.0, 656.0, 804.0], 'info': ['calculated based on the level VWAP', 'calculated based on the level VWAP_Bottom_Band_1', 'calculated based on the level WVWAP_Top_Band_2', 'calculated based on the level VWAP_Bottom_Band_2', 'calculated based on the level VWAP_Bottom_Band_3', 'calculate based on 5min SR level starting from 2024-06-21 15:45:00.000000', 'calculated based on the level VWAP_Bottom_Band_4', 'calculated based on the level initial_balance_low', 'calculate based on hourly SR level starting from 2024-06-21 12:24:00.000000', 'calculated based on the level WVWAP_Top_Band_1', 'calculated based on the level Overnight_mid', 'calculated based on the level WVWAP', 'calculated based on the level VP_VAH', 'calculated based on the level prev_session_max', 'calculated based on the level WVWAP_Bottom_Band_1', 'calculated based on the level VP_POC', 'calculated based on the level WVWAP_Bottom_Band_2', 'calculated based on the level Overnight_low', 'calculated based on the level WVWAP_Bottom_Band_3', 'calculated based on the level prev_session_mid', 'calculated based on the level VP_VAL', 'calculated based on the level WVWAP_Bottom_Band_4', 'calculated based on the level prev_session_min']}, 'symbol': 'YM', 'timeframe': '1d'}}\n",
      "Inference Time: 28.46527862548828 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be the stop loss of trading long positinos based on NQ and DVWAP_band method?    =>    {'response': 'The stop loss for trading long positions based on the NQ and DVWAP_band method is 19982.5. This stop loss is calculated based on the VWAP_Bottom_Band_1 as the bottom of the VWAP zone -1, where the current price is inside the VWAP zone 1. The risk on this trade is 24.75 points.', 'chart_info': {'stop_loss': {'sl': [19982.5], 'risk': [24.75], 'info': ['calculated based on VWAP_Bottom_Band_1 as the bottom of vwap zone -1 (current price is inside vwap zone 1)']}, 'symbol': 'NQ', 'timeframe': '1d'}}\n",
      "Inference Time: 23.07347798347473 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_sl_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_sl_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    calculate_sl_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_sl_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_sl_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Take-Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "calculate_tp_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"How much would be the take-profit of trading based on NQ, long positions and stop loss of 100?\",\n",
    "    \"How much would be the take-profit of trading based on NQ and stop loss of 100?\",\n",
    "    \"How much would be the take-profit of trading based on NQ and long positions?\",\n",
    "    \"How much would be the take-profit of trading based on long positions and stop loss of 100?\",\n",
    "    \"How much would be the take-profit?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much would be the take-profit of trading based on NQ, long positions and stop loss of 100?    =>    {'response': 'I apologize for the inconvenience. It seems that there was an issue with the calculation of the take-profit levels based on the provided parameters. To accurately calculate the take-profit, I would need the current price of NQ and additional information such as the desired risk-reward ratio or target price. Please provide the necessary details so that I can assist you further in calculating the take-profit for your trading position.', 'chart_info': {'take_profit': {'tp': [], 'info': []}, 'symbol': 'NQ', 'timeframe': '1d'}}\n",
      "Inference Time: 31.88167119026184 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "WARNING:root:gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'function_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m input_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_message\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m prompt\n\u001b[1;32m     10\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 11\u001b[0m output_json \u001b[38;5;241m=\u001b[39m \u001b[43mllm_surf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m    =>    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Work/TenSurf/TenSurf_Brain/main.py:190\u001b[0m, in \u001b[0;36mllm_surf\u001b[0;34m(llm_input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     MA \u001b[38;5;241m=\u001b[39m Multi_Agent(\n\u001b[1;32m    187\u001b[0m         ChatWithOpenai\u001b[38;5;241m=\u001b[39mChatWithOpenai, client\u001b[38;5;241m=\u001b[39mazure_connector_surf\u001b[38;5;241m.\u001b[39mclient\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m     graph \u001b[38;5;241m=\u001b[39m MA\u001b[38;5;241m.\u001b[39minitialize_graph()\n\u001b[0;32m--> 190\u001b[0m     llm_output \u001b[38;5;241m=\u001b[39m \u001b[43mMA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_multi_agent_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# running in single-agent mode\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODE\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Work/TenSurf/TenSurf_Brain/multi_agent/multi_agent.py:87\u001b[0m, in \u001b[0;36mMulti_Agent.generate_multi_agent_answer\u001b[0;34m(self, input_json, graph)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_multi_agent_answer\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_json, graph):\n\u001b[1;32m     74\u001b[0m     generated_messages \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m     75\u001b[0m         {\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m150\u001b[39m},\n\u001b[1;32m     85\u001b[0m     )\n\u001b[0;32m---> 87\u001b[0m     generated_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerated_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(generated_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generated_messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][k]:\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/site-packages/langgraph/pregel/__init__.py:963\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m    962\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m--> 963\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1489\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1492\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1494\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/site-packages/langgraph/pregel/retry.py:66\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     64\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/site-packages/langchain_core/runnables/base.py:2502\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2498\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2499\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2500\u001b[0m )\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2502\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2504\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/envs/sepehr/lib/python3.10/site-packages/langgraph/utils.py:95\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m     94\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 95\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Work/TenSurf/TenSurf_Brain/multi_agent/utils.py:174\u001b[0m, in \u001b[0;36mUtils.tool_node\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    171\u001b[0m messages \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    172\u001b[0m last_message \u001b[38;5;241m=\u001b[39m messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    173\u001b[0m tool_input \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\n\u001b[0;32m--> 174\u001b[0m     \u001b[43mlast_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    175\u001b[0m )\n\u001b[1;32m    176\u001b[0m output_json \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tool_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__arg1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tool_input:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'function_call'"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "calculate_tp_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in calculate_tp_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    calculate_tp_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/calculate_tp_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(calculate_tp_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "get_bias_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Tell me about the bias of ES on the market.\",\n",
    "    \"What is the current trading bias for ES?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about the bias of ES on the market.    =>    {'response': 'Based on the analysis of different methods, the bias of ES on the market is determined to be bullish. This conclusion is supported by multiple indicators, including the weekly VWAP, VAL/VAH of volume profile, short-term trend, mid-term trend, long-term trend, trend of the last hour, and counter ratio and power ratio. The combined bias is also bullish.', 'chart_info': {}}\n",
      "What is the current trading bias for ES?    =>    {'response': 'The current trading bias for ES is bullish. This is determined based on various methods including weekly VWAP, VAL/VAH of volume profile, short term trend, mid term trend, long term trend, trend of last hour, and counter ratio and power ratio. The combined bias is also bullish.', 'chart_info': {}}\n"
     ]
    }
   ],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "get_bias_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in get_bias_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    get_bias_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/get_bias_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(get_bias_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "introduction_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Who are you?\",\n",
    "    \"What are you?\",\n",
    "    \"What can you do for me?\",\n",
    "    \"What are your functionalities?\",\n",
    "    \"How can you help me?\",\n",
    "    # Challenging prompts\n",
    "    \"Hi!\",\n",
    "    \"Good Morning!\",\n",
    "    \"What's up!?\",\n",
    "    \"How can I start?\",\n",
    "    \"Please help me!\",\n",
    "    \"What is TenSurf?\",\n",
    "    \"How could you help me?\",\n",
    "    # \"What about market today?\",\n",
    "    \"Could you guide me on how to use tensurf?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "introduction_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in introduction_prompts:\n",
    "    input_json = input_filter.front_end_json_sample\n",
    "    input_json[\"new_message\"] = prompt\n",
    "    start = time()\n",
    "    output_json = llm_surf(input_json)\n",
    "    end = time()\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    print(f\"Inference Time: {end - start} seconds\")\n",
    "    introduction_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/introduction_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(introduction_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odd Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "odd_prompts = [\n",
    "\t\"Trend in the last month\" ,\n",
    "\t\"What is the trend of NQ stock from 3/4/2024/45 15:45:30 until 3/4/2024/67 15:45:30?\" ,\n",
    "\t\"What about market today?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "odd_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in odd_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    odd_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/odd_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(odd_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Chat Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_chat_scenario_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"Hello\",\n",
    "    \"Who are you?\",\n",
    "    \"What can you do for me?\",\n",
    "    \"What is the trend of NQ?\",\n",
    "    \"For the past week\",\n",
    "    \"Can you also calculate the sr of it, too?\",\n",
    "    \"But how about the trend of it for the last month?\",\n",
    "    \"But how about the trend of it for the last year?\",\n",
    "    \"But how about the trend of it for the last day?\",\n",
    "    \"But how about the trend of it for the last hour?\",\n",
    "    \"Hi!\",\n",
    "    \"Can you calculate the sr of it?\",\n",
    "    \"What else can you do?\",\n",
    "    \"So how would be the stop loss for the short position?\",\n",
    "    \"How about long ones?\",\n",
    "    \"So what would be the take profit based on this stop loss?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "long_chat_scenario_results = {}\n",
    "\n",
    "# getting the answer of the prompts\n",
    "# try:\n",
    "\n",
    "for prompt in long_chat_scenario_prompts:\n",
    "    input_json = {\n",
    "        \"file\": None,\n",
    "        \"new_message\": prompt,\n",
    "        \"history_message\": messages,\n",
    "        \"timezone\": -210,\n",
    "        \"symbol\": \"NQ\",\n",
    "        \"start_datetime\": \"\",\n",
    "        \"end_datetime\": \"\",\n",
    "        \"timeframe\": \"1min\",\n",
    "        \"user_id\": \"1\",\n",
    "    }\n",
    "    output_json = llm_surf(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    long_chat_scenario_results[prompt]=output_json[\"response\"]\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"UnitTest/test_results/long_chat_scenario_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(long_chat_scenario_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_function_calling_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the ternd and sr of NQ?\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "parallel_function_calling_results = {}\n",
    "\n",
    "# # getting the answer of the prompts\n",
    "# try:\n",
    "for prompt in parallel_function_calling_prompts:\n",
    "    input_json = {\n",
    "        \"file_path\": None,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    parallel_function_calling_results[prompt]=output_json\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"test_results/parallel_function_calling_test_results.json\", \"w\") as outputfile: \n",
    "    json.dump(parallel_function_calling_results, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of file paths and prompts\n",
    "messages = []\n",
    "\n",
    "file_paths = [\"samplefiles/TjqcZqip.png\", 'samplefiles/applyjobs.xlsx', 'samplefiles/paper.docx',\n",
    "              'samplefiles/sample.pdf', 'samplefiles/transcription.txt', 'samplefiles/english.mp3', None]\n",
    "\n",
    "general_prompts = [\"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"what is the main idea of this file?\",\n",
    "           \"What is the trend of NQ stock from 3/10/2023 15:45:30 until 3/11/2023 15:45:30?\"]\n",
    "\n",
    "# Iterate over file_paths and prompts and run the code\n",
    "for file_path, prompt in zip(file_paths, general_prompts):\n",
    "    input_json = {\n",
    "        \"file_path\": file_path,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the speed of light?    =>    I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\n",
      "tell me about english teaching    =>    I'm here to help with trading and financial market queries. If you think your ask relates to trading and isn't addressed, please report a bug using the bottom right panel.\n"
     ]
    }
   ],
   "source": [
    "irrelevant_prompts = [\n",
    "    # Normal Prompts\n",
    "    \"What is the speed of light?\",\n",
    "    \"tell me about english teaching\",\n",
    "    # Challenging prompts\n",
    "    \n",
    "]\n",
    "\n",
    "# saving the answer of the prompt in a dictionary which its key is the prompt and its value is the answer to that prompt\n",
    "irrelevant_results = {}\n",
    "\n",
    "# # getting the answer of the prompts\n",
    "# try:\n",
    "for prompt in irrelevant_prompts:\n",
    "    input_json = {\n",
    "        \"file_path\": file_path,\n",
    "        \"prompt\": prompt,\n",
    "        \"messages\": messages,\n",
    "        \"front_json\": input_filter.front_end_json_sample\n",
    "    }\n",
    "    output_json = main.main(input_json)\n",
    "    print(f\"{prompt}    =>    {output_json}\")\n",
    "    irrelevant_results[prompt]=output_json\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"The following exception occured:\\n{e}\")\n",
    "\n",
    "# finally:\n",
    "# saving the answers\n",
    "with open(\"test_results/irrelevant_prompts_results.json\", \"w\") as outputfile: \n",
    "    json.dump(irrelevant_results, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech file detected. Processing speech...\n",
      "Speech processing complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The main idea of this file is to provide information about long-term trading in the stock market. It explains that long-term trading involves buying shares of a company and holding onto them for an extended period, with the goal of benefiting from the company's growth over time and earning dividends. Long-term traders are often categorized as investors or position traders.\",\n",
       " {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'samplefiles/tts_test.mp3'\n",
    "messages = []\n",
    "prompt = None\n",
    "\n",
    "input_json = {\n",
    "    \"file_path\": file_path,\n",
    "    \"prompt\": None,\n",
    "    \"messages\": messages,\n",
    "    \"front_json\": input_filter.front_end_json_sample\n",
    "}\n",
    "\n",
    "output_json = main.main(input_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The founders of Microsoft are Bill Gates and Paul Allen. They established the company on April 4, 1975, with the goal of developing and selling software for personal computers. Bill Gates is particularly known for his role in shaping the company's vision and strategy, while Paul Allen played a significant role in technical aspects and product development.\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurf.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '74b3de375b964f73a6b7668fe459e26f'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Corporation was founded by Bill Gates and Paul Allen. Bill Gates, currently one of the world's wealthiest individuals, served as Microsoft's Chairman and CEO for many years before transitioning to a role as a technology advisor. Paul Allen was a prominent philanthropist and entrepreneur who co-founded Microsoft with Bill Gates, but he passed away in 2018.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "api_type = \"azure\"\n",
    "api_endpoint = 'https://tensurfbrain1.openai.azure.com/'\n",
    "api_version = '2023-10-01-preview'\n",
    "api_key = '80ddd1ad72504f2fa226755d49491a61'\n",
    "client = AzureOpenAI(\n",
    "    api_key= api_key,\n",
    "    api_version= api_version,\n",
    "    azure_endpoint= api_endpoint\n",
    ")\n",
    "#########\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt_35\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sepehr\\anaconda3\\envs\\sepehr\\lib\\site-packages\\deepeval\\__init__.py:42: UserWarning: You are using deepeval version 0.21.43, however version 0.21.45 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from UnitTest import unit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_test.unit_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
